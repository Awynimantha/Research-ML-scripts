{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Awynimantha/Research-ML-scripts/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLJ_GvneBpvg",
        "outputId": "90b831b4-41a6-4a53-98f5-61a17f54dd18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import gc as gc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file1 = h5py.File(\"/content/drive/MyDrive/signal data/dataset-benign-latest.h5\", \"r\")\n",
        "file2 = h5py.File(\"/content/drive/MyDrive/signal data/test-benign-idle-5.h5\", \"r\")\n",
        "file3 = h5py.File(\"/content/drive/MyDrive/signal data/dataset-infected-test.h5\", \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import scipy.signal as signal  # Ensure signal is properly imported\n",
        "\n",
        "# Create the new folder if it doesn't exist\n",
        "output_folder = \"/content/drive/MyDrive/spectrograms/test/0\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "keys = file2.keys()\n",
        "for key in list(keys)[3:9]:\n",
        "    try:\n",
        "        signal_data = file2[key]  # Load data\n",
        "        fig = plt.figure()\n",
        "        plt.psd(signal_data, NFFT=2048, Fc=12e6, Fs=20e6)\n",
        "        output_filename = os.path.join(output_folder, f\"z5noise-{key}.png\")\n",
        "        fig.savefig(output_filename, dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
        "        plt.close(fig)  # Close figure to release memory\n",
        "\n",
        "        print(f\"Spectrogram for {key} saved to {output_filename}\")\n",
        "\n",
        "        gc.collect()  # Trigger garbage collection\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing key {key}: {e}\")\n"
      ],
      "metadata": {
        "id": "rVSracNQQqIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import scipy.signal as signal  # Ensure signal is properly imported\n",
        "def add_gaussian_noise(signal, noise_level=0.005):\n",
        "    real_noise = np.random.normal(0, noise_level, size=signal.shape)\n",
        "    imag_noise = np.random.normal(0, noise_level, size=signal.shape)\n",
        "    noisy_signal = signal + (real_noise + 1j * imag_noise)\n",
        "    return noisy_signal\n",
        "\n",
        "# Create the new folder if it doesn't exist\n",
        "output_folder = \"/content/drive/MyDrive/spectrograms/test/0\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "keys = file2.keys()\n",
        "for key in list(keys)[3:9]:\n",
        "    try:\n",
        "        signal_data = add_gaussian_noise(file2[key])  # Load data\n",
        "        fig = plt.figure()\n",
        "        plt.psd(signal_data, NFFT=2048, Fc=12e6, Fs=20e6)\n",
        "        output_filename = os.path.join(output_folder, f\"z5noise-{key}.png\")\n",
        "        fig.savefig(output_filename, dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
        "        plt.close(fig)  # Close figure to release memory\n",
        "\n",
        "        print(f\"Spectrogram for {key} saved to {output_filename}\")\n",
        "\n",
        "        gc.collect()  # Trigger garbage collection\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing key {key}: {e}\")\n"
      ],
      "metadata": {
        "id": "Yx65_7k8Qj9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUhM_dP6C4Tu",
        "outputId": "519563ae-f065-4685-ee1b-8c7fec4d12da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram for benign-idle11 saved to /content/drive/MyDrive/spectrograms/test/0/z5noise-benign-idle11.png\n",
            "Spectrogram for benign-idle12 saved to /content/drive/MyDrive/spectrograms/test/0/z5noise-benign-idle12.png\n",
            "Spectrogram for benign-idle13 saved to /content/drive/MyDrive/spectrograms/test/0/z5noise-benign-idle13.png\n",
            "Spectrogram for benign-idle14 saved to /content/drive/MyDrive/spectrograms/test/0/z5noise-benign-idle14.png\n",
            "Spectrogram for benign-idle15 saved to /content/drive/MyDrive/spectrograms/test/0/z5noise-benign-idle15.png\n",
            "Spectrogram for benign-idle16 saved to /content/drive/MyDrive/spectrograms/test/0/z5noise-benign-idle16.png\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import scipy.signal as signal  # Ensure signal is properly imported\n",
        "def add_gaussian_noise(signal, noise_level=0.005):\n",
        "    real_noise = np.random.normal(0, noise_level, size=signal.shape)\n",
        "    imag_noise = np.random.normal(0, noise_level, size=signal.shape)\n",
        "    noisy_signal = signal + (real_noise + 1j * imag_noise)\n",
        "    return noisy_signal\n",
        "MLP.ipynb_\n",
        "MLP\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import signal\n",
        "import gc as gc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# file1 = h5py.File(\"/content/drive/MyDrive/signal data/dataset-benign-latest.h5\", \"r\")\n",
        "# file2 = h5py.File(\"/content/drive/MyDrive/signal data/dataset-infected-latest.h5\", \"r\")\n",
        "# file3 = h5py.File(\"/content/drive/MyDrive/signal data/dataset-infected-test.h5\", \"r\")\n",
        "# file4 = h5py.File(\"/content/drive/MyDrive/signal data/test-data-idle.h5\", \"r\")\n",
        "file1 = h5py.File(\"/content/drive/MyDrive/signal data/big-benign.h5\", \"r\")\n",
        "file2 = h5py.File(\"/content/drive/MyDrive/signal data/big-infected.h5\", \"r\")\n",
        "file3 = h5py.File(\"/content/drive/MyDrive/signal data/test-benign-idle-5.h5\", \"r\")\n",
        "file4 = h5py.File(\"/content/drive/MyDrive/signal data/test-infected-idle-5.h5\", \"r\")\n",
        "file5 = h5py.File(\"/content/drive/MyDrive/signal data/test-data.h5\", \"r\")\n",
        "\n",
        "file6 = h5py.File(\"/content/drive/MyDrive/signal data/benign-vm.h5\", \"r\")\n",
        "file7 = h5py.File(\"/content/drive/MyDrive/signal data/infected-gamesall.h5\", \"r\")\n",
        "\n",
        "print(file1.keys())\n",
        "print(file2.keys())\n",
        "\n",
        "<KeysViewHDF5 ['benign-idle0', 'benign-idle0_file3', 'benign-idle0_file3_file4', 'benign-idle0_file4', 'benign-idle0_file5', 'benign-idle0_file8', 'benign-idle1', 'benign-idle10', 'benign-idle10_file3', 'benign-idle10_file3_file4', 'benign-idle10_file4', 'benign-idle10_file5', 'benign-idle10_file8', 'benign-idle11', 'benign-idle11_file3', 'benign-idle11_file4', 'benign-idle11_file8', 'benign-idle12', 'benign-idle12_file3', 'benign-idle12_file3_file4', 'benign-idle12_file4', 'benign-idle12_file5', 'benign-idle12_file8', 'benign-idle13', 'benign-idle13_file3', 'benign-idle13_file3_file4', 'benign-idle13_file4', 'benign-idle13_file5', 'benign-idle13_file8', 'benign-idle14', 'benign-idle14_file3', 'benign-idle14_file3_file4', 'benign-idle14_file4', 'benign-idle14_file5', 'benign-idle14_file8', 'benign-idle15', 'benign-idle15_file3', 'benign-idle15_file3_file4', 'benign-idle15_file4', 'benign-idle15_file8', 'benign-idle16', 'benign-idle16_file3', 'benign-idle16_file3_file4', 'benign-idle16_file4', 'benign-idle16_file8', 'benign-idle17', 'benign-idle17_file3', 'benign-idle17_file3_file4', 'benign-idle17_file4', 'benign-idle17_file8', 'benign-idle18', 'benign-idle18_file3', 'benign-idle18_file3_file4', 'benign-idle18_file4', 'benign-idle18_file8', 'benign-idle19', 'benign-idle19_file3', 'benign-idle19_file4', 'benign-idle19_file8', 'benign-idle1_file3', 'benign-idle1_file4', 'benign-idle1_file5', 'benign-idle1_file8', 'benign-idle2', 'benign-idle20', 'benign-idle20_file3', 'benign-idle20_file3_file4', 'benign-idle20_file4', 'benign-idle20_file8', 'benign-idle21', 'benign-idle21_file3', 'benign-idle21_file3_file4', 'benign-idle21_file4', 'benign-idle21_file8', 'benign-idle22', 'benign-idle22_file3', 'benign-idle22_file3_file4', 'benign-idle22_file4', 'benign-idle22_file8', 'benign-idle23', 'benign-idle23_file3', 'benign-idle23_file3_file4', 'benign-idle23_file4', 'benign-idle23_file8', 'benign-idle24', 'benign-idle24_file3', 'benign-idle24_file3_file4', 'benign-idle24_file4', 'benign-idle24_file8', 'benign-idle25', 'benign-idle25_file3', 'benign-idle25_file3_file4', 'benign-idle25_file4', 'benign-idle25_file8', 'benign-idle26', 'benign-idle26_file3', 'benign-idle26_file3_file4', 'benign-idle26_file4', 'benign-idle26_file8', 'benign-idle27', 'benign-idle27_file3', 'benign-idle27_file3_file4', 'benign-idle27_file4', 'benign-idle27_file8', 'benign-idle28', 'benign-idle28_file3', 'benign-idle28_file4', 'benign-idle28_file8', 'benign-idle29', 'benign-idle29_file3', 'benign-idle29_file3_file4', 'benign-idle29_file4', 'benign-idle29_file8', 'benign-idle2_file3', 'benign-idle2_file3_file4', 'benign-idle2_file4', 'benign-idle2_file5', 'benign-idle2_file8', 'benign-idle3', 'benign-idle30', 'benign-idle30_file3', 'benign-idle30_file3_file4', 'benign-idle30_file4', 'benign-idle30_file8', 'benign-idle31', 'benign-idle31_file3', 'benign-idle31_file3_file4', 'benign-idle31_file4', 'benign-idle31_file8', 'benign-idle32', 'benign-idle32_file3', 'benign-idle32_file3_file4', 'benign-idle32_file4', 'benign-idle32_file8', 'benign-idle33', 'benign-idle33_file3', 'benign-idle33_file3_file4', 'benign-idle33_file4', 'benign-idle33_file8', 'benign-idle34', 'benign-idle34_file3', 'benign-idle34_file3_file4', 'benign-idle34_file4', 'benign-idle34_file8', 'benign-idle35', 'benign-idle35_file3', 'benign-idle35_file3_file4', 'benign-idle35_file4', 'benign-idle35_file8', 'benign-idle36', 'benign-idle36_file3', 'benign-idle36_file3_file4', 'benign-idle36_file4', 'benign-idle36_file8', 'benign-idle37', 'benign-idle37_file3', 'benign-idle37_file3_file4', 'benign-idle37_file4', 'benign-idle37_file8', 'benign-idle38', 'benign-idle38_file3', 'benign-idle38_file3_file4', 'benign-idle38_file4', 'benign-idle38_file8', 'benign-idle39', 'benign-idle39_file3', 'benign-idle39_file3_file4', 'benign-idle39_file4', 'benign-idle39_file8', 'benign-idle3_file3', 'benign-idle3_file3_file4', 'benign-idle3_file4', 'benign-idle3_file5', 'benign-idle3_file8', 'benign-idle4', 'benign-idle40', 'benign-idle40_file3', 'benign-idle40_file3_file4', 'benign-idle40_file4', 'benign-idle40_file8', 'benign-idle41', 'benign-idle41_file3', 'benign-idle41_file3_file4', 'benign-idle41_file4', 'benign-idle41_file8', 'benign-idle42', 'benign-idle42_file3', 'benign-idle42_file3_file4', 'benign-idle42_file4', 'benign-idle42_file8', 'benign-idle43', 'benign-idle43_file3', 'benign-idle43_file3_file4', 'benign-idle43_file4', 'benign-idle43_file8', 'benign-idle44', 'benign-idle44_file3', 'benign-idle44_file3_file4', 'benign-idle44_file4', 'benign-idle44_file8', 'benign-idle45', 'benign-idle45_file8', 'benign-idle46', 'benign-idle47', 'benign-idle48', 'benign-idle49', 'benign-idle4_file3', 'benign-idle4_file3_file4', 'benign-idle4_file4', 'benign-idle4_file5', 'benign-idle4_file8', 'benign-idle5', 'benign-idle50', 'benign-idle51', 'benign-idle52', 'benign-idle53', 'benign-idle54', 'benign-idle55', 'benign-idle56', 'benign-idle57', 'benign-idle58', 'benign-idle5_file3', 'benign-idle5_file4', 'benign-idle5_file5', 'benign-idle5_file8', 'benign-idle6', 'benign-idle6_file3', 'benign-idle6_file3_file4', 'benign-idle6_file4', 'benign-idle6_file5', 'benign-idle6_file8', 'benign-idle7', 'benign-idle7_file3', 'benign-idle7_file3_file4', 'benign-idle7_file4', 'benign-idle7_file5', 'benign-idle7_file8', 'benign-idle8', 'benign-idle8_file3', 'benign-idle8_file3_file4', 'benign-idle8_file4', 'benign-idle8_file5', 'benign-idle8_file8', 'benign-idle9', 'benign-idle9_file3', 'benign-idle9_file3_file4', 'benign-idle9_file4', 'benign-idle9_file5', 'benign-idle9_file8']>\n",
        "<KeysViewHDF5 ['infected-idle0', 'infected-idle0_file10', 'infected-idle0_file11', 'infected-idle0_file12', 'infected-idle0_file8', 'infected-idle0_file8_file10', 'infected-idle1', 'infected-idle10', 'infected-idle10_file10', 'infected-idle10_file11', 'infected-idle10_file12', 'infected-idle10_file8', 'infected-idle10_file8_file10', 'infected-idle11', 'infected-idle11_file10', 'infected-idle11_file11', 'infected-idle11_file12', 'infected-idle11_file8', 'infected-idle11_file8_file10', 'infected-idle12', 'infected-idle12_file10', 'infected-idle12_file11', 'infected-idle12_file12', 'infected-idle12_file8', 'infected-idle12_file8_file10', 'infected-idle13', 'infected-idle13_file10', 'infected-idle13_file11', 'infected-idle13_file12', 'infected-idle13_file8', 'infected-idle13_file8_file10', 'infected-idle14', 'infected-idle14_file10', 'infected-idle14_file12', 'infected-idle14_file8', 'infected-idle14_file8_file10', 'infected-idle15', 'infected-idle15_file10', 'infected-idle15_file12', 'infected-idle15_file8', 'infected-idle15_file8_file10', 'infected-idle16', 'infected-idle16_file10', 'infected-idle16_file12', 'infected-idle16_file8', 'infected-idle16_file8_file10', 'infected-idle17', 'infected-idle17_file10', 'infected-idle17_file12', 'infected-idle17_file8', 'infected-idle17_file8_file10', 'infected-idle18', 'infected-idle18_file10', 'infected-idle18_file12', 'infected-idle18_file8', 'infected-idle18_file8_file10', 'infected-idle19', 'infected-idle19_file10', 'infected-idle19_file12', 'infected-idle19_file8', 'infected-idle1_file10', 'infected-idle1_file11', 'infected-idle1_file12', 'infected-idle1_file8', 'infected-idle2', 'infected-idle20', 'infected-idle20_file10', 'infected-idle20_file12', 'infected-idle20_file8', 'infected-idle20_file8_file10', 'infected-idle21', 'infected-idle21_file10', 'infected-idle21_file12', 'infected-idle21_file8', 'infected-idle21_file8_file10', 'infected-idle22', 'infected-idle22_file10', 'infected-idle22_file12', 'infected-idle22_file8', 'infected-idle22_file8_file10', 'infected-idle23', 'infected-idle23_file10', 'infected-idle23_file12', 'infected-idle23_file8', 'infected-idle23_file8_file10', 'infected-idle24', 'infected-idle24_file10', 'infected-idle24_file12', 'infected-idle24_file8', 'infected-idle24_file8_file10', 'infected-idle25', 'infected-idle25_file10', 'infected-idle25_file12', 'infected-idle25_file8', 'infected-idle25_file8_file10', 'infected-idle26', 'infected-idle26_file10', 'infected-idle26_file12', 'infected-idle26_file8', 'infected-idle26_file8_file10', 'infected-idle27', 'infected-idle27_file10', 'infected-idle27_file12', 'infected-idle27_file8', 'infected-idle27_file8_file10', 'infected-idle28', 'infected-idle28_file10', 'infected-idle28_file12', 'infected-idle28_file8', 'infected-idle28_file8_file10', 'infected-idle29', 'infected-idle29_file10', 'infected-idle29_file12', 'infected-idle29_file8', 'infected-idle29_file8_file10', 'infected-idle2_file10', 'infected-idle2_file11', 'infected-idle2_file12', 'infected-idle2_file8', 'infected-idle2_file8_file10', 'infected-idle3', 'infected-idle30', 'infected-idle30_file10', 'infected-idle30_file12', 'infected-idle30_file8', 'infected-idle30_file8_file10', 'infected-idle31', 'infected-idle31_file10', 'infected-idle31_file12', 'infected-idle31_file8', 'infected-idle31_file8_file10', 'infected-idle32', 'infected-idle32_file10', 'infected-idle32_file12', 'infected-idle32_file8', 'infected-idle32_file8_file10', 'infected-idle33', 'infected-idle33_file10', 'infected-idle33_file12', 'infected-idle33_file8', 'infected-idle33_file8_file10', 'infected-idle34', 'infected-idle34_file10', 'infected-idle34_file12', 'infected-idle34_file8', 'infected-idle34_file8_file10', 'infected-idle35', 'infected-idle35_file10', 'infected-idle35_file12', 'infected-idle35_file8', 'infected-idle35_file8_file10', 'infected-idle36', 'infected-idle36_file10', 'infected-idle36_file12', 'infected-idle36_file8', 'infected-idle37', 'infected-idle37_file10', 'infected-idle37_file12', 'infected-idle37_file8', 'infected-idle37_file8_file10', 'infected-idle38', 'infected-idle38_file10', 'infected-idle38_file12', 'infected-idle38_file8', 'infected-idle38_file8_file10', 'infected-idle39', 'infected-idle39_file10', 'infected-idle39_file12', 'infected-idle39_file8', 'infected-idle39_file8_file10', 'infected-idle3_file10', 'infected-idle3_file11', 'infected-idle3_file12', 'infected-idle3_file8', 'infected-idle3_file8_file10', 'infected-idle4', 'infected-idle40', 'infected-idle40_file10', 'infected-idle40_file12', 'infected-idle40_file8', 'infected-idle40_file8_file10', 'infected-idle41', 'infected-idle41_file10', 'infected-idle41_file12', 'infected-idle41_file8', 'infected-idle41_file8_file10', 'infected-idle42', 'infected-idle42_file10', 'infected-idle42_file8', 'infected-idle42_file8_file10', 'infected-idle43', 'infected-idle43_file10', 'infected-idle43_file12', 'infected-idle43_file8', 'infected-idle44', 'infected-idle44_file10', 'infected-idle44_file12', 'infected-idle44_file8', 'infected-idle44_file8_file10', 'infected-idle45', 'infected-idle45_file10', 'infected-idle45_file12', 'infected-idle45_file8', 'infected-idle46', 'infected-idle46_file10', 'infected-idle46_file12', 'infected-idle46_file8', 'infected-idle47', 'infected-idle47_file12', 'infected-idle47_file8', 'infected-idle48', 'infected-idle49', 'infected-idle4_file10', 'infected-idle4_file11', 'infected-idle4_file12', 'infected-idle4_file8', 'infected-idle4_file8_file10', 'infected-idle5', 'infected-idle50', 'infected-idle51', 'infected-idle52', 'infected-idle53', 'infected-idle54', 'infected-idle55', 'infected-idle56', 'infected-idle57', 'infected-idle58', 'infected-idle59', 'infected-idle5_file10', 'infected-idle5_file11', 'infected-idle5_file12', 'infected-idle5_file8', 'infected-idle5_file8_file10', 'infected-idle6', 'infected-idle60', 'infected-idle61', 'infected-idle62', 'infected-idle63', 'infected-idle6_file10', 'infected-idle6_file11', 'infected-idle6_file12', 'infected-idle6_file8', 'infected-idle6_file8_file10', 'infected-idle7', 'infected-idle7_file10', 'infected-idle7_file11', 'infected-idle7_file12', 'infected-idle7_file8', 'infected-idle8', 'infected-idle8_file10', 'infected-idle8_file11', 'infected-idle8_file12', 'infected-idle8_file8', 'infected-idle8_file8_file10', 'infected-idle9', 'infected-idle9_file10', 'infected-idle9_file11', 'infected-idle9_file12', 'infected-idle9_file8', 'infected-idle9_file8_file10']>\n",
        "\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "file1 = h5py.File(\"/content/drive/MyDrive/signal data/big-benign.h5\", \"r\")\n",
        "file2 = h5py.File(\"/content/drive/MyDrive/signal data/big-infected.h5\", \"r\")\n",
        "\n",
        "def compute_nicv_fixed(num_samples=10):\n",
        "    \"\"\"Compute NICV scores for each frequency bin across multiple samples per class.\"\"\"\n",
        "\n",
        "    benign_keys = list(file1.keys())\n",
        "    infected_keys = list(file2.keys())\n",
        "\n",
        "    # Randomly choose 'num_samples' from each class\n",
        "    benign_keys = np.random.choice(benign_keys, size=num_samples, replace=False)\n",
        "    infected_keys = np.random.choice(infected_keys, size=num_samples, replace=False)\n",
        "\n",
        "    benign_magnitudes = []\n",
        "    infected_magnitudes = []\n",
        "\n",
        "    # First: figure out the minimum signal length across all selected samples\n",
        "    lengths = []\n",
        "    for key in benign_keys:\n",
        "        lengths.append(len(file1[key]))\n",
        "    for key in infected_keys:\n",
        "        lengths.append(len(file2[key]))\n",
        "    min_len = min(lengths)\n",
        "\n",
        "    def compute_stft_magnitude(dataset):\n",
        "        # Truncate to min_len\n",
        "        signal = dataset[:min_len]\n",
        "        tensor = tf.convert_to_tensor(signal, dtype=tf.float32)\n",
        "        Zxx = tf.signal.stft(tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "        return tf.abs(Zxx).numpy()\n",
        "\n",
        "    # Compute STFT magnitudes\n",
        "    for key in benign_keys:\n",
        "        benign_magnitudes.append(compute_stft_magnitude(file1[key]))\n",
        "\n",
        "    for key in infected_keys:\n",
        "        infected_magnitudes.append(compute_stft_magnitude(file2[key]))\n",
        "\n",
        "    benign_magnitudes = np.stack(benign_magnitudes)  # shape: [N, T, F]\n",
        "    infected_magnitudes = np.stack(infected_magnitudes)  # shape: [N, T, F]\n",
        "\n",
        "    # Combine and reshape\n",
        "    all_magnitudes = np.concatenate([benign_magnitudes, infected_magnitudes], axis=0)  # [2N, T, F]\n",
        "\n",
        "    # NICV is calculated per frequency bin (averaged over time and samples)\n",
        "    benign_mean_time = benign_magnitudes.mean(axis=1)  # shape: [N, F]\n",
        "    infected_mean_time = infected_magnitudes.mean(axis=1)  # shape: [N, F]\n",
        "    combined_mean_time = all_magnitudes.mean(axis=1)  # shape: [2N, F]\n",
        "\n",
        "    total_variance = np.var(combined_mean_time, axis=0)  # [F]\n",
        "\n",
        "    benign_class_mean = benign_mean_time.mean(axis=0)  # [F]\n",
        "    infected_class_mean = infected_mean_time.mean(axis=0)  # [F]\n",
        "    overall_mean = combined_mean_time.mean(axis=0)  # [F]\n",
        "\n",
        "    n = benign_mean_time.shape[0]\n",
        "    between_class_variance = (\n",
        "        n * (benign_class_mean - overall_mean) ** 2 +\n",
        "        n * (infected_class_mean - overall_mean) ** 2\n",
        "    )  # [F]\n",
        "\n",
        "    nicv_values = between_class_variance / (total_variance + 1e-8)  # [F]\n",
        "\n",
        "    return nicv_values\n",
        "\n",
        "nicv_scores = compute_nicv_fixed()\n",
        "np.save(\"/content/drive/MyDrive/nicv/(4096,2048)\", nicv_scores)\n",
        "\n",
        "nicv_values = np.load(\"/content/drive/MyDrive/nicv/(4096,2048).npy\")\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "\n",
        "keys =  list(file1.keys())[:100] + list(file2.keys())[0:100] + list(file1.keys())[100:] + list(file2.keys())[100:]\n",
        "X_batch = []\n",
        "y_batch = []\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 0\n",
        "  if name in file1:\n",
        "    label = 0\n",
        "    data = file1[name]\n",
        "  else:\n",
        "    label = 1\n",
        "    data = file2[name]\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_batch.append(final_features)\n",
        "  y_batch.append(label)\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py:108: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X_batch_np = np.array(X_batch)\n",
        "y_batch_np = np.array(y_batch)\n",
        "\n",
        "# Save to .npy files\n",
        "np.save('/content/drive/MyDrive/mlp/X_batch.npy', X_batch_np)\n",
        "np.save('/content/drive/MyDrive/mlp/y_batch.npy', y_batch_np)\n",
        "\n",
        "(509, 100)\n",
        "(509,)\n",
        "\n",
        "Epoch 1/350\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
        "\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 2s 10ms/step - accuracy: 0.5082 - loss: 2.7383 - val_accuracy: 0.5163 - val_loss: 0.8406\n",
        "Epoch 2/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5367 - loss: 1.4930 - val_accuracy: 0.8889 - val_loss: 0.6283\n",
        "Epoch 3/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5356 - loss: 0.9671 - val_accuracy: 0.4837 - val_loss: 0.6965\n",
        "Epoch 4/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5696 - loss: 0.8323 - val_accuracy: 0.4837 - val_loss: 0.7004\n",
        "Epoch 5/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5265 - loss: 0.7816 - val_accuracy: 0.4837 - val_loss: 0.6976\n",
        "Epoch 6/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5467 - loss: 0.7571 - val_accuracy: 0.4837 - val_loss: 0.6976\n",
        "Epoch 7/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.5820 - loss: 0.6906 - val_accuracy: 0.4837 - val_loss: 0.6972\n",
        "Epoch 8/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5407 - loss: 0.6991 - val_accuracy: 0.4837 - val_loss: 0.6968\n",
        "Epoch 9/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5104 - loss: 0.7331 - val_accuracy: 0.4837 - val_loss: 0.6961\n",
        "Epoch 10/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5853 - loss: 0.6947 - val_accuracy: 0.4837 - val_loss: 0.6964\n",
        "Epoch 11/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.4656 - loss: 0.7465 - val_accuracy: 0.4837 - val_loss: 0.6959\n",
        "Epoch 12/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.5452 - loss: 0.6938 - val_accuracy: 0.4837 - val_loss: 0.6954\n",
        "Epoch 13/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.5658 - loss: 0.6945 - val_accuracy: 0.4837 - val_loss: 0.6952\n",
        "Epoch 14/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5857 - loss: 0.6797 - val_accuracy: 0.4837 - val_loss: 0.6954\n",
        "Epoch 15/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.5415 - loss: 0.7069 - val_accuracy: 0.4837 - val_loss: 0.6954\n",
        "Epoch 16/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5702 - loss: 0.6851 - val_accuracy: 0.4837 - val_loss: 0.6954\n",
        "Epoch 17/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.5853 - loss: 0.6818 - val_accuracy: 0.4837 - val_loss: 0.6955\n",
        "Epoch 18/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.5553 - loss: 0.6925 - val_accuracy: 0.4837 - val_loss: 0.6954\n",
        "Epoch 19/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5578 - loss: 0.6782 - val_accuracy: 0.4837 - val_loss: 0.6956\n",
        "Epoch 20/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5837 - loss: 0.6755 - val_accuracy: 0.4837 - val_loss: 0.6958\n",
        "Epoch 21/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5110 - loss: 0.6871 - val_accuracy: 0.4837 - val_loss: 0.6957\n",
        "Epoch 22/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5557 - loss: 0.6852 - val_accuracy: 0.4837 - val_loss: 0.6958\n",
        "Epoch 23/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6444 - loss: 0.6516 - val_accuracy: 0.4837 - val_loss: 0.6960\n",
        "Epoch 24/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5577 - loss: 0.6741 - val_accuracy: 0.4837 - val_loss: 0.6960\n",
        "Epoch 25/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6115 - loss: 0.6615 - val_accuracy: 0.4837 - val_loss: 0.6958\n",
        "Epoch 26/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6276 - loss: 0.6439 - val_accuracy: 0.4837 - val_loss: 0.6962\n",
        "Epoch 27/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5896 - loss: 0.6660 - val_accuracy: 0.4837 - val_loss: 0.6962\n",
        "Epoch 28/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6072 - loss: 0.6650 - val_accuracy: 0.4837 - val_loss: 0.6965\n",
        "Epoch 29/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5998 - loss: 0.6665 - val_accuracy: 0.4837 - val_loss: 0.6968\n",
        "Epoch 30/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5787 - loss: 0.6663 - val_accuracy: 0.4837 - val_loss: 0.6969\n",
        "Epoch 31/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5841 - loss: 0.6429 - val_accuracy: 0.4837 - val_loss: 0.6972\n",
        "Epoch 32/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.5859 - loss: 0.6381 - val_accuracy: 0.4837 - val_loss: 0.6973\n",
        "Epoch 33/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6736 - loss: 0.6220 - val_accuracy: 0.4837 - val_loss: 0.6964\n",
        "Epoch 34/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6112 - loss: 0.6661 - val_accuracy: 0.4837 - val_loss: 0.6979\n",
        "Epoch 35/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6725 - loss: 0.6334 - val_accuracy: 0.4837 - val_loss: 0.6889\n",
        "Epoch 36/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6358 - loss: 0.6348 - val_accuracy: 0.8170 - val_loss: 0.6461\n",
        "Epoch 37/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6522 - loss: 0.6202 - val_accuracy: 0.8235 - val_loss: 0.6229\n",
        "Epoch 38/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.6488 - loss: 0.6265 - val_accuracy: 0.8693 - val_loss: 0.5641\n",
        "Epoch 39/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7145 - loss: 0.5956 - val_accuracy: 0.8824 - val_loss: 0.5039\n",
        "Epoch 40/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7585 - loss: 0.5747 - val_accuracy: 0.8824 - val_loss: 0.4773\n",
        "Epoch 41/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7823 - loss: 0.5564 - val_accuracy: 0.8824 - val_loss: 0.4643\n",
        "Epoch 42/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7763 - loss: 0.5305 - val_accuracy: 0.8824 - val_loss: 0.4524\n",
        "Epoch 43/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8163 - loss: 0.5141 - val_accuracy: 0.8889 - val_loss: 0.4383\n",
        "Epoch 44/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7590 - loss: 0.5308 - val_accuracy: 0.8889 - val_loss: 0.4219\n",
        "Epoch 45/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7104 - loss: 0.5410 - val_accuracy: 0.8824 - val_loss: 0.4116\n",
        "Epoch 46/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7841 - loss: 0.5224 - val_accuracy: 0.8889 - val_loss: 0.3980\n",
        "Epoch 47/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7771 - loss: 0.4947 - val_accuracy: 0.8889 - val_loss: 0.3910\n",
        "Epoch 48/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8094 - loss: 0.4906 - val_accuracy: 0.8889 - val_loss: 0.3902\n",
        "Epoch 49/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8149 - loss: 0.4916 - val_accuracy: 0.8824 - val_loss: 0.3801\n",
        "Epoch 50/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.7670 - loss: 0.5203 - val_accuracy: 0.8889 - val_loss: 0.3718\n",
        "Epoch 51/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8541 - loss: 0.4469 - val_accuracy: 0.8889 - val_loss: 0.3635\n",
        "Epoch 52/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8400 - loss: 0.4421 - val_accuracy: 0.8824 - val_loss: 0.3605\n",
        "Epoch 53/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.7935 - loss: 0.4781 - val_accuracy: 0.8889 - val_loss: 0.3531\n",
        "Epoch 54/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8097 - loss: 0.4706 - val_accuracy: 0.8824 - val_loss: 0.3520\n",
        "Epoch 55/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8426 - loss: 0.4615 - val_accuracy: 0.8824 - val_loss: 0.3499\n",
        "Epoch 56/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8659 - loss: 0.3904 - val_accuracy: 0.8824 - val_loss: 0.3470\n",
        "Epoch 57/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8455 - loss: 0.4257 - val_accuracy: 0.8824 - val_loss: 0.3436\n",
        "Epoch 58/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8640 - loss: 0.3862 - val_accuracy: 0.8824 - val_loss: 0.3403\n",
        "Epoch 59/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8263 - loss: 0.4386 - val_accuracy: 0.8824 - val_loss: 0.3373\n",
        "Epoch 60/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8219 - loss: 0.4384 - val_accuracy: 0.8889 - val_loss: 0.3336\n",
        "Epoch 61/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8318 - loss: 0.4150 - val_accuracy: 0.8889 - val_loss: 0.3331\n",
        "Epoch 62/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8605 - loss: 0.3906 - val_accuracy: 0.8889 - val_loss: 0.3287\n",
        "Epoch 63/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8003 - loss: 0.4365 - val_accuracy: 0.8889 - val_loss: 0.3267\n",
        "Epoch 64/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8510 - loss: 0.3981 - val_accuracy: 0.8889 - val_loss: 0.3248\n",
        "Epoch 65/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8157 - loss: 0.4292 - val_accuracy: 0.8889 - val_loss: 0.3220\n",
        "Epoch 66/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8486 - loss: 0.4007 - val_accuracy: 0.8889 - val_loss: 0.3196\n",
        "Epoch 67/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8622 - loss: 0.3837 - val_accuracy: 0.8889 - val_loss: 0.3181\n",
        "Epoch 68/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8741 - loss: 0.3732 - val_accuracy: 0.8889 - val_loss: 0.3178\n",
        "Epoch 69/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8417 - loss: 0.3767 - val_accuracy: 0.8889 - val_loss: 0.3158\n",
        "Epoch 70/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8524 - loss: 0.3892 - val_accuracy: 0.8889 - val_loss: 0.3120\n",
        "Epoch 71/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8539 - loss: 0.3670 - val_accuracy: 0.8889 - val_loss: 0.3099\n",
        "Epoch 72/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8584 - loss: 0.3821 - val_accuracy: 0.8889 - val_loss: 0.3077\n",
        "Epoch 73/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8288 - loss: 0.3931 - val_accuracy: 0.8889 - val_loss: 0.3074\n",
        "Epoch 74/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8619 - loss: 0.3661 - val_accuracy: 0.8889 - val_loss: 0.3046\n",
        "Epoch 75/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8495 - loss: 0.3767 - val_accuracy: 0.8889 - val_loss: 0.3034\n",
        "Epoch 76/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8428 - loss: 0.3644 - val_accuracy: 0.8889 - val_loss: 0.3015\n",
        "Epoch 77/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8081 - loss: 0.4127 - val_accuracy: 0.8889 - val_loss: 0.3015\n",
        "Epoch 78/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8602 - loss: 0.3500 - val_accuracy: 0.8824 - val_loss: 0.3027\n",
        "Epoch 79/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8266 - loss: 0.3949 - val_accuracy: 0.8889 - val_loss: 0.3069\n",
        "Epoch 80/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8723 - loss: 0.3377 - val_accuracy: 0.8889 - val_loss: 0.3018\n",
        "Epoch 81/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8549 - loss: 0.3599 - val_accuracy: 0.8889 - val_loss: 0.2964\n",
        "Epoch 82/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8570 - loss: 0.3747 - val_accuracy: 0.8889 - val_loss: 0.2933\n",
        "Epoch 83/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8553 - loss: 0.3536 - val_accuracy: 0.8889 - val_loss: 0.2894\n",
        "Epoch 84/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8423 - loss: 0.3846 - val_accuracy: 0.8889 - val_loss: 0.2917\n",
        "Epoch 85/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8744 - loss: 0.3187 - val_accuracy: 0.8889 - val_loss: 0.2914\n",
        "Epoch 86/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8631 - loss: 0.3657 - val_accuracy: 0.8889 - val_loss: 0.2913\n",
        "Epoch 87/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8877 - loss: 0.3130 - val_accuracy: 0.8889 - val_loss: 0.2842\n",
        "Epoch 88/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8690 - loss: 0.3534 - val_accuracy: 0.8889 - val_loss: 0.2868\n",
        "Epoch 89/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8650 - loss: 0.3466 - val_accuracy: 0.8889 - val_loss: 0.2878\n",
        "Epoch 90/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8443 - loss: 0.3609 - val_accuracy: 0.8889 - val_loss: 0.2858\n",
        "Epoch 91/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8354 - loss: 0.3767 - val_accuracy: 0.8889 - val_loss: 0.2862\n",
        "Epoch 92/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8686 - loss: 0.3231 - val_accuracy: 0.8889 - val_loss: 0.2779\n",
        "Epoch 93/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8682 - loss: 0.3423 - val_accuracy: 0.8889 - val_loss: 0.2785\n",
        "Epoch 94/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8463 - loss: 0.3674 - val_accuracy: 0.8889 - val_loss: 0.2876\n",
        "Epoch 95/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8644 - loss: 0.3497 - val_accuracy: 0.8889 - val_loss: 0.2804\n",
        "Epoch 96/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8757 - loss: 0.3045 - val_accuracy: 0.8889 - val_loss: 0.2769\n",
        "Epoch 97/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8474 - loss: 0.3844 - val_accuracy: 0.8889 - val_loss: 0.2743\n",
        "Epoch 98/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8417 - loss: 0.3758 - val_accuracy: 0.8889 - val_loss: 0.2815\n",
        "Epoch 99/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8586 - loss: 0.3414 - val_accuracy: 0.8889 - val_loss: 0.2762\n",
        "Epoch 100/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8603 - loss: 0.3508 - val_accuracy: 0.8889 - val_loss: 0.2895\n",
        "Epoch 101/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8626 - loss: 0.3356 - val_accuracy: 0.8889 - val_loss: 0.2750\n",
        "Epoch 102/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8625 - loss: 0.3462 - val_accuracy: 0.8889 - val_loss: 0.2782\n",
        "Epoch 103/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8732 - loss: 0.3169 - val_accuracy: 0.8889 - val_loss: 0.2782\n",
        "Epoch 104/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8441 - loss: 0.3686 - val_accuracy: 0.8889 - val_loss: 0.2791\n",
        "Epoch 105/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8308 - loss: 0.3647 - val_accuracy: 0.8954 - val_loss: 0.2773\n",
        "Epoch 106/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8467 - loss: 0.3664 - val_accuracy: 0.8889 - val_loss: 0.2770\n",
        "Epoch 107/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8665 - loss: 0.3491 - val_accuracy: 0.8889 - val_loss: 0.2782\n",
        "Epoch 108/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8501 - loss: 0.3525 - val_accuracy: 0.8889 - val_loss: 0.2721\n",
        "Epoch 109/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8611 - loss: 0.3397 - val_accuracy: 0.8889 - val_loss: 0.2713\n",
        "Epoch 110/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8764 - loss: 0.3148 - val_accuracy: 0.8889 - val_loss: 0.2705\n",
        "Epoch 111/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8725 - loss: 0.3419 - val_accuracy: 0.8889 - val_loss: 0.2731\n",
        "Epoch 112/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8394 - loss: 0.3639 - val_accuracy: 0.8889 - val_loss: 0.2772\n",
        "Epoch 113/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8626 - loss: 0.3279 - val_accuracy: 0.8954 - val_loss: 0.2662\n",
        "Epoch 114/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8549 - loss: 0.3271 - val_accuracy: 0.8954 - val_loss: 0.2629\n",
        "Epoch 115/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8543 - loss: 0.3519 - val_accuracy: 0.8889 - val_loss: 0.2706\n",
        "Epoch 116/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8623 - loss: 0.3392 - val_accuracy: 0.8954 - val_loss: 0.2642\n",
        "Epoch 117/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8637 - loss: 0.3375 - val_accuracy: 0.8889 - val_loss: 0.2719\n",
        "Epoch 118/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8821 - loss: 0.2978 - val_accuracy: 0.8954 - val_loss: 0.2630\n",
        "Epoch 119/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8812 - loss: 0.3124 - val_accuracy: 0.8954 - val_loss: 0.2618\n",
        "Epoch 120/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9013 - loss: 0.2845 - val_accuracy: 0.8954 - val_loss: 0.2595\n",
        "Epoch 121/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8389 - loss: 0.3559 - val_accuracy: 0.8954 - val_loss: 0.2699\n",
        "Epoch 122/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8635 - loss: 0.3392 - val_accuracy: 0.8954 - val_loss: 0.2679\n",
        "Epoch 123/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8406 - loss: 0.3656 - val_accuracy: 0.8889 - val_loss: 0.2769\n",
        "Epoch 124/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8396 - loss: 0.3435 - val_accuracy: 0.8954 - val_loss: 0.2643\n",
        "Epoch 125/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9061 - loss: 0.2841 - val_accuracy: 0.8954 - val_loss: 0.2632\n",
        "Epoch 126/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9189 - loss: 0.2771 - val_accuracy: 0.9020 - val_loss: 0.2583\n",
        "Epoch 127/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8566 - loss: 0.3553 - val_accuracy: 0.8954 - val_loss: 0.2673\n",
        "Epoch 128/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9069 - loss: 0.2951 - val_accuracy: 0.8954 - val_loss: 0.2673\n",
        "Epoch 129/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8737 - loss: 0.3166 - val_accuracy: 0.8954 - val_loss: 0.2652\n",
        "Epoch 130/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8549 - loss: 0.3500 - val_accuracy: 0.8954 - val_loss: 0.2617\n",
        "Epoch 131/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8658 - loss: 0.3247 - val_accuracy: 0.8954 - val_loss: 0.2679\n",
        "Epoch 132/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8927 - loss: 0.3027 - val_accuracy: 0.9020 - val_loss: 0.2568\n",
        "Epoch 133/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8720 - loss: 0.3365 - val_accuracy: 0.8954 - val_loss: 0.2624\n",
        "Epoch 134/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8864 - loss: 0.2934 - val_accuracy: 0.8954 - val_loss: 0.2698\n",
        "Epoch 135/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8677 - loss: 0.3123 - val_accuracy: 0.8889 - val_loss: 0.2711\n",
        "Epoch 136/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8787 - loss: 0.3229 - val_accuracy: 0.8954 - val_loss: 0.2646\n",
        "Epoch 137/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8529 - loss: 0.3465 - val_accuracy: 0.9020 - val_loss: 0.2582\n",
        "Epoch 138/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8730 - loss: 0.3241 - val_accuracy: 0.8954 - val_loss: 0.2627\n",
        "Epoch 139/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9081 - loss: 0.2561 - val_accuracy: 0.8954 - val_loss: 0.2570\n",
        "Epoch 140/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8873 - loss: 0.2958 - val_accuracy: 0.8954 - val_loss: 0.2635\n",
        "Epoch 141/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8756 - loss: 0.3288 - val_accuracy: 0.8954 - val_loss: 0.2689\n",
        "Epoch 142/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8657 - loss: 0.3293 - val_accuracy: 0.9020 - val_loss: 0.2573\n",
        "Epoch 143/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8851 - loss: 0.2967 - val_accuracy: 0.9020 - val_loss: 0.2594\n",
        "Epoch 144/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8925 - loss: 0.2864 - val_accuracy: 0.8954 - val_loss: 0.2644\n",
        "Epoch 145/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8865 - loss: 0.2760 - val_accuracy: 0.9020 - val_loss: 0.2727\n",
        "Epoch 146/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8783 - loss: 0.3167 - val_accuracy: 0.8954 - val_loss: 0.2602\n",
        "Epoch 147/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8945 - loss: 0.2778 - val_accuracy: 0.9020 - val_loss: 0.2546\n",
        "Epoch 148/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8547 - loss: 0.3176 - val_accuracy: 0.9020 - val_loss: 0.2526\n",
        "Epoch 149/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8508 - loss: 0.3530 - val_accuracy: 0.9020 - val_loss: 0.2566\n",
        "Epoch 150/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8481 - loss: 0.3493 - val_accuracy: 0.8954 - val_loss: 0.2651\n",
        "Epoch 151/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8553 - loss: 0.3520 - val_accuracy: 0.8954 - val_loss: 0.2634\n",
        "Epoch 152/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8701 - loss: 0.3184 - val_accuracy: 0.9020 - val_loss: 0.2517\n",
        "Epoch 153/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8449 - loss: 0.3909 - val_accuracy: 0.8954 - val_loss: 0.2623\n",
        "Epoch 154/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8730 - loss: 0.3265 - val_accuracy: 0.9020 - val_loss: 0.2515\n",
        "Epoch 155/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8721 - loss: 0.3321 - val_accuracy: 0.8954 - val_loss: 0.2606\n",
        "Epoch 156/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8642 - loss: 0.3302 - val_accuracy: 0.8954 - val_loss: 0.2654\n",
        "Epoch 157/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8754 - loss: 0.3218 - val_accuracy: 0.8954 - val_loss: 0.2635\n",
        "Epoch 158/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8490 - loss: 0.3403 - val_accuracy: 0.8954 - val_loss: 0.2677\n",
        "Epoch 159/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8655 - loss: 0.3320 - val_accuracy: 0.8954 - val_loss: 0.2584\n",
        "Epoch 160/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8837 - loss: 0.3047 - val_accuracy: 0.9020 - val_loss: 0.2554\n",
        "Epoch 161/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8535 - loss: 0.3408 - val_accuracy: 0.8954 - val_loss: 0.2709\n",
        "Epoch 162/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8626 - loss: 0.3230 - val_accuracy: 0.8954 - val_loss: 0.2612\n",
        "Epoch 163/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9040 - loss: 0.2810 - val_accuracy: 0.8954 - val_loss: 0.2609\n",
        "Epoch 164/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8622 - loss: 0.3070 - val_accuracy: 0.9020 - val_loss: 0.2564\n",
        "Epoch 165/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8853 - loss: 0.2972 - val_accuracy: 0.8954 - val_loss: 0.2615\n",
        "Epoch 166/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8617 - loss: 0.3378 - val_accuracy: 0.8954 - val_loss: 0.2665\n",
        "Epoch 167/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8356 - loss: 0.3745 - val_accuracy: 0.8889 - val_loss: 0.2721\n",
        "Epoch 168/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8701 - loss: 0.3115 - val_accuracy: 0.8889 - val_loss: 0.2752\n",
        "Epoch 169/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8508 - loss: 0.3411 - val_accuracy: 0.8954 - val_loss: 0.2569\n",
        "Epoch 170/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8936 - loss: 0.2996 - val_accuracy: 0.8954 - val_loss: 0.2664\n",
        "Epoch 171/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8651 - loss: 0.3298 - val_accuracy: 0.8954 - val_loss: 0.2572\n",
        "Epoch 172/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8745 - loss: 0.3266 - val_accuracy: 0.8954 - val_loss: 0.2593\n",
        "Epoch 173/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8381 - loss: 0.3636 - val_accuracy: 0.8954 - val_loss: 0.2675\n",
        "Epoch 174/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8747 - loss: 0.3129 - val_accuracy: 0.8954 - val_loss: 0.2659\n",
        "Epoch 175/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8387 - loss: 0.3458 - val_accuracy: 0.8889 - val_loss: 0.2696\n",
        "Epoch 176/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8704 - loss: 0.3191 - val_accuracy: 0.8954 - val_loss: 0.2624\n",
        "Epoch 177/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8535 - loss: 0.3411 - val_accuracy: 0.8954 - val_loss: 0.2612\n",
        "Epoch 178/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8640 - loss: 0.3220 - val_accuracy: 0.8954 - val_loss: 0.2631\n",
        "Epoch 179/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8816 - loss: 0.3102 - val_accuracy: 0.8954 - val_loss: 0.2656\n",
        "Epoch 180/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8728 - loss: 0.3075 - val_accuracy: 0.8954 - val_loss: 0.2562\n",
        "Epoch 181/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8589 - loss: 0.3441 - val_accuracy: 0.8954 - val_loss: 0.2670\n",
        "Epoch 182/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8548 - loss: 0.3232 - val_accuracy: 0.8954 - val_loss: 0.2599\n",
        "Epoch 183/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8952 - loss: 0.2862 - val_accuracy: 0.8954 - val_loss: 0.2631\n",
        "Epoch 184/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8828 - loss: 0.3053 - val_accuracy: 0.8954 - val_loss: 0.2637\n",
        "Epoch 185/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8621 - loss: 0.3330 - val_accuracy: 0.8954 - val_loss: 0.2555\n",
        "Epoch 186/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8665 - loss: 0.3263 - val_accuracy: 0.8954 - val_loss: 0.2565\n",
        "Epoch 187/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8398 - loss: 0.3686 - val_accuracy: 0.8889 - val_loss: 0.2697\n",
        "Epoch 188/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8430 - loss: 0.3535 - val_accuracy: 0.8954 - val_loss: 0.2572\n",
        "Epoch 189/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9032 - loss: 0.2712 - val_accuracy: 0.8954 - val_loss: 0.2613\n",
        "Epoch 190/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8576 - loss: 0.3289 - val_accuracy: 0.9020 - val_loss: 0.2528\n",
        "Epoch 191/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8617 - loss: 0.3411 - val_accuracy: 0.8954 - val_loss: 0.2608\n",
        "Epoch 192/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8739 - loss: 0.3179 - val_accuracy: 0.8954 - val_loss: 0.2580\n",
        "Epoch 193/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8905 - loss: 0.2816 - val_accuracy: 0.8954 - val_loss: 0.2589\n",
        "Epoch 194/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8448 - loss: 0.3532 - val_accuracy: 0.8954 - val_loss: 0.2624\n",
        "Epoch 195/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8388 - loss: 0.3602 - val_accuracy: 0.8954 - val_loss: 0.2639\n",
        "Epoch 196/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8583 - loss: 0.3176 - val_accuracy: 0.8954 - val_loss: 0.2649\n",
        "Epoch 197/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8803 - loss: 0.2980 - val_accuracy: 0.8954 - val_loss: 0.2590\n",
        "Epoch 198/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8730 - loss: 0.3207 - val_accuracy: 0.8954 - val_loss: 0.2564\n",
        "Epoch 199/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8715 - loss: 0.3140 - val_accuracy: 0.8954 - val_loss: 0.2537\n",
        "Epoch 200/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8505 - loss: 0.3569 - val_accuracy: 0.8954 - val_loss: 0.2598\n",
        "Epoch 201/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8960 - loss: 0.2845 - val_accuracy: 0.8954 - val_loss: 0.2577\n",
        "Epoch 202/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8774 - loss: 0.3230 - val_accuracy: 0.8954 - val_loss: 0.2571\n",
        "Epoch 203/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8881 - loss: 0.3028 - val_accuracy: 0.8954 - val_loss: 0.2548\n",
        "Epoch 204/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8537 - loss: 0.3377 - val_accuracy: 0.9020 - val_loss: 0.2534\n",
        "Epoch 205/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8291 - loss: 0.3859 - val_accuracy: 0.8954 - val_loss: 0.2553\n",
        "Epoch 206/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8812 - loss: 0.3237 - val_accuracy: 0.8954 - val_loss: 0.2608\n",
        "Epoch 207/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8573 - loss: 0.3291 - val_accuracy: 0.8954 - val_loss: 0.2568\n",
        "Epoch 208/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8485 - loss: 0.3585 - val_accuracy: 0.8954 - val_loss: 0.2530\n",
        "Epoch 209/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8599 - loss: 0.3184 - val_accuracy: 0.8954 - val_loss: 0.2602\n",
        "Epoch 210/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8411 - loss: 0.3653 - val_accuracy: 0.8954 - val_loss: 0.2548\n",
        "Epoch 211/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8329 - loss: 0.3994 - val_accuracy: 0.8954 - val_loss: 0.2629\n",
        "Epoch 212/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8692 - loss: 0.3422 - val_accuracy: 0.8954 - val_loss: 0.2566\n",
        "Epoch 213/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8572 - loss: 0.3485 - val_accuracy: 0.8954 - val_loss: 0.2641\n",
        "Epoch 214/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8582 - loss: 0.3330 - val_accuracy: 0.8954 - val_loss: 0.2611\n",
        "Epoch 215/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8991 - loss: 0.2796 - val_accuracy: 0.8954 - val_loss: 0.2564\n",
        "Epoch 216/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8521 - loss: 0.3546 - val_accuracy: 0.8954 - val_loss: 0.2573\n",
        "Epoch 217/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8579 - loss: 0.3364 - val_accuracy: 0.8954 - val_loss: 0.2585\n",
        "Epoch 218/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8648 - loss: 0.3382 - val_accuracy: 0.8954 - val_loss: 0.2606\n",
        "Epoch 219/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9006 - loss: 0.2913 - val_accuracy: 0.8954 - val_loss: 0.2574\n",
        "Epoch 220/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8876 - loss: 0.2885 - val_accuracy: 0.8954 - val_loss: 0.2602\n",
        "Epoch 221/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8404 - loss: 0.3738 - val_accuracy: 0.8824 - val_loss: 0.2786\n",
        "Epoch 222/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8768 - loss: 0.3110 - val_accuracy: 0.8889 - val_loss: 0.2750\n",
        "Epoch 223/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8956 - loss: 0.2805 - val_accuracy: 0.8954 - val_loss: 0.2592\n",
        "Epoch 224/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8484 - loss: 0.3502 - val_accuracy: 0.8954 - val_loss: 0.2567\n",
        "Epoch 225/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8743 - loss: 0.3090 - val_accuracy: 0.8954 - val_loss: 0.2591\n",
        "Epoch 226/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8532 - loss: 0.3693 - val_accuracy: 0.8954 - val_loss: 0.2585\n",
        "Epoch 227/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8195 - loss: 0.3931 - val_accuracy: 0.8954 - val_loss: 0.2555\n",
        "Epoch 228/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9025 - loss: 0.2882 - val_accuracy: 0.8954 - val_loss: 0.2589\n",
        "Epoch 229/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8318 - loss: 0.3789 - val_accuracy: 0.8954 - val_loss: 0.2570\n",
        "Epoch 230/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8351 - loss: 0.3633 - val_accuracy: 0.8889 - val_loss: 0.2696\n",
        "Epoch 231/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8811 - loss: 0.3059 - val_accuracy: 0.8954 - val_loss: 0.2545\n",
        "Epoch 232/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8713 - loss: 0.3055 - val_accuracy: 0.8954 - val_loss: 0.2591\n",
        "Epoch 233/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8605 - loss: 0.3270 - val_accuracy: 0.8954 - val_loss: 0.2581\n",
        "Epoch 234/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8700 - loss: 0.3034 - val_accuracy: 0.8954 - val_loss: 0.2664\n",
        "Epoch 235/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8592 - loss: 0.3207 - val_accuracy: 0.8954 - val_loss: 0.2599\n",
        "Epoch 236/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8186 - loss: 0.3931 - val_accuracy: 0.8889 - val_loss: 0.2732\n",
        "Epoch 237/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8568 - loss: 0.3398 - val_accuracy: 0.8954 - val_loss: 0.2575\n",
        "Epoch 238/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8693 - loss: 0.3022 - val_accuracy: 0.8954 - val_loss: 0.2780\n",
        "Epoch 239/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8895 - loss: 0.2993 - val_accuracy: 0.8954 - val_loss: 0.2539\n",
        "Epoch 240/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8399 - loss: 0.3690 - val_accuracy: 0.8889 - val_loss: 0.2648\n",
        "Epoch 241/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8716 - loss: 0.3260 - val_accuracy: 0.8889 - val_loss: 0.2646\n",
        "Epoch 242/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8903 - loss: 0.2905 - val_accuracy: 0.8889 - val_loss: 0.2647\n",
        "Epoch 243/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8578 - loss: 0.3286 - val_accuracy: 0.8954 - val_loss: 0.2537\n",
        "Epoch 244/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8510 - loss: 0.3380 - val_accuracy: 0.8954 - val_loss: 0.2571\n",
        "Epoch 245/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8764 - loss: 0.2974 - val_accuracy: 0.8954 - val_loss: 0.2577\n",
        "Epoch 246/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8799 - loss: 0.3069 - val_accuracy: 0.8954 - val_loss: 0.2566\n",
        "Epoch 247/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8766 - loss: 0.3063 - val_accuracy: 0.8954 - val_loss: 0.2620\n",
        "Epoch 248/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8389 - loss: 0.3663 - val_accuracy: 0.8954 - val_loss: 0.2596\n",
        "Epoch 249/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8742 - loss: 0.3223 - val_accuracy: 0.8954 - val_loss: 0.2623\n",
        "Epoch 250/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8557 - loss: 0.3350 - val_accuracy: 0.8954 - val_loss: 0.2638\n",
        "Epoch 251/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8084 - loss: 0.4014 - val_accuracy: 0.8954 - val_loss: 0.2596\n",
        "Epoch 252/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8393 - loss: 0.3426 - val_accuracy: 0.8954 - val_loss: 0.2629\n",
        "Epoch 253/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8754 - loss: 0.3152 - val_accuracy: 0.8954 - val_loss: 0.2541\n",
        "Epoch 254/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8372 - loss: 0.3675 - val_accuracy: 0.8954 - val_loss: 0.2554\n",
        "Epoch 255/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8736 - loss: 0.3093 - val_accuracy: 0.8954 - val_loss: 0.2613\n",
        "Epoch 256/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8852 - loss: 0.2989 - val_accuracy: 0.8954 - val_loss: 0.2533\n",
        "Epoch 257/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8800 - loss: 0.3016 - val_accuracy: 0.8954 - val_loss: 0.2649\n",
        "Epoch 258/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8726 - loss: 0.3133 - val_accuracy: 0.8954 - val_loss: 0.2545\n",
        "Epoch 259/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8219 - loss: 0.3838 - val_accuracy: 0.8954 - val_loss: 0.2617\n",
        "Epoch 260/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8717 - loss: 0.3219 - val_accuracy: 0.8954 - val_loss: 0.2603\n",
        "Epoch 261/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8797 - loss: 0.3038 - val_accuracy: 0.8954 - val_loss: 0.2581\n",
        "Epoch 262/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8982 - loss: 0.2852 - val_accuracy: 0.8954 - val_loss: 0.2514\n",
        "Epoch 263/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8755 - loss: 0.3232 - val_accuracy: 0.8954 - val_loss: 0.2619\n",
        "Epoch 264/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8594 - loss: 0.3387 - val_accuracy: 0.8954 - val_loss: 0.2554\n",
        "Epoch 265/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8688 - loss: 0.3098 - val_accuracy: 0.9020 - val_loss: 0.2516\n",
        "Epoch 266/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8299 - loss: 0.3837 - val_accuracy: 0.8954 - val_loss: 0.2546\n",
        "Epoch 267/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8861 - loss: 0.2863 - val_accuracy: 0.8954 - val_loss: 0.2536\n",
        "Epoch 268/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8576 - loss: 0.3371 - val_accuracy: 0.9020 - val_loss: 0.2489\n",
        "Epoch 269/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8429 - loss: 0.3636 - val_accuracy: 0.8954 - val_loss: 0.2563\n",
        "Epoch 270/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8732 - loss: 0.3126 - val_accuracy: 0.8954 - val_loss: 0.2590\n",
        "Epoch 271/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8550 - loss: 0.3412 - val_accuracy: 0.8954 - val_loss: 0.2554\n",
        "Epoch 272/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8499 - loss: 0.3322 - val_accuracy: 0.9020 - val_loss: 0.2550\n",
        "Epoch 273/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8941 - loss: 0.2907 - val_accuracy: 0.9020 - val_loss: 0.2503\n",
        "Epoch 274/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8819 - loss: 0.3151 - val_accuracy: 0.8954 - val_loss: 0.2555\n",
        "Epoch 275/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8715 - loss: 0.3154 - val_accuracy: 0.9020 - val_loss: 0.2507\n",
        "Epoch 276/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8736 - loss: 0.3080 - val_accuracy: 0.8954 - val_loss: 0.2621\n",
        "Epoch 277/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8479 - loss: 0.3402 - val_accuracy: 0.8954 - val_loss: 0.2520\n",
        "Epoch 278/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8715 - loss: 0.3094 - val_accuracy: 0.9020 - val_loss: 0.2505\n",
        "Epoch 279/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8487 - loss: 0.3592 - val_accuracy: 0.9020 - val_loss: 0.2509\n",
        "Epoch 280/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8595 - loss: 0.3314 - val_accuracy: 0.8954 - val_loss: 0.2539\n",
        "Epoch 281/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8517 - loss: 0.3432 - val_accuracy: 0.8954 - val_loss: 0.2607\n",
        "Epoch 282/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8136 - loss: 0.3908 - val_accuracy: 0.8954 - val_loss: 0.2651\n",
        "Epoch 283/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8698 - loss: 0.3243 - val_accuracy: 0.8954 - val_loss: 0.2568\n",
        "Epoch 284/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.9026 - loss: 0.2688 - val_accuracy: 0.8954 - val_loss: 0.2580\n",
        "Epoch 285/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8551 - loss: 0.3452 - val_accuracy: 0.9020 - val_loss: 0.2510\n",
        "Epoch 286/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8430 - loss: 0.3612 - val_accuracy: 0.8954 - val_loss: 0.2562\n",
        "Epoch 287/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8897 - loss: 0.2970 - val_accuracy: 0.8954 - val_loss: 0.2594\n",
        "Epoch 288/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8527 - loss: 0.3522 - val_accuracy: 0.8954 - val_loss: 0.2582\n",
        "Epoch 289/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8389 - loss: 0.3924 - val_accuracy: 0.8954 - val_loss: 0.2597\n",
        "Epoch 290/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8659 - loss: 0.3219 - val_accuracy: 0.8954 - val_loss: 0.2577\n",
        "Epoch 291/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8462 - loss: 0.3328 - val_accuracy: 0.9020 - val_loss: 0.2507\n",
        "Epoch 292/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8606 - loss: 0.3185 - val_accuracy: 0.9020 - val_loss: 0.2514\n",
        "Epoch 293/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8714 - loss: 0.3310 - val_accuracy: 0.8954 - val_loss: 0.2550\n",
        "Epoch 294/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8802 - loss: 0.3083 - val_accuracy: 0.8954 - val_loss: 0.2557\n",
        "Epoch 295/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8902 - loss: 0.2972 - val_accuracy: 0.8954 - val_loss: 0.2583\n",
        "Epoch 296/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8594 - loss: 0.3401 - val_accuracy: 0.8954 - val_loss: 0.2592\n",
        "Epoch 297/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8770 - loss: 0.2972 - val_accuracy: 0.8954 - val_loss: 0.2572\n",
        "Epoch 298/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8474 - loss: 0.3544 - val_accuracy: 0.8954 - val_loss: 0.2547\n",
        "Epoch 299/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8440 - loss: 0.3553 - val_accuracy: 0.8954 - val_loss: 0.2524\n",
        "Epoch 300/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8597 - loss: 0.3490 - val_accuracy: 0.8954 - val_loss: 0.2613\n",
        "Epoch 301/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8651 - loss: 0.3147 - val_accuracy: 0.8954 - val_loss: 0.2517\n",
        "Epoch 302/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8784 - loss: 0.2997 - val_accuracy: 0.8954 - val_loss: 0.2560\n",
        "Epoch 303/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8667 - loss: 0.3115 - val_accuracy: 0.8954 - val_loss: 0.2532\n",
        "Epoch 304/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.9033 - loss: 0.2632 - val_accuracy: 0.8954 - val_loss: 0.2535\n",
        "Epoch 305/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.9152 - loss: 0.2662 - val_accuracy: 0.9020 - val_loss: 0.2475\n",
        "Epoch 306/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8688 - loss: 0.3239 - val_accuracy: 0.9020 - val_loss: 0.2512\n",
        "Epoch 307/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8750 - loss: 0.3147 - val_accuracy: 0.8954 - val_loss: 0.2685\n",
        "Epoch 308/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8692 - loss: 0.3274 - val_accuracy: 0.8954 - val_loss: 0.2604\n",
        "Epoch 309/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8440 - loss: 0.3522 - val_accuracy: 0.8954 - val_loss: 0.2585\n",
        "Epoch 310/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8700 - loss: 0.3241 - val_accuracy: 0.8954 - val_loss: 0.2610\n",
        "Epoch 311/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8647 - loss: 0.3285 - val_accuracy: 0.8954 - val_loss: 0.2572\n",
        "Epoch 312/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8625 - loss: 0.3228 - val_accuracy: 0.8889 - val_loss: 0.2682\n",
        "Epoch 313/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8949 - loss: 0.2923 - val_accuracy: 0.8954 - val_loss: 0.2644\n",
        "Epoch 314/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8463 - loss: 0.3547 - val_accuracy: 0.8954 - val_loss: 0.2558\n",
        "Epoch 315/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8621 - loss: 0.3186 - val_accuracy: 0.8954 - val_loss: 0.2649\n",
        "Epoch 316/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8435 - loss: 0.3672 - val_accuracy: 0.8824 - val_loss: 0.2778\n",
        "Epoch 317/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8554 - loss: 0.3474 - val_accuracy: 0.8954 - val_loss: 0.2586\n",
        "Epoch 318/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8954 - loss: 0.2810 - val_accuracy: 0.8954 - val_loss: 0.2588\n",
        "Epoch 319/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8751 - loss: 0.2957 - val_accuracy: 0.9020 - val_loss: 0.2511\n",
        "Epoch 320/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8600 - loss: 0.3281 - val_accuracy: 0.8954 - val_loss: 0.2599\n",
        "Epoch 321/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8503 - loss: 0.3480 - val_accuracy: 0.9020 - val_loss: 0.2483\n",
        "Epoch 322/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8729 - loss: 0.3215 - val_accuracy: 0.8954 - val_loss: 0.2544\n",
        "Epoch 323/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8821 - loss: 0.2901 - val_accuracy: 0.9020 - val_loss: 0.2504\n",
        "Epoch 324/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8791 - loss: 0.3115 - val_accuracy: 0.8954 - val_loss: 0.2569\n",
        "Epoch 325/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8365 - loss: 0.3622 - val_accuracy: 0.8889 - val_loss: 0.2660\n",
        "Epoch 326/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8673 - loss: 0.3296 - val_accuracy: 0.8954 - val_loss: 0.2657\n",
        "Epoch 327/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8934 - loss: 0.2969 - val_accuracy: 0.8889 - val_loss: 0.2684\n",
        "Epoch 328/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8668 - loss: 0.3256 - val_accuracy: 0.8954 - val_loss: 0.2620\n",
        "Epoch 329/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8645 - loss: 0.3225 - val_accuracy: 0.8954 - val_loss: 0.2639\n",
        "Epoch 330/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8482 - loss: 0.3416 - val_accuracy: 0.8954 - val_loss: 0.2600\n",
        "Epoch 331/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8718 - loss: 0.3126 - val_accuracy: 0.8954 - val_loss: 0.2552\n",
        "Epoch 332/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8612 - loss: 0.3352 - val_accuracy: 0.8954 - val_loss: 0.2571\n",
        "Epoch 333/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8431 - loss: 0.3488 - val_accuracy: 0.9020 - val_loss: 0.2510\n",
        "Epoch 334/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8669 - loss: 0.3244 - val_accuracy: 0.8954 - val_loss: 0.2554\n",
        "Epoch 335/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8507 - loss: 0.3520 - val_accuracy: 0.8954 - val_loss: 0.2539\n",
        "Epoch 336/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8857 - loss: 0.3053 - val_accuracy: 0.8954 - val_loss: 0.2532\n",
        "Epoch 337/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8888 - loss: 0.2790 - val_accuracy: 0.8954 - val_loss: 0.2555\n",
        "Epoch 338/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8879 - loss: 0.3019 - val_accuracy: 0.9020 - val_loss: 0.2484\n",
        "Epoch 339/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8619 - loss: 0.3242 - val_accuracy: 0.8954 - val_loss: 0.2553\n",
        "Epoch 340/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8760 - loss: 0.2997 - val_accuracy: 0.9020 - val_loss: 0.2475\n",
        "Epoch 341/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8810 - loss: 0.3291 - val_accuracy: 0.8954 - val_loss: 0.2625\n",
        "Epoch 342/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8711 - loss: 0.3077 - val_accuracy: 0.8954 - val_loss: 0.2605\n",
        "Epoch 343/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8932 - loss: 0.3025 - val_accuracy: 0.8954 - val_loss: 0.2522\n",
        "Epoch 344/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8393 - loss: 0.3618 - val_accuracy: 0.8954 - val_loss: 0.2573\n",
        "Epoch 345/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8354 - loss: 0.3667 - val_accuracy: 0.8954 - val_loss: 0.2631\n",
        "Epoch 346/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8700 - loss: 0.3166 - val_accuracy: 0.8954 - val_loss: 0.2593\n",
        "Epoch 347/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - accuracy: 0.8922 - loss: 0.2923 - val_accuracy: 0.8954 - val_loss: 0.2656\n",
        "Epoch 348/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8877 - loss: 0.3001 - val_accuracy: 0.8954 - val_loss: 0.2519\n",
        "Epoch 349/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8765 - loss: 0.3085 - val_accuracy: 0.8954 - val_loss: 0.2562\n",
        "Epoch 350/350\n",
        "36/36 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - accuracy: 0.8559 - loss: 0.3185 - val_accuracy: 0.8954 - val_loss: 0.2612\n",
        "\n",
        "<keras.src.callbacks.history.History at 0x7d1ccb062690>\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test_batch, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(np.array(X_test_batch), np.array(y_test_batch), verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "Test Accuracy: 0.9000\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/mlp/model(4096,2048)-87.h5')\n",
        "\n",
        "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/drive/MyDrive/mlp/model(4096,2048)-87.h5')\n",
        "\n",
        "# Now you can use the loaded model for prediction or further training\n",
        "# For example, to make predictions:\n",
        "# predictions = model.predict(new_data)\n",
        "\n",
        "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Set number of folds\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Store scores\n",
        "fold_accuracies = []\n",
        "model2 = None\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X_train_global)):\n",
        "    print(f\"Training Fold {fold + 1}/{k}...\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X_train_global[train_idx], X_test_global[test_idx]\n",
        "    y_train, y_test = y_train_global[train_idx], y_test_global[test_idx]\n",
        "\n",
        "    # Define MLP model\n",
        "    model = Sequential([\n",
        "      Dense(32, activation='relu', input_shape=(500,)),\n",
        "      Dropout(0.3),\n",
        "      Dense(16, activation='relu'),\n",
        "      Dropout(0.3),\n",
        "      Dense(8, activation='relu'),\n",
        "      Dropout(0.3),\n",
        "      Dense(4, activation='relu'),\n",
        "      Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "    model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model2.fit(X_train, y_train, epochs=400, batch_size=10,\n",
        "                        validation_data=(X_test, y_test), verbose=2)\n",
        "\n",
        "    # Evaluate the model\n",
        "    _, accuracy = model2.evaluate(X_test, y_test, verbose=0)\n",
        "    fold_accuracies.append(accuracy)\n",
        "    print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\\n\")\n",
        "\n",
        "# Print final cross-validation accuracy\n",
        "print(f\"Mean Accuracy: {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "\n",
        "keys =  list(file3.keys())[:100] + list(file4.keys())[0:100] + list(file3.keys())[100:] + list(file4.keys())[100:]\n",
        "X_test_batch = []\n",
        "y_test_batch = []\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 0\n",
        "  if name in file3:\n",
        "    label = 0\n",
        "    data = file3[name]\n",
        "  else:\n",
        "    label = 1\n",
        "    data = file4[name]\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_test_batch.append(final_features)\n",
        "  y_test_batch.append(label)\n",
        "\n",
        "\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "\n",
        "keys =  list(file5.keys())\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 0\n",
        "  if(file5[name].attrs.get('label') == \"benign\"):\n",
        "    label = 0\n",
        "    data = file5[name]\n",
        "  else:\n",
        "    label = 1\n",
        "    data = file5[name]\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_test_batch.append(final_features)\n",
        "  y_test_batch.append(label)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(np.array(X_test_global), np.array(y_test_global), verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "Test Accuracy: 0.9020\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(np.array(X_test_global))\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(classification_report(y_test_global, y_pred))\n",
        "\n",
        "1/5 ━━━━━━━━━━━━━━━━━━━━ 0s 64ms/step\n",
        "\n",
        "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79f0a07a40e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
        "\n",
        "5/5 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.81      0.90        79\n",
        "           1       0.83      1.00      0.91        74\n",
        "\n",
        "    accuracy                           0.90       153\n",
        "   macro avg       0.92      0.91      0.90       153\n",
        "weighted avg       0.92      0.90      0.90       153\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test_global, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(np.array(X_test_batch), np.array(y_test_batch), verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "Test Accuracy: 0.8769\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(np.array(X_test_batch), np.array(y_test_batch), verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "Test Accuracy: 0.8769\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(np.array(X_test_batch))\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(classification_report(y_test_batch, y_pred))\n",
        "\n",
        "3/3 ━━━━━━━━━━━━━━━━━━━━ 0s 11ms/step\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.78      0.88        36\n",
        "           1       0.78      1.00      0.88        29\n",
        "\n",
        "    accuracy                           0.88        65\n",
        "   macro avg       0.89      0.89      0.88        65\n",
        "weighted avg       0.90      0.88      0.88        65\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test_batch, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(np.array(X_test_batch))\n",
        "\n",
        "# Get FPR, TPR for different thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test_batch, y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # random guess line\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "test\n",
        "\n",
        "file6 = h5py.File(\"/content/drive/MyDrive/signal data/benign-single.h5\", \"r\")\n",
        "file7 = h5py.File(\"/content/drive/MyDrive/signal data/infected-single.h5\", \"r\")\n",
        "file8 = h5py.File(\"/content/drive/MyDrive/signal data/benign-gamesall.h5\", \"r\")\n",
        "file9 = h5py.File(\"/content/drive/MyDrive/signal data/infected-gamesall.h5\", \"r\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/nicv/(4096,2048).npy\"\n",
        "nicv_values = np.load(file_path)\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "file = file8\n",
        "keys =  list(file.keys())\n",
        "X_test_batch_gamesall = []\n",
        "y_test_batch_gamesall = []\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 1\n",
        "  data = file[name]\n",
        "\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_test_batch_gamesall.append(final_features)\n",
        "  y_test_batch_gamesall.append(label)\n",
        "\n",
        "\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py:108: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
        "\n",
        "X_test_batch = np.load(\"/content/drive/MyDrive/stft_data/X_batch(4096,2048)_test_noise.npy\", \"r\")\n",
        "y_test_batch = np.load(\"/content/drive/MyDrive/stft_data/y_batch(4096,2048)_test_noise.npy\", \"r\")\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(np.array(X_test_batch), np.array(y_test_batch), verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "Test Accuracy: 0.8800\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(np.array(X_test_batch))\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(classification_report(y_test_batch, y_pred))\n",
        "\n",
        "4/4 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      0.77      0.87        53\n",
        "           1       0.80      1.00      0.89        47\n",
        "\n",
        "    accuracy                           0.88       100\n",
        "   macro avg       0.90      0.89      0.88       100\n",
        "weighted avg       0.90      0.88      0.88       100\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test_batch, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = model.predict(np.array(X_test_batch))\n",
        "\n",
        "# Get FPR, TPR for different thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test_batch, y_pred_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')  # random guess line\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "file6 = h5py.File(\"/content/drive/MyDrive/signal data/benign-single.h5\", \"r\")\n",
        "file7 = h5py.File(\"/content/drive/MyDrive/signal data/infected-single.h5\", \"r\")\n",
        "file8 = h5py.File(\"/content/drive/MyDrive/signal data/benign-gamesall.h5\", \"r\")\n",
        "file9 = h5py.File(\"/content/drive/MyDrive/signal data/infected-gamesall.h5\", \"r\")\n",
        "\n",
        "infected gamesall\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/nicv/(4096,2048).npy\"\n",
        "nicv_values = np.load(file_path)\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "file = file6\n",
        "keys =  list(file.keys())\n",
        "X_test_batch_vm = []\n",
        "y_test_batch_vm = []\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 0\n",
        "  data = file[name]\n",
        "\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_test_batch_vm.append(final_features)\n",
        "  y_test_batch_vm.append(label)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(np.array(X_test_batch_vm))\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(classification_report(y_test_batch_vm, y_pred))\n",
        "cm = confusion_matrix(y_test_batch_vm, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/nicv/(4096,2048).npy\"\n",
        "nicv_values = np.load(file_path)\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "file = file7\n",
        "keys =  list(file.keys())\n",
        "X_test_batch_gamesall = []\n",
        "y_test_batch_gamesall = []\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 1\n",
        "  data = file[name]\n",
        "\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_test_batch_gamesall.append(final_features)\n",
        "  y_test_batch_gamesall.append(label)\n",
        "\n",
        "\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py:108: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(np.array(X_test_batch_gamesall))\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(classification_report(y_test_batch_gamesall, y_pred))\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "cm = confusion_matrix(y_test_batch_gamesall, y_pred)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/nicv/(4096,2048).npy\"\n",
        "nicv_values = np.load(file_path)\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "file = file8\n",
        "keys =  list(file.keys())\n",
        "X_test_batch_gamesall = []\n",
        "y_test_batch_gamesall = []\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 0\n",
        "  data = file[name]\n",
        "\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_test_batch_gamesall.append(final_features)\n",
        "  y_test_batch_gamesall.append(label)\n",
        "\n",
        "\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py:108: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(np.array(X_test_batch_gamesall))\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(classification_report(y_test_batch_gamesall, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test_batch_gamesall, y_pred)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/nicv/(4096,2048).npy\"\n",
        "nicv_values = np.load(file_path)\n",
        "\n",
        "nicv_scores = nicv_values\n",
        "n_components = 100\n",
        "file = file9\n",
        "keys =  list(file.keys())\n",
        "X_test_batch_gamesall = []\n",
        "y_test_batch_gamesall = []\n",
        "for name in keys:\n",
        "  data = []\n",
        "  label = 1\n",
        "  data = file[name]\n",
        "\n",
        "  data_tensor = tf.convert_to_tensor(data, dtype=tf.float32)\n",
        "  Zxx = tf.signal.stft(data_tensor, frame_length=4096, frame_step=2048, fft_length=4096)\n",
        "  magnitude = tf.abs(Zxx).numpy().reshape(Zxx.shape[0], -1)\n",
        "  selected_indices = np.argsort(nicv_scores)[-n_components:]\n",
        "  reduced_features = magnitude[:, selected_indices]\n",
        "  final_features = np.mean(reduced_features, axis=0)\n",
        "  X_test_batch_gamesall.append(final_features)\n",
        "  y_test_batch_gamesall.append(label)\n",
        "\n",
        "\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py:108: ComplexWarning: Casting complex values to real discards the imaginary part\n",
        "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
        "\n",
        "print(y_test_batch_gamesall)\n",
        "\n",
        "[1, 1, 1]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(np.array(X_test_batch_gamesall))\n",
        "y_pred = np.round(y_pred).flatten()\n",
        "print(classification_report(y_test_batch_gamesall, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test_batch_gamesall, y_pred)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "Colab paid products - Cancel contracts here\n",
        "\n",
        "\n",
        "# Create the new folder if it doesn't exist\n",
        "output_folder = \"/content/drive/MyDrive/spectrograms/test/0\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "keys = file2.keys()\n",
        "for key in list(keys)[3:9]:\n",
        "    try:\n",
        "        signal_data = add_gaussian_noise(file2[key])  # Load data\n",
        "        fig = plt.figure()\n",
        "        plt.psd(signal_data, NFFT=2048, Fc=12e6, Fs=20e6)\n",
        "        output_filename = os.path.join(output_folder, f\"z5noise-{key}.png\")\n",
        "        fig.savefig(output_filename, dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
        "        plt.close(fig)  # Close figure to release memory\n",
        "\n",
        "        print(f\"Spectrogram for {key} saved to {output_filename}\")\n",
        "\n",
        "        gc.collect()  # Trigger garbage collection\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing key {key}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy6FqhwFW0oG",
        "outputId": "086d8604-41d2-4c2e-c0b0-bf5a73dc54d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 459 images belonging to 2 classes.\n",
            "Found 50 images belonging to 2 classes.\n",
            "Epoch 1/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 4s/step - accuracy: 0.4901 - loss: 0.8003 - val_accuracy: 0.5000 - val_loss: 0.6951\n",
            "Epoch 2/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.4967 - loss: 0.7744 - val_accuracy: 0.5400 - val_loss: 0.6897\n",
            "Epoch 3/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 916ms/step - accuracy: 0.5047 - loss: 0.7498 - val_accuracy: 0.5000 - val_loss: 0.6904\n",
            "Epoch 4/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.5263 - loss: 0.7203 - val_accuracy: 0.5000 - val_loss: 0.6925\n",
            "Epoch 5/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 925ms/step - accuracy: 0.4924 - loss: 0.7313 - val_accuracy: 0.5000 - val_loss: 0.6918\n",
            "Epoch 6/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.4929 - loss: 0.7455 - val_accuracy: 0.5000 - val_loss: 0.6912\n",
            "Epoch 7/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 911ms/step - accuracy: 0.5060 - loss: 0.7400 - val_accuracy: 0.5000 - val_loss: 0.6921\n",
            "Epoch 8/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 911ms/step - accuracy: 0.5362 - loss: 0.7067 - val_accuracy: 0.5000 - val_loss: 0.6923\n",
            "Epoch 9/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 983ms/step - accuracy: 0.5246 - loss: 0.7027 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 10/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 916ms/step - accuracy: 0.4471 - loss: 0.7263 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 11/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 933ms/step - accuracy: 0.5205 - loss: 0.7070 - val_accuracy: 0.5000 - val_loss: 0.6919\n",
            "Epoch 12/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.4719 - loss: 0.7200 - val_accuracy: 0.5000 - val_loss: 0.6903\n",
            "Epoch 13/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.4549 - loss: 0.7391 - val_accuracy: 0.5000 - val_loss: 0.6915\n",
            "Epoch 14/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.4815 - loss: 0.7309 - val_accuracy: 0.5000 - val_loss: 0.6904\n",
            "Epoch 15/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.5016 - loss: 0.7105 - val_accuracy: 0.5000 - val_loss: 0.6913\n",
            "Epoch 16/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 919ms/step - accuracy: 0.5149 - loss: 0.7150 - val_accuracy: 0.5000 - val_loss: 0.6900\n",
            "Epoch 17/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.4629 - loss: 0.7294 - val_accuracy: 0.5000 - val_loss: 0.6910\n",
            "Epoch 18/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 900ms/step - accuracy: 0.5172 - loss: 0.6890 - val_accuracy: 0.5000 - val_loss: 0.6897\n",
            "Epoch 19/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 918ms/step - accuracy: 0.4831 - loss: 0.7052 - val_accuracy: 0.5400 - val_loss: 0.6892\n",
            "Epoch 20/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.5162 - loss: 0.7149 - val_accuracy: 0.5000 - val_loss: 0.6895\n",
            "Epoch 21/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 990ms/step - accuracy: 0.4497 - loss: 0.7284 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 22/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 917ms/step - accuracy: 0.4845 - loss: 0.7072 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 23/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.4886 - loss: 0.7092 - val_accuracy: 0.5000 - val_loss: 0.6897\n",
            "Epoch 24/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.4774 - loss: 0.7240 - val_accuracy: 0.5000 - val_loss: 0.6899\n",
            "Epoch 25/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.5329 - loss: 0.7045 - val_accuracy: 0.5000 - val_loss: 0.6904\n",
            "Epoch 26/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 909ms/step - accuracy: 0.5030 - loss: 0.7140 - val_accuracy: 0.5000 - val_loss: 0.6902\n",
            "Epoch 27/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.5180 - loss: 0.6917 - val_accuracy: 0.5000 - val_loss: 0.6906\n",
            "Epoch 28/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.5740 - loss: 0.6794 - val_accuracy: 0.5400 - val_loss: 0.6890\n",
            "Epoch 29/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.5232 - loss: 0.6977 - val_accuracy: 0.5000 - val_loss: 0.6893\n",
            "Epoch 30/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 910ms/step - accuracy: 0.5284 - loss: 0.6914 - val_accuracy: 0.5000 - val_loss: 0.6891\n",
            "Epoch 31/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.4878 - loss: 0.7012 - val_accuracy: 0.5000 - val_loss: 0.6900\n",
            "Epoch 32/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.4966 - loss: 0.6967 - val_accuracy: 0.5000 - val_loss: 0.6902\n",
            "Epoch 33/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.5163 - loss: 0.7034 - val_accuracy: 0.5000 - val_loss: 0.6893\n",
            "Epoch 34/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 907ms/step - accuracy: 0.5398 - loss: 0.6975 - val_accuracy: 0.5000 - val_loss: 0.6892\n",
            "Epoch 35/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 911ms/step - accuracy: 0.5408 - loss: 0.7047 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 36/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 924ms/step - accuracy: 0.4881 - loss: 0.7022 - val_accuracy: 0.5800 - val_loss: 0.6887\n",
            "Epoch 37/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.5485 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6892\n",
            "Epoch 38/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 907ms/step - accuracy: 0.4414 - loss: 0.7196 - val_accuracy: 0.5000 - val_loss: 0.6893\n",
            "Epoch 39/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 922ms/step - accuracy: 0.4249 - loss: 0.7288 - val_accuracy: 0.5000 - val_loss: 0.6892\n",
            "Epoch 40/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 942ms/step - accuracy: 0.5344 - loss: 0.6976 - val_accuracy: 0.5000 - val_loss: 0.6895\n",
            "Epoch 41/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.5167 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6901\n",
            "Epoch 42/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.4557 - loss: 0.7164 - val_accuracy: 0.5000 - val_loss: 0.6890\n",
            "Epoch 43/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.5472 - loss: 0.6904 - val_accuracy: 0.5000 - val_loss: 0.6894\n",
            "Epoch 44/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.5608 - loss: 0.6945 - val_accuracy: 0.5000 - val_loss: 0.6911\n",
            "Epoch 45/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.5173 - loss: 0.7003 - val_accuracy: 0.5000 - val_loss: 0.6888\n",
            "Epoch 46/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 911ms/step - accuracy: 0.5184 - loss: 0.6987 - val_accuracy: 0.5000 - val_loss: 0.6895\n",
            "Epoch 47/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.5507 - loss: 0.6877 - val_accuracy: 0.5000 - val_loss: 0.6887\n",
            "Epoch 48/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.5273 - loss: 0.7095 - val_accuracy: 0.5000 - val_loss: 0.6894\n",
            "Epoch 49/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.5153 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6897\n",
            "Epoch 50/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.5060 - loss: 0.7063 - val_accuracy: 0.5000 - val_loss: 0.6892\n",
            "Epoch 51/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.4908 - loss: 0.7180 - val_accuracy: 0.5000 - val_loss: 0.6892\n",
            "Epoch 52/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.5019 - loss: 0.7038 - val_accuracy: 0.5400 - val_loss: 0.6885\n",
            "Epoch 53/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.5382 - loss: 0.6861 - val_accuracy: 0.5400 - val_loss: 0.6883\n",
            "Epoch 54/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 935ms/step - accuracy: 0.5203 - loss: 0.6996 - val_accuracy: 0.5000 - val_loss: 0.6891\n",
            "Epoch 55/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.4868 - loss: 0.7002 - val_accuracy: 0.5000 - val_loss: 0.6898\n",
            "Epoch 56/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.5242 - loss: 0.6906 - val_accuracy: 0.5000 - val_loss: 0.6893\n",
            "Epoch 57/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 951ms/step - accuracy: 0.4744 - loss: 0.7065 - val_accuracy: 0.5000 - val_loss: 0.6902\n",
            "Epoch 58/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 933ms/step - accuracy: 0.5764 - loss: 0.6857 - val_accuracy: 0.5000 - val_loss: 0.6904\n",
            "Epoch 59/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.4625 - loss: 0.7124 - val_accuracy: 0.5000 - val_loss: 0.6903\n",
            "Epoch 60/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 930ms/step - accuracy: 0.5449 - loss: 0.7010 - val_accuracy: 0.5000 - val_loss: 0.6901\n",
            "Epoch 61/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 950ms/step - accuracy: 0.4890 - loss: 0.7000 - val_accuracy: 0.5000 - val_loss: 0.6894\n",
            "Epoch 62/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 960ms/step - accuracy: 0.5696 - loss: 0.6891 - val_accuracy: 0.5000 - val_loss: 0.6889\n",
            "Epoch 63/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.5413 - loss: 0.6882 - val_accuracy: 0.5000 - val_loss: 0.6895\n",
            "Epoch 64/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.4597 - loss: 0.7148 - val_accuracy: 0.5000 - val_loss: 0.6889\n",
            "Epoch 65/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.5354 - loss: 0.6952 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 66/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 960ms/step - accuracy: 0.5175 - loss: 0.6991 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 67/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.5707 - loss: 0.6819 - val_accuracy: 0.5000 - val_loss: 0.6901\n",
            "Epoch 68/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.4684 - loss: 0.7141 - val_accuracy: 0.5000 - val_loss: 0.6891\n",
            "Epoch 69/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.5469 - loss: 0.6842 - val_accuracy: 0.5000 - val_loss: 0.6898\n",
            "Epoch 70/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 925ms/step - accuracy: 0.4612 - loss: 0.7214 - val_accuracy: 0.5000 - val_loss: 0.6904\n",
            "Epoch 71/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 950ms/step - accuracy: 0.5215 - loss: 0.7015 - val_accuracy: 0.5000 - val_loss: 0.6899\n",
            "Epoch 72/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.4859 - loss: 0.6945 - val_accuracy: 0.5000 - val_loss: 0.6914\n",
            "Epoch 73/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.4775 - loss: 0.7064 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 74/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 913ms/step - accuracy: 0.5443 - loss: 0.6910 - val_accuracy: 0.5000 - val_loss: 0.6902\n",
            "Epoch 75/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.4958 - loss: 0.6998 - val_accuracy: 0.5000 - val_loss: 0.6899\n",
            "Epoch 76/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.5017 - loss: 0.6888 - val_accuracy: 0.5000 - val_loss: 0.6902\n",
            "Epoch 77/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.4820 - loss: 0.7058 - val_accuracy: 0.5000 - val_loss: 0.6901\n",
            "Epoch 78/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 909ms/step - accuracy: 0.4947 - loss: 0.7108 - val_accuracy: 0.5000 - val_loss: 0.6901\n",
            "Epoch 79/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 913ms/step - accuracy: 0.4970 - loss: 0.6993 - val_accuracy: 0.5000 - val_loss: 0.6916\n",
            "Epoch 80/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.4177 - loss: 0.7172 - val_accuracy: 0.5000 - val_loss: 0.6911\n",
            "Epoch 81/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.4683 - loss: 0.7094 - val_accuracy: 0.5000 - val_loss: 0.6917\n",
            "Epoch 82/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 912ms/step - accuracy: 0.5104 - loss: 0.7008 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 83/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.5202 - loss: 0.6895 - val_accuracy: 0.5000 - val_loss: 0.6892\n",
            "Epoch 84/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.5609 - loss: 0.6843 - val_accuracy: 0.5000 - val_loss: 0.6899\n",
            "Epoch 85/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.5026 - loss: 0.7039 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 86/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.5262 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6896\n",
            "Epoch 87/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.5493 - loss: 0.6843 - val_accuracy: 0.5000 - val_loss: 0.6887\n",
            "Epoch 88/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.4891 - loss: 0.6948 - val_accuracy: 0.5000 - val_loss: 0.6888\n",
            "Epoch 89/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.5369 - loss: 0.6877 - val_accuracy: 0.5000 - val_loss: 0.6897\n",
            "Epoch 90/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 901ms/step - accuracy: 0.5091 - loss: 0.6918 - val_accuracy: 0.5000 - val_loss: 0.6910\n",
            "Epoch 91/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.4820 - loss: 0.7107 - val_accuracy: 0.5000 - val_loss: 0.6885\n",
            "Epoch 92/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.4777 - loss: 0.7153 - val_accuracy: 0.5000 - val_loss: 0.6890\n",
            "Epoch 93/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.4884 - loss: 0.7059 - val_accuracy: 0.5000 - val_loss: 0.6899\n",
            "Epoch 94/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 913ms/step - accuracy: 0.5263 - loss: 0.7049 - val_accuracy: 0.5000 - val_loss: 0.6900\n",
            "Epoch 95/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.4976 - loss: 0.7105 - val_accuracy: 0.5000 - val_loss: 0.6918\n",
            "Epoch 96/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.5140 - loss: 0.6987 - val_accuracy: 0.5000 - val_loss: 0.6923\n",
            "Epoch 97/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.5166 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6911\n",
            "Epoch 98/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.4926 - loss: 0.7026 - val_accuracy: 0.5000 - val_loss: 0.6904\n",
            "Epoch 99/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.5837 - loss: 0.6788 - val_accuracy: 0.5000 - val_loss: 0.6920\n",
            "Epoch 100/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.4907 - loss: 0.7094 - val_accuracy: 0.5000 - val_loss: 0.6912\n",
            "Epoch 1/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - accuracy: 0.5241 - loss: 0.7229 - val_accuracy: 0.5000 - val_loss: 0.7016\n",
            "Epoch 2/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 964ms/step - accuracy: 0.5196 - loss: 0.7228 - val_accuracy: 0.5000 - val_loss: 0.7142\n",
            "Epoch 3/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.5607 - loss: 0.6750 - val_accuracy: 0.5000 - val_loss: 0.7046\n",
            "Epoch 4/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 981ms/step - accuracy: 0.5422 - loss: 0.6753 - val_accuracy: 0.5000 - val_loss: 0.6961\n",
            "Epoch 5/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 983ms/step - accuracy: 0.5481 - loss: 0.7009 - val_accuracy: 0.5000 - val_loss: 0.6988\n",
            "Epoch 6/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.5891 - loss: 0.6637 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 7/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.5511 - loss: 0.6822 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 8/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.5492 - loss: 0.7370 - val_accuracy: 0.5000 - val_loss: 0.6868\n",
            "Epoch 9/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.5319 - loss: 0.7021 - val_accuracy: 0.5400 - val_loss: 0.6850\n",
            "Epoch 10/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 957ms/step - accuracy: 0.5792 - loss: 0.6497 - val_accuracy: 0.5400 - val_loss: 0.6921\n",
            "Epoch 11/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.5937 - loss: 0.6960 - val_accuracy: 0.5400 - val_loss: 0.6831\n",
            "Epoch 12/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.6683 - loss: 0.6503 - val_accuracy: 0.5400 - val_loss: 0.6774\n",
            "Epoch 13/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.6486 - loss: 0.6319 - val_accuracy: 0.5400 - val_loss: 0.6635\n",
            "Epoch 14/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 966ms/step - accuracy: 0.5728 - loss: 0.6394 - val_accuracy: 0.5400 - val_loss: 0.6730\n",
            "Epoch 15/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.6173 - loss: 0.6432 - val_accuracy: 0.5800 - val_loss: 0.6519\n",
            "Epoch 16/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.6258 - loss: 0.6390 - val_accuracy: 0.5400 - val_loss: 0.6800\n",
            "Epoch 17/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 993ms/step - accuracy: 0.6417 - loss: 0.6372 - val_accuracy: 0.6400 - val_loss: 0.6395\n",
            "Epoch 18/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.6571 - loss: 0.5978 - val_accuracy: 0.5400 - val_loss: 0.6698\n",
            "Epoch 19/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 971ms/step - accuracy: 0.6774 - loss: 0.5737 - val_accuracy: 0.8000 - val_loss: 0.6156\n",
            "Epoch 20/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 932ms/step - accuracy: 0.6371 - loss: 0.6286 - val_accuracy: 0.6800 - val_loss: 0.6238\n",
            "Epoch 21/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.6644 - loss: 0.6187 - val_accuracy: 0.5400 - val_loss: 0.6487\n",
            "Epoch 22/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 952ms/step - accuracy: 0.6711 - loss: 0.5958 - val_accuracy: 0.7400 - val_loss: 0.6228\n",
            "Epoch 23/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 907ms/step - accuracy: 0.6778 - loss: 0.6001 - val_accuracy: 0.6400 - val_loss: 0.6353\n",
            "Epoch 24/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 983ms/step - accuracy: 0.6909 - loss: 0.5832 - val_accuracy: 0.7800 - val_loss: 0.5923\n",
            "Epoch 25/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 921ms/step - accuracy: 0.6639 - loss: 0.6061 - val_accuracy: 0.5000 - val_loss: 0.6229\n",
            "Epoch 26/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 988ms/step - accuracy: 0.7064 - loss: 0.5859 - val_accuracy: 0.7800 - val_loss: 0.5866\n",
            "Epoch 27/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 961ms/step - accuracy: 0.6930 - loss: 0.5995 - val_accuracy: 0.5000 - val_loss: 0.7500\n",
            "Epoch 28/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 985ms/step - accuracy: 0.6479 - loss: 0.6054 - val_accuracy: 0.7800 - val_loss: 0.5401\n",
            "Epoch 29/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.7601 - loss: 0.5240 - val_accuracy: 0.7400 - val_loss: 0.5187\n",
            "Epoch 30/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.6703 - loss: 0.5929 - val_accuracy: 0.7400 - val_loss: 0.5169\n",
            "Epoch 31/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 988ms/step - accuracy: 0.6916 - loss: 0.5737 - val_accuracy: 0.7000 - val_loss: 0.5726\n",
            "Epoch 32/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.6953 - loss: 0.5707 - val_accuracy: 0.9200 - val_loss: 0.4853\n",
            "Epoch 33/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.7461 - loss: 0.5366 - val_accuracy: 0.9000 - val_loss: 0.3910\n",
            "Epoch 34/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.7587 - loss: 0.5225 - val_accuracy: 0.9000 - val_loss: 0.3860\n",
            "Epoch 35/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.7622 - loss: 0.5084 - val_accuracy: 0.8800 - val_loss: 0.3734\n",
            "Epoch 36/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 961ms/step - accuracy: 0.7479 - loss: 0.5258 - val_accuracy: 0.6800 - val_loss: 0.7158\n",
            "Epoch 37/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.8125 - loss: 0.4196 - val_accuracy: 0.8000 - val_loss: 0.4027\n",
            "Epoch 38/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.7349 - loss: 0.5323 - val_accuracy: 0.6200 - val_loss: 0.7385\n",
            "Epoch 39/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.7544 - loss: 0.5123 - val_accuracy: 0.7400 - val_loss: 0.4464\n",
            "Epoch 40/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.7023 - loss: 0.5533 - val_accuracy: 0.7600 - val_loss: 0.4309\n",
            "Epoch 41/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.7504 - loss: 0.5114 - val_accuracy: 0.5800 - val_loss: 0.7958\n",
            "Epoch 42/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.7634 - loss: 0.4595 - val_accuracy: 0.7200 - val_loss: 0.5089\n",
            "Epoch 43/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 959ms/step - accuracy: 0.7506 - loss: 0.4997 - val_accuracy: 0.7000 - val_loss: 0.6749\n",
            "Epoch 44/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 958ms/step - accuracy: 0.7816 - loss: 0.4776 - val_accuracy: 0.6600 - val_loss: 0.7723\n",
            "Epoch 45/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 974ms/step - accuracy: 0.7347 - loss: 0.5523 - val_accuracy: 0.5400 - val_loss: 1.1206\n",
            "Epoch 46/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.7431 - loss: 0.5338 - val_accuracy: 0.7000 - val_loss: 0.5548\n",
            "Epoch 47/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 942ms/step - accuracy: 0.7783 - loss: 0.4629 - val_accuracy: 0.7000 - val_loss: 0.6750\n",
            "Epoch 48/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 988ms/step - accuracy: 0.7704 - loss: 0.5168 - val_accuracy: 0.8200 - val_loss: 0.3369\n",
            "Epoch 49/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.7683 - loss: 0.4598 - val_accuracy: 0.7200 - val_loss: 0.5609\n",
            "Epoch 50/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 990ms/step - accuracy: 0.7126 - loss: 0.5283 - val_accuracy: 0.8000 - val_loss: 0.3367\n",
            "Epoch 51/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8120 - loss: 0.4394 - val_accuracy: 0.8400 - val_loss: 0.2881\n",
            "Epoch 52/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.7926 - loss: 0.4714 - val_accuracy: 0.7000 - val_loss: 0.7277\n",
            "Epoch 53/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.7762 - loss: 0.4637 - val_accuracy: 0.7200 - val_loss: 0.4619\n",
            "Epoch 54/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.7814 - loss: 0.4558 - val_accuracy: 0.7000 - val_loss: 0.6177\n",
            "Epoch 55/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.7701 - loss: 0.4887 - val_accuracy: 0.7000 - val_loss: 0.7177\n",
            "Epoch 56/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 952ms/step - accuracy: 0.7728 - loss: 0.4758 - val_accuracy: 0.7400 - val_loss: 0.4174\n",
            "Epoch 57/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8058 - loss: 0.4882 - val_accuracy: 0.7400 - val_loss: 0.4341\n",
            "Epoch 58/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.7959 - loss: 0.4588 - val_accuracy: 0.8400 - val_loss: 0.3334\n",
            "Epoch 59/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.7846 - loss: 0.4484 - val_accuracy: 0.7000 - val_loss: 0.6156\n",
            "Epoch 60/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 971ms/step - accuracy: 0.8083 - loss: 0.4261 - val_accuracy: 0.8400 - val_loss: 0.3039\n",
            "Epoch 61/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.7797 - loss: 0.4740 - val_accuracy: 0.8000 - val_loss: 0.3488\n",
            "Epoch 62/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 915ms/step - accuracy: 0.8103 - loss: 0.4262 - val_accuracy: 0.8000 - val_loss: 0.3617\n",
            "Epoch 63/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 948ms/step - accuracy: 0.7845 - loss: 0.4388 - val_accuracy: 0.6800 - val_loss: 0.8479\n",
            "Epoch 64/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 983ms/step - accuracy: 0.7890 - loss: 0.4590 - val_accuracy: 0.8200 - val_loss: 0.3298\n",
            "Epoch 65/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.7859 - loss: 0.4421 - val_accuracy: 0.7000 - val_loss: 0.7220\n",
            "Epoch 66/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 927ms/step - accuracy: 0.8013 - loss: 0.4585 - val_accuracy: 0.7200 - val_loss: 0.6377\n",
            "Epoch 67/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.8296 - loss: 0.4281 - val_accuracy: 0.7400 - val_loss: 0.5325\n",
            "Epoch 68/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 988ms/step - accuracy: 0.8218 - loss: 0.4009 - val_accuracy: 0.7200 - val_loss: 0.6412\n",
            "Epoch 69/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.8394 - loss: 0.3891 - val_accuracy: 0.7000 - val_loss: 0.9234\n",
            "Epoch 70/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.7906 - loss: 0.4510 - val_accuracy: 0.7200 - val_loss: 0.6033\n",
            "Epoch 71/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 980ms/step - accuracy: 0.8038 - loss: 0.4273 - val_accuracy: 0.7200 - val_loss: 0.6421\n",
            "Epoch 72/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 987ms/step - accuracy: 0.8133 - loss: 0.4169 - val_accuracy: 0.7400 - val_loss: 0.4495\n",
            "Epoch 73/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.8029 - loss: 0.4289 - val_accuracy: 0.7400 - val_loss: 0.6499\n",
            "Epoch 74/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 916ms/step - accuracy: 0.8318 - loss: 0.4199 - val_accuracy: 0.7000 - val_loss: 0.9073\n",
            "Epoch 75/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 942ms/step - accuracy: 0.8165 - loss: 0.4030 - val_accuracy: 0.7800 - val_loss: 0.4159\n",
            "Epoch 76/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.7872 - loss: 0.4522 - val_accuracy: 0.8200 - val_loss: 0.3428\n",
            "Epoch 77/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.8019 - loss: 0.4286 - val_accuracy: 0.7400 - val_loss: 0.5234\n",
            "Epoch 78/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 974ms/step - accuracy: 0.7981 - loss: 0.4379 - val_accuracy: 0.9000 - val_loss: 0.2227\n",
            "Epoch 79/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 949ms/step - accuracy: 0.8076 - loss: 0.4390 - val_accuracy: 0.8400 - val_loss: 0.2786\n",
            "Epoch 80/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 974ms/step - accuracy: 0.7473 - loss: 0.4659 - val_accuracy: 0.7400 - val_loss: 0.5907\n",
            "Epoch 81/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 933ms/step - accuracy: 0.8240 - loss: 0.4072 - val_accuracy: 0.7200 - val_loss: 0.7422\n",
            "Epoch 82/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 912ms/step - accuracy: 0.8099 - loss: 0.4144 - val_accuracy: 0.7400 - val_loss: 0.5891\n",
            "Epoch 83/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8102 - loss: 0.4209 - val_accuracy: 0.7000 - val_loss: 0.9177\n",
            "Epoch 84/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 960ms/step - accuracy: 0.8112 - loss: 0.4331 - val_accuracy: 0.7400 - val_loss: 0.6189\n",
            "Epoch 85/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 965ms/step - accuracy: 0.8292 - loss: 0.4078 - val_accuracy: 0.7400 - val_loss: 0.7151\n",
            "Epoch 86/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.7787 - loss: 0.4493 - val_accuracy: 0.8400 - val_loss: 0.3423\n",
            "Epoch 87/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 982ms/step - accuracy: 0.8021 - loss: 0.4050 - val_accuracy: 0.7400 - val_loss: 0.4724\n",
            "Epoch 88/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 960ms/step - accuracy: 0.7823 - loss: 0.4796 - val_accuracy: 0.7400 - val_loss: 0.7569\n",
            "Epoch 89/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 965ms/step - accuracy: 0.8333 - loss: 0.4009 - val_accuracy: 0.7000 - val_loss: 0.8637\n",
            "Epoch 90/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 941ms/step - accuracy: 0.7997 - loss: 0.4239 - val_accuracy: 0.7200 - val_loss: 0.9023\n",
            "Epoch 91/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 955ms/step - accuracy: 0.7737 - loss: 0.5060 - val_accuracy: 0.7400 - val_loss: 0.5569\n",
            "Epoch 92/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.8550 - loss: 0.3712 - val_accuracy: 0.7400 - val_loss: 0.6598\n",
            "Epoch 93/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 952ms/step - accuracy: 0.8184 - loss: 0.3991 - val_accuracy: 0.7400 - val_loss: 0.4830\n",
            "Epoch 94/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.8199 - loss: 0.4183 - val_accuracy: 0.8000 - val_loss: 0.3811\n",
            "Epoch 95/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 969ms/step - accuracy: 0.8344 - loss: 0.3949 - val_accuracy: 0.7400 - val_loss: 0.5673\n",
            "Epoch 96/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 996ms/step - accuracy: 0.8437 - loss: 0.3681 - val_accuracy: 0.8400 - val_loss: 0.2956\n",
            "Epoch 97/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.8355 - loss: 0.3687 - val_accuracy: 0.7400 - val_loss: 0.7727\n",
            "Epoch 98/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 948ms/step - accuracy: 0.7915 - loss: 0.4306 - val_accuracy: 0.7200 - val_loss: 0.6671\n",
            "Epoch 99/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 972ms/step - accuracy: 0.8229 - loss: 0.3987 - val_accuracy: 0.7400 - val_loss: 0.4887\n",
            "Epoch 100/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 974ms/step - accuracy: 0.8432 - loss: 0.3642 - val_accuracy: 0.7000 - val_loss: 0.8937\n",
            "Epoch 101/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.7924 - loss: 0.4401 - val_accuracy: 0.6800 - val_loss: 1.1061\n",
            "Epoch 102/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 942ms/step - accuracy: 0.8052 - loss: 0.4173 - val_accuracy: 0.7000 - val_loss: 0.8528\n",
            "Epoch 103/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 961ms/step - accuracy: 0.8254 - loss: 0.3925 - val_accuracy: 0.7400 - val_loss: 0.6124\n",
            "Epoch 104/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.8667 - loss: 0.3537 - val_accuracy: 0.7400 - val_loss: 0.5637\n",
            "Epoch 105/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 964ms/step - accuracy: 0.8418 - loss: 0.3569 - val_accuracy: 0.7400 - val_loss: 0.6096\n",
            "Epoch 106/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 949ms/step - accuracy: 0.8504 - loss: 0.3697 - val_accuracy: 0.7400 - val_loss: 0.6007\n",
            "Epoch 107/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 963ms/step - accuracy: 0.8253 - loss: 0.3613 - val_accuracy: 0.7400 - val_loss: 0.7053\n",
            "Epoch 108/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 981ms/step - accuracy: 0.7811 - loss: 0.4528 - val_accuracy: 0.8600 - val_loss: 0.2628\n",
            "Epoch 109/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.8377 - loss: 0.3963 - val_accuracy: 0.8000 - val_loss: 0.3916\n",
            "Epoch 110/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8826 - loss: 0.3275 - val_accuracy: 0.7600 - val_loss: 0.5967\n",
            "Epoch 111/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.8466 - loss: 0.3421 - val_accuracy: 0.7000 - val_loss: 1.2213\n",
            "Epoch 112/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 963ms/step - accuracy: 0.8563 - loss: 0.3323 - val_accuracy: 0.7600 - val_loss: 0.5166\n",
            "Epoch 113/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.8533 - loss: 0.3314 - val_accuracy: 0.7800 - val_loss: 0.4413\n",
            "Epoch 114/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.8528 - loss: 0.3702 - val_accuracy: 0.7400 - val_loss: 0.5189\n",
            "Epoch 115/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 939ms/step - accuracy: 0.8339 - loss: 0.3373 - val_accuracy: 0.7600 - val_loss: 0.4623\n",
            "Epoch 116/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.7947 - loss: 0.4124 - val_accuracy: 0.6800 - val_loss: 1.1238\n",
            "Epoch 117/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.8213 - loss: 0.4177 - val_accuracy: 0.7600 - val_loss: 0.4456\n",
            "Epoch 118/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.8209 - loss: 0.4264 - val_accuracy: 0.7400 - val_loss: 0.5395\n",
            "Epoch 119/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.8324 - loss: 0.3606 - val_accuracy: 0.7400 - val_loss: 0.5131\n",
            "Epoch 120/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 951ms/step - accuracy: 0.8360 - loss: 0.3681 - val_accuracy: 0.7200 - val_loss: 0.6256\n",
            "Epoch 121/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.8311 - loss: 0.3480 - val_accuracy: 0.8400 - val_loss: 0.2854\n",
            "Epoch 122/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.8399 - loss: 0.3793 - val_accuracy: 0.7200 - val_loss: 0.5136\n",
            "Epoch 123/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 932ms/step - accuracy: 0.8637 - loss: 0.3052 - val_accuracy: 0.8000 - val_loss: 0.3285\n",
            "Epoch 124/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.8755 - loss: 0.3039 - val_accuracy: 0.7400 - val_loss: 0.5186\n",
            "Epoch 125/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.8631 - loss: 0.3477 - val_accuracy: 0.8400 - val_loss: 0.2808\n",
            "Epoch 126/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.8395 - loss: 0.3715 - val_accuracy: 0.7600 - val_loss: 0.4655\n",
            "Epoch 127/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 931ms/step - accuracy: 0.8189 - loss: 0.3600 - val_accuracy: 0.7400 - val_loss: 0.6504\n",
            "Epoch 128/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 949ms/step - accuracy: 0.8661 - loss: 0.3145 - val_accuracy: 0.7000 - val_loss: 1.0559\n",
            "Epoch 129/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 946ms/step - accuracy: 0.8258 - loss: 0.3741 - val_accuracy: 0.7400 - val_loss: 0.6102\n",
            "Epoch 130/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.8562 - loss: 0.3571 - val_accuracy: 0.7400 - val_loss: 0.6350\n",
            "Epoch 131/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 935ms/step - accuracy: 0.8538 - loss: 0.3220 - val_accuracy: 0.7400 - val_loss: 0.6820\n",
            "Epoch 132/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 989ms/step - accuracy: 0.8393 - loss: 0.3451 - val_accuracy: 0.7400 - val_loss: 0.5657\n",
            "Epoch 133/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.8060 - loss: 0.4059 - val_accuracy: 0.8200 - val_loss: 0.3494\n",
            "Epoch 134/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.8604 - loss: 0.3549 - val_accuracy: 0.8000 - val_loss: 0.4118\n",
            "Epoch 135/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 931ms/step - accuracy: 0.8132 - loss: 0.4084 - val_accuracy: 0.7000 - val_loss: 0.7988\n",
            "Epoch 136/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8456 - loss: 0.3763 - val_accuracy: 0.7800 - val_loss: 0.3825\n",
            "Epoch 137/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.8589 - loss: 0.3406 - val_accuracy: 0.6800 - val_loss: 0.8235\n",
            "Epoch 138/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 933ms/step - accuracy: 0.8591 - loss: 0.3397 - val_accuracy: 0.7000 - val_loss: 0.6267\n",
            "Epoch 139/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 928ms/step - accuracy: 0.8495 - loss: 0.3516 - val_accuracy: 0.7800 - val_loss: 0.4327\n",
            "Epoch 140/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 956ms/step - accuracy: 0.8417 - loss: 0.3470 - val_accuracy: 0.7400 - val_loss: 0.5911\n",
            "Epoch 141/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.8764 - loss: 0.3471 - val_accuracy: 0.7600 - val_loss: 0.4554\n",
            "Epoch 142/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.8369 - loss: 0.3760 - val_accuracy: 0.7600 - val_loss: 0.3978\n",
            "Epoch 143/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.8457 - loss: 0.3481 - val_accuracy: 0.7400 - val_loss: 0.5512\n",
            "Epoch 144/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.8117 - loss: 0.4231 - val_accuracy: 0.7400 - val_loss: 0.4727\n",
            "Epoch 145/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.8202 - loss: 0.3922 - val_accuracy: 0.7200 - val_loss: 0.7705\n",
            "Epoch 146/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.8624 - loss: 0.3189 - val_accuracy: 0.7600 - val_loss: 0.4758\n",
            "Epoch 147/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.8626 - loss: 0.3283 - val_accuracy: 0.7400 - val_loss: 0.5567\n",
            "Epoch 148/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 958ms/step - accuracy: 0.8493 - loss: 0.3481 - val_accuracy: 0.8000 - val_loss: 0.3903\n",
            "Epoch 149/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.8704 - loss: 0.3076 - val_accuracy: 0.8600 - val_loss: 0.2345\n",
            "Epoch 150/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 921ms/step - accuracy: 0.8225 - loss: 0.3790 - val_accuracy: 0.7400 - val_loss: 0.6302\n",
            "Epoch 151/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.8565 - loss: 0.2941 - val_accuracy: 0.7600 - val_loss: 0.5686\n",
            "Epoch 152/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 969ms/step - accuracy: 0.8400 - loss: 0.3418 - val_accuracy: 0.7400 - val_loss: 0.5715\n",
            "Epoch 153/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.8811 - loss: 0.3194 - val_accuracy: 0.8400 - val_loss: 0.2719\n",
            "Epoch 154/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.8646 - loss: 0.2995 - val_accuracy: 0.7400 - val_loss: 0.7534\n",
            "Epoch 155/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 938ms/step - accuracy: 0.8500 - loss: 0.3610 - val_accuracy: 0.7400 - val_loss: 0.6793\n",
            "Epoch 156/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.8749 - loss: 0.3361 - val_accuracy: 0.7800 - val_loss: 0.4750\n",
            "Epoch 157/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.8374 - loss: 0.3902 - val_accuracy: 0.7200 - val_loss: 0.7944\n",
            "Epoch 158/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.8700 - loss: 0.2959 - val_accuracy: 0.6800 - val_loss: 0.9613\n",
            "Epoch 159/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 925ms/step - accuracy: 0.8439 - loss: 0.3386 - val_accuracy: 0.6800 - val_loss: 0.7816\n",
            "Epoch 160/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.8436 - loss: 0.3318 - val_accuracy: 0.6800 - val_loss: 0.9310\n",
            "Epoch 161/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.8603 - loss: 0.3129 - val_accuracy: 0.6800 - val_loss: 1.0418\n",
            "Epoch 162/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.8468 - loss: 0.3452 - val_accuracy: 0.7400 - val_loss: 0.9122\n",
            "Epoch 163/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 932ms/step - accuracy: 0.8715 - loss: 0.3092 - val_accuracy: 0.7400 - val_loss: 0.6449\n",
            "Epoch 164/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 948ms/step - accuracy: 0.8524 - loss: 0.3253 - val_accuracy: 0.7200 - val_loss: 0.7760\n",
            "Epoch 165/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 917ms/step - accuracy: 0.8188 - loss: 0.3733 - val_accuracy: 0.7400 - val_loss: 0.5330\n",
            "Epoch 166/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.8369 - loss: 0.3549 - val_accuracy: 0.7000 - val_loss: 0.7499\n",
            "Epoch 167/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 933ms/step - accuracy: 0.9059 - loss: 0.2527 - val_accuracy: 0.7400 - val_loss: 0.5641\n",
            "Epoch 168/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 951ms/step - accuracy: 0.8598 - loss: 0.3205 - val_accuracy: 0.7800 - val_loss: 0.3424\n",
            "Epoch 169/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 915ms/step - accuracy: 0.8634 - loss: 0.2857 - val_accuracy: 0.7600 - val_loss: 0.4328\n",
            "Epoch 170/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 910ms/step - accuracy: 0.8594 - loss: 0.3623 - val_accuracy: 0.7400 - val_loss: 0.6600\n",
            "Epoch 171/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.8427 - loss: 0.3547 - val_accuracy: 0.7400 - val_loss: 0.5404\n",
            "Epoch 172/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 949ms/step - accuracy: 0.8798 - loss: 0.3013 - val_accuracy: 0.7600 - val_loss: 0.3818\n",
            "Epoch 173/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 921ms/step - accuracy: 0.8823 - loss: 0.3006 - val_accuracy: 0.7400 - val_loss: 0.5209\n",
            "Epoch 174/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.8524 - loss: 0.3319 - val_accuracy: 0.7800 - val_loss: 0.3361\n",
            "Epoch 175/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.8522 - loss: 0.3183 - val_accuracy: 0.7400 - val_loss: 0.4381\n",
            "Epoch 176/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.8678 - loss: 0.3127 - val_accuracy: 0.7400 - val_loss: 0.5173\n",
            "Epoch 177/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.8571 - loss: 0.2969 - val_accuracy: 0.7600 - val_loss: 0.4456\n",
            "Epoch 178/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 935ms/step - accuracy: 0.8427 - loss: 0.3408 - val_accuracy: 0.7200 - val_loss: 0.4988\n",
            "Epoch 179/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 922ms/step - accuracy: 0.8507 - loss: 0.3335 - val_accuracy: 0.7600 - val_loss: 0.4314\n",
            "Epoch 180/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 983ms/step - accuracy: 0.8399 - loss: 0.3323 - val_accuracy: 0.7400 - val_loss: 0.6493\n",
            "Epoch 181/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.8629 - loss: 0.2787 - val_accuracy: 0.7200 - val_loss: 0.8395\n",
            "Epoch 182/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.8497 - loss: 0.3118 - val_accuracy: 0.7400 - val_loss: 0.6309\n",
            "Epoch 183/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 928ms/step - accuracy: 0.8588 - loss: 0.3369 - val_accuracy: 0.7400 - val_loss: 0.5839\n",
            "Epoch 184/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 949ms/step - accuracy: 0.8787 - loss: 0.2783 - val_accuracy: 0.7400 - val_loss: 0.5604\n",
            "Epoch 185/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.8830 - loss: 0.2711 - val_accuracy: 0.8000 - val_loss: 0.3878\n",
            "Epoch 186/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.8842 - loss: 0.2715 - val_accuracy: 0.7000 - val_loss: 0.9750\n",
            "Epoch 187/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 949ms/step - accuracy: 0.8620 - loss: 0.3064 - val_accuracy: 0.7400 - val_loss: 0.8015\n",
            "Epoch 188/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.8626 - loss: 0.3023 - val_accuracy: 0.7200 - val_loss: 0.7798\n",
            "Epoch 189/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 919ms/step - accuracy: 0.8717 - loss: 0.3349 - val_accuracy: 0.7400 - val_loss: 0.7322\n",
            "Epoch 190/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.8329 - loss: 0.3772 - val_accuracy: 0.7800 - val_loss: 0.3663\n",
            "Epoch 191/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.8486 - loss: 0.3290 - val_accuracy: 0.7800 - val_loss: 0.4128\n",
            "Epoch 192/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 954ms/step - accuracy: 0.8744 - loss: 0.2582 - val_accuracy: 0.7400 - val_loss: 0.6813\n",
            "Epoch 193/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.8644 - loss: 0.2986 - val_accuracy: 0.7200 - val_loss: 0.7283\n",
            "Epoch 194/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.8928 - loss: 0.2832 - val_accuracy: 0.7400 - val_loss: 0.5498\n",
            "Epoch 195/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.8905 - loss: 0.2761 - val_accuracy: 0.7600 - val_loss: 0.5114\n",
            "Epoch 196/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 961ms/step - accuracy: 0.8803 - loss: 0.2873 - val_accuracy: 0.8000 - val_loss: 0.3103\n",
            "Epoch 197/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8576 - loss: 0.3384 - val_accuracy: 0.8000 - val_loss: 0.3266\n",
            "Epoch 198/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.8594 - loss: 0.3315 - val_accuracy: 0.7600 - val_loss: 0.3805\n",
            "Epoch 199/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.8827 - loss: 0.2897 - val_accuracy: 0.7400 - val_loss: 0.5137\n",
            "Epoch 200/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 964ms/step - accuracy: 0.8971 - loss: 0.2651 - val_accuracy: 0.7400 - val_loss: 0.5133\n",
            "Epoch 201/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 927ms/step - accuracy: 0.8604 - loss: 0.3133 - val_accuracy: 0.8400 - val_loss: 0.2800\n",
            "Epoch 202/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 925ms/step - accuracy: 0.8589 - loss: 0.3226 - val_accuracy: 0.8000 - val_loss: 0.3022\n",
            "Epoch 203/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 931ms/step - accuracy: 0.8511 - loss: 0.3242 - val_accuracy: 0.7000 - val_loss: 0.6721\n",
            "Epoch 204/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 972ms/step - accuracy: 0.8675 - loss: 0.3334 - val_accuracy: 0.7600 - val_loss: 0.5702\n",
            "Epoch 205/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.8350 - loss: 0.3841 - val_accuracy: 0.7800 - val_loss: 0.4003\n",
            "Epoch 206/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 936ms/step - accuracy: 0.8862 - loss: 0.2996 - val_accuracy: 0.7000 - val_loss: 0.8740\n",
            "Epoch 207/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.8190 - loss: 0.3669 - val_accuracy: 0.7000 - val_loss: 0.8737\n",
            "Epoch 208/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 972ms/step - accuracy: 0.9087 - loss: 0.2891 - val_accuracy: 0.7400 - val_loss: 0.6619\n",
            "Epoch 209/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 913ms/step - accuracy: 0.8844 - loss: 0.3013 - val_accuracy: 0.7400 - val_loss: 0.5427\n",
            "Epoch 210/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 927ms/step - accuracy: 0.8794 - loss: 0.2902 - val_accuracy: 0.7400 - val_loss: 0.4746\n",
            "Epoch 211/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 952ms/step - accuracy: 0.8849 - loss: 0.3144 - val_accuracy: 0.7400 - val_loss: 0.4943\n",
            "Epoch 212/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 986ms/step - accuracy: 0.8752 - loss: 0.2938 - val_accuracy: 0.7400 - val_loss: 0.5616\n",
            "Epoch 213/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 948ms/step - accuracy: 0.8217 - loss: 0.3580 - val_accuracy: 0.7400 - val_loss: 0.6709\n",
            "Epoch 214/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.8606 - loss: 0.3093 - val_accuracy: 0.7000 - val_loss: 0.6955\n",
            "Epoch 215/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.8767 - loss: 0.2769 - val_accuracy: 0.7600 - val_loss: 0.4243\n",
            "Epoch 216/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 985ms/step - accuracy: 0.8527 - loss: 0.3116 - val_accuracy: 0.7400 - val_loss: 0.6266\n",
            "Epoch 217/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.8599 - loss: 0.3203 - val_accuracy: 0.8000 - val_loss: 0.3772\n",
            "Epoch 218/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 936ms/step - accuracy: 0.8730 - loss: 0.2599 - val_accuracy: 0.8000 - val_loss: 0.3508\n",
            "Epoch 219/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.8830 - loss: 0.3021 - val_accuracy: 0.7400 - val_loss: 0.5231\n",
            "Epoch 220/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 988ms/step - accuracy: 0.8549 - loss: 0.3161 - val_accuracy: 0.8400 - val_loss: 0.2534\n",
            "Epoch 221/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 945ms/step - accuracy: 0.8475 - loss: 0.3252 - val_accuracy: 0.7600 - val_loss: 0.3959\n",
            "Epoch 222/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 937ms/step - accuracy: 0.8533 - loss: 0.3093 - val_accuracy: 0.7600 - val_loss: 0.4006\n",
            "Epoch 223/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.8951 - loss: 0.2625 - val_accuracy: 0.7400 - val_loss: 0.5145\n",
            "Epoch 224/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 950ms/step - accuracy: 0.8797 - loss: 0.2937 - val_accuracy: 0.6800 - val_loss: 0.7919\n",
            "Epoch 225/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 933ms/step - accuracy: 0.8456 - loss: 0.3296 - val_accuracy: 0.7800 - val_loss: 0.3649\n",
            "Epoch 226/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.8360 - loss: 0.3667 - val_accuracy: 0.7600 - val_loss: 0.4377\n",
            "Epoch 227/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 961ms/step - accuracy: 0.8363 - loss: 0.3400 - val_accuracy: 0.7800 - val_loss: 0.3368\n",
            "Epoch 228/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 951ms/step - accuracy: 0.8352 - loss: 0.3731 - val_accuracy: 0.8600 - val_loss: 0.2246\n",
            "Epoch 229/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 971ms/step - accuracy: 0.8738 - loss: 0.2868 - val_accuracy: 0.7600 - val_loss: 0.4271\n",
            "Epoch 230/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 970ms/step - accuracy: 0.8459 - loss: 0.3560 - val_accuracy: 0.7400 - val_loss: 0.4637\n",
            "Epoch 231/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 968ms/step - accuracy: 0.8868 - loss: 0.2782 - val_accuracy: 0.7800 - val_loss: 0.3673\n",
            "Epoch 232/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.8200 - loss: 0.3296 - val_accuracy: 0.8600 - val_loss: 0.2370\n",
            "Epoch 233/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 938ms/step - accuracy: 0.8713 - loss: 0.3170 - val_accuracy: 0.7800 - val_loss: 0.3878\n",
            "Epoch 234/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.8069 - loss: 0.3644 - val_accuracy: 0.8600 - val_loss: 0.1895\n",
            "Epoch 235/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 952ms/step - accuracy: 0.8810 - loss: 0.2633 - val_accuracy: 0.7400 - val_loss: 0.4768\n",
            "Epoch 236/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 971ms/step - accuracy: 0.8617 - loss: 0.3050 - val_accuracy: 0.7600 - val_loss: 0.3746\n",
            "Epoch 237/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 959ms/step - accuracy: 0.8700 - loss: 0.3250 - val_accuracy: 0.7000 - val_loss: 0.9123\n",
            "Epoch 238/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 944ms/step - accuracy: 0.8907 - loss: 0.2469 - val_accuracy: 0.7400 - val_loss: 0.5830\n",
            "Epoch 239/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 937ms/step - accuracy: 0.8595 - loss: 0.3050 - val_accuracy: 0.8600 - val_loss: 0.2225\n",
            "Epoch 240/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8647 - loss: 0.2946 - val_accuracy: 0.7800 - val_loss: 0.3422\n",
            "Epoch 241/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 985ms/step - accuracy: 0.8938 - loss: 0.3209 - val_accuracy: 0.7600 - val_loss: 0.4190\n",
            "Epoch 242/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.8940 - loss: 0.2724 - val_accuracy: 0.7200 - val_loss: 0.4410\n",
            "Epoch 243/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.8559 - loss: 0.3195 - val_accuracy: 0.7200 - val_loss: 0.6259\n",
            "Epoch 244/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 936ms/step - accuracy: 0.8682 - loss: 0.3020 - val_accuracy: 0.7000 - val_loss: 0.6806\n",
            "Epoch 245/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 948ms/step - accuracy: 0.8722 - loss: 0.3218 - val_accuracy: 0.7400 - val_loss: 0.4038\n",
            "Epoch 246/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 944ms/step - accuracy: 0.8899 - loss: 0.2499 - val_accuracy: 0.7600 - val_loss: 0.3847\n",
            "Epoch 247/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.8772 - loss: 0.2927 - val_accuracy: 0.7400 - val_loss: 0.5283\n",
            "Epoch 248/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 950ms/step - accuracy: 0.8813 - loss: 0.2775 - val_accuracy: 0.6800 - val_loss: 0.7792\n",
            "Epoch 249/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 970ms/step - accuracy: 0.8960 - loss: 0.2453 - val_accuracy: 0.7200 - val_loss: 0.5182\n",
            "Epoch 250/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 942ms/step - accuracy: 0.8924 - loss: 0.2320 - val_accuracy: 0.7800 - val_loss: 0.3811\n",
            "Epoch 251/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 935ms/step - accuracy: 0.8597 - loss: 0.3302 - val_accuracy: 0.7800 - val_loss: 0.3628\n",
            "Epoch 252/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 949ms/step - accuracy: 0.8860 - loss: 0.2826 - val_accuracy: 0.8000 - val_loss: 0.3244\n",
            "Epoch 253/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8612 - loss: 0.2950 - val_accuracy: 0.7200 - val_loss: 0.6752\n",
            "Epoch 254/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 931ms/step - accuracy: 0.8591 - loss: 0.3277 - val_accuracy: 0.7800 - val_loss: 0.4315\n",
            "Epoch 255/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 934ms/step - accuracy: 0.8843 - loss: 0.2551 - val_accuracy: 0.7800 - val_loss: 0.3612\n",
            "Epoch 256/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 942ms/step - accuracy: 0.8810 - loss: 0.3087 - val_accuracy: 0.9400 - val_loss: 0.2215\n",
            "Epoch 257/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 967ms/step - accuracy: 0.8687 - loss: 0.3367 - val_accuracy: 0.7400 - val_loss: 0.5979\n",
            "Epoch 258/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8631 - loss: 0.2832 - val_accuracy: 0.7600 - val_loss: 0.3755\n",
            "Epoch 259/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 959ms/step - accuracy: 0.8785 - loss: 0.2967 - val_accuracy: 0.7400 - val_loss: 0.4734\n",
            "Epoch 260/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 959ms/step - accuracy: 0.8518 - loss: 0.3535 - val_accuracy: 0.7200 - val_loss: 0.6966\n",
            "Epoch 261/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 991ms/step - accuracy: 0.8914 - loss: 0.2602 - val_accuracy: 0.7400 - val_loss: 0.4835\n",
            "Epoch 262/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 935ms/step - accuracy: 0.9076 - loss: 0.2929 - val_accuracy: 0.7400 - val_loss: 0.3787\n",
            "Epoch 263/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.8505 - loss: 0.2962 - val_accuracy: 0.7200 - val_loss: 0.5985\n",
            "Epoch 264/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 960ms/step - accuracy: 0.8752 - loss: 0.3010 - val_accuracy: 0.7600 - val_loss: 0.3423\n",
            "Epoch 265/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 997ms/step - accuracy: 0.8892 - loss: 0.2564 - val_accuracy: 0.7200 - val_loss: 0.5829\n",
            "Epoch 266/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 944ms/step - accuracy: 0.8392 - loss: 0.3416 - val_accuracy: 0.7400 - val_loss: 0.6270\n",
            "Epoch 267/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 937ms/step - accuracy: 0.8647 - loss: 0.2794 - val_accuracy: 0.7600 - val_loss: 0.4602\n",
            "Epoch 268/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8502 - loss: 0.2833 - val_accuracy: 0.7200 - val_loss: 0.6413\n",
            "Epoch 269/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 979ms/step - accuracy: 0.8760 - loss: 0.2735 - val_accuracy: 0.7400 - val_loss: 0.7227\n",
            "Epoch 270/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 961ms/step - accuracy: 0.8642 - loss: 0.3586 - val_accuracy: 0.7000 - val_loss: 0.9523\n",
            "Epoch 271/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 972ms/step - accuracy: 0.8793 - loss: 0.3095 - val_accuracy: 0.6800 - val_loss: 1.0075\n",
            "Epoch 272/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 948ms/step - accuracy: 0.8695 - loss: 0.3301 - val_accuracy: 0.6800 - val_loss: 0.9672\n",
            "Epoch 273/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 982ms/step - accuracy: 0.8716 - loss: 0.3126 - val_accuracy: 0.6800 - val_loss: 0.6579\n",
            "Epoch 274/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8731 - loss: 0.2767 - val_accuracy: 0.7200 - val_loss: 0.4964\n",
            "Epoch 275/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.8886 - loss: 0.2614 - val_accuracy: 0.7800 - val_loss: 0.3649\n",
            "Epoch 276/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8629 - loss: 0.3194 - val_accuracy: 0.7000 - val_loss: 0.6358\n",
            "Epoch 277/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8831 - loss: 0.3322 - val_accuracy: 0.8200 - val_loss: 0.2825\n",
            "Epoch 278/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9139 - loss: 0.2300 - val_accuracy: 0.7400 - val_loss: 0.7004\n",
            "Epoch 279/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8849 - loss: 0.2759 - val_accuracy: 0.7400 - val_loss: 0.4648\n",
            "Epoch 280/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.8688 - loss: 0.3354 - val_accuracy: 0.8200 - val_loss: 0.2490\n",
            "Epoch 281/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 983ms/step - accuracy: 0.8622 - loss: 0.3242 - val_accuracy: 0.7400 - val_loss: 0.5278\n",
            "Epoch 282/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 979ms/step - accuracy: 0.8428 - loss: 0.2946 - val_accuracy: 0.7400 - val_loss: 0.5887\n",
            "Epoch 283/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 969ms/step - accuracy: 0.8901 - loss: 0.2546 - val_accuracy: 0.8000 - val_loss: 0.3039\n",
            "Epoch 284/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 974ms/step - accuracy: 0.8662 - loss: 0.3085 - val_accuracy: 0.7800 - val_loss: 0.4372\n",
            "Epoch 285/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 994ms/step - accuracy: 0.9003 - loss: 0.2563 - val_accuracy: 0.8600 - val_loss: 0.2236\n",
            "Epoch 286/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 990ms/step - accuracy: 0.8548 - loss: 0.3067 - val_accuracy: 0.7400 - val_loss: 0.5426\n",
            "Epoch 287/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8638 - loss: 0.2993 - val_accuracy: 0.7800 - val_loss: 0.3791\n",
            "Epoch 288/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 955ms/step - accuracy: 0.9011 - loss: 0.2675 - val_accuracy: 0.7400 - val_loss: 0.5301\n",
            "Epoch 289/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 981ms/step - accuracy: 0.9054 - loss: 0.2335 - val_accuracy: 0.8000 - val_loss: 0.3494\n",
            "Epoch 290/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.8880 - loss: 0.2878 - val_accuracy: 0.7400 - val_loss: 0.5679\n",
            "Epoch 291/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 943ms/step - accuracy: 0.8962 - loss: 0.2354 - val_accuracy: 0.7600 - val_loss: 0.5526\n",
            "Epoch 292/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.9134 - loss: 0.2364 - val_accuracy: 0.7400 - val_loss: 0.8175\n",
            "Epoch 293/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 970ms/step - accuracy: 0.8803 - loss: 0.2797 - val_accuracy: 0.7400 - val_loss: 0.5698\n",
            "Epoch 294/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 931ms/step - accuracy: 0.8623 - loss: 0.3094 - val_accuracy: 0.7400 - val_loss: 0.5186\n",
            "Epoch 295/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 935ms/step - accuracy: 0.8524 - loss: 0.3294 - val_accuracy: 0.7000 - val_loss: 0.8587\n",
            "Epoch 296/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.8783 - loss: 0.2971 - val_accuracy: 0.7400 - val_loss: 0.4595\n",
            "Epoch 297/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 971ms/step - accuracy: 0.9297 - loss: 0.2121 - val_accuracy: 0.7000 - val_loss: 0.7077\n",
            "Epoch 298/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.8895 - loss: 0.2599 - val_accuracy: 0.7400 - val_loss: 0.4738\n",
            "Epoch 299/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 937ms/step - accuracy: 0.8979 - loss: 0.2576 - val_accuracy: 0.7000 - val_loss: 0.9144\n",
            "Epoch 300/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.8663 - loss: 0.2875 - val_accuracy: 0.7400 - val_loss: 0.5253\n",
            "Epoch 301/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 932ms/step - accuracy: 0.8735 - loss: 0.2564 - val_accuracy: 0.7400 - val_loss: 0.6083\n",
            "Epoch 302/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 941ms/step - accuracy: 0.8798 - loss: 0.2927 - val_accuracy: 0.7400 - val_loss: 0.6041\n",
            "Epoch 303/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 945ms/step - accuracy: 0.9001 - loss: 0.2712 - val_accuracy: 0.7400 - val_loss: 0.5355\n",
            "Epoch 304/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 954ms/step - accuracy: 0.8980 - loss: 0.2751 - val_accuracy: 0.7400 - val_loss: 0.5915\n",
            "Epoch 305/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 952ms/step - accuracy: 0.8723 - loss: 0.2980 - val_accuracy: 0.7400 - val_loss: 0.6109\n",
            "Epoch 306/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 938ms/step - accuracy: 0.8888 - loss: 0.2505 - val_accuracy: 0.7800 - val_loss: 0.3627\n",
            "Epoch 307/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.8897 - loss: 0.2569 - val_accuracy: 0.7400 - val_loss: 0.4780\n",
            "Epoch 308/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 953ms/step - accuracy: 0.8944 - loss: 0.2526 - val_accuracy: 0.7400 - val_loss: 0.6133\n",
            "Epoch 309/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 975ms/step - accuracy: 0.8909 - loss: 0.2715 - val_accuracy: 0.7400 - val_loss: 0.4494\n",
            "Epoch 310/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.9019 - loss: 0.2780 - val_accuracy: 0.7800 - val_loss: 0.3402\n",
            "Epoch 311/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 953ms/step - accuracy: 0.8996 - loss: 0.2589 - val_accuracy: 0.7200 - val_loss: 0.7668\n",
            "Epoch 312/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8889 - loss: 0.2653 - val_accuracy: 0.7400 - val_loss: 0.4721\n",
            "Epoch 313/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 962ms/step - accuracy: 0.8886 - loss: 0.2354 - val_accuracy: 0.7800 - val_loss: 0.3416\n",
            "Epoch 314/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 941ms/step - accuracy: 0.8893 - loss: 0.2868 - val_accuracy: 0.7400 - val_loss: 0.6519\n",
            "Epoch 315/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8679 - loss: 0.2803 - val_accuracy: 0.7400 - val_loss: 0.7128\n",
            "Epoch 316/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 960ms/step - accuracy: 0.8868 - loss: 0.3043 - val_accuracy: 0.7400 - val_loss: 0.4394\n",
            "Epoch 317/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8672 - loss: 0.3094 - val_accuracy: 0.7400 - val_loss: 0.4370\n",
            "Epoch 318/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.8925 - loss: 0.2811 - val_accuracy: 0.7000 - val_loss: 0.5526\n",
            "Epoch 319/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 957ms/step - accuracy: 0.8706 - loss: 0.3100 - val_accuracy: 0.7800 - val_loss: 0.3267\n",
            "Epoch 320/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 952ms/step - accuracy: 0.8953 - loss: 0.2269 - val_accuracy: 0.7400 - val_loss: 0.4469\n",
            "Epoch 321/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 965ms/step - accuracy: 0.8789 - loss: 0.2678 - val_accuracy: 0.7400 - val_loss: 0.5711\n",
            "Epoch 322/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 926ms/step - accuracy: 0.8678 - loss: 0.2802 - val_accuracy: 0.7400 - val_loss: 0.4713\n",
            "Epoch 323/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 943ms/step - accuracy: 0.8796 - loss: 0.2443 - val_accuracy: 0.7400 - val_loss: 0.4969\n",
            "Epoch 324/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8830 - loss: 0.2757 - val_accuracy: 0.8200 - val_loss: 0.2621\n",
            "Epoch 325/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 950ms/step - accuracy: 0.9147 - loss: 0.2282 - val_accuracy: 0.7400 - val_loss: 0.4763\n",
            "Epoch 326/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 933ms/step - accuracy: 0.9050 - loss: 0.2557 - val_accuracy: 0.8000 - val_loss: 0.2896\n",
            "Epoch 327/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.9017 - loss: 0.2430 - val_accuracy: 0.7600 - val_loss: 0.3973\n",
            "Epoch 328/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 964ms/step - accuracy: 0.9096 - loss: 0.2035 - val_accuracy: 0.7400 - val_loss: 0.4713\n",
            "Epoch 329/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.9241 - loss: 0.2189 - val_accuracy: 0.7400 - val_loss: 0.6114\n",
            "Epoch 330/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8880 - loss: 0.2412 - val_accuracy: 0.7400 - val_loss: 0.6479\n",
            "Epoch 331/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 941ms/step - accuracy: 0.8702 - loss: 0.2724 - val_accuracy: 0.7800 - val_loss: 0.4445\n",
            "Epoch 332/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 959ms/step - accuracy: 0.8660 - loss: 0.2768 - val_accuracy: 0.8000 - val_loss: 0.3287\n",
            "Epoch 333/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.8637 - loss: 0.2753 - val_accuracy: 0.7800 - val_loss: 0.3437\n",
            "Epoch 334/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 967ms/step - accuracy: 0.8625 - loss: 0.3019 - val_accuracy: 0.7400 - val_loss: 0.4549\n",
            "Epoch 335/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.9039 - loss: 0.2402 - val_accuracy: 0.7400 - val_loss: 0.7006\n",
            "Epoch 336/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 939ms/step - accuracy: 0.8751 - loss: 0.2787 - val_accuracy: 0.7800 - val_loss: 0.3431\n",
            "Epoch 337/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 950ms/step - accuracy: 0.9010 - loss: 0.2531 - val_accuracy: 0.7800 - val_loss: 0.4458\n",
            "Epoch 338/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 954ms/step - accuracy: 0.9065 - loss: 0.2639 - val_accuracy: 0.8600 - val_loss: 0.2638\n",
            "Epoch 339/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 945ms/step - accuracy: 0.8904 - loss: 0.2439 - val_accuracy: 0.7600 - val_loss: 0.5000\n",
            "Epoch 340/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.8942 - loss: 0.2564 - val_accuracy: 0.8200 - val_loss: 0.3105\n",
            "Epoch 341/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 987ms/step - accuracy: 0.8969 - loss: 0.2371 - val_accuracy: 0.7400 - val_loss: 0.5406\n",
            "Epoch 342/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8652 - loss: 0.2814 - val_accuracy: 0.7200 - val_loss: 0.7567\n",
            "Epoch 343/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 948ms/step - accuracy: 0.8649 - loss: 0.2839 - val_accuracy: 0.7600 - val_loss: 0.4926\n",
            "Epoch 344/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 956ms/step - accuracy: 0.8746 - loss: 0.2991 - val_accuracy: 0.7400 - val_loss: 0.5532\n",
            "Epoch 345/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 980ms/step - accuracy: 0.8880 - loss: 0.2925 - val_accuracy: 0.7600 - val_loss: 0.5004\n",
            "Epoch 346/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 941ms/step - accuracy: 0.9082 - loss: 0.2145 - val_accuracy: 0.8400 - val_loss: 0.2698\n",
            "Epoch 347/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.8731 - loss: 0.2664 - val_accuracy: 0.8400 - val_loss: 0.2137\n",
            "Epoch 348/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 956ms/step - accuracy: 0.9035 - loss: 0.2892 - val_accuracy: 0.7800 - val_loss: 0.4195\n",
            "Epoch 349/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 950ms/step - accuracy: 0.8967 - loss: 0.2618 - val_accuracy: 0.7400 - val_loss: 0.5525\n",
            "Epoch 350/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 927ms/step - accuracy: 0.8802 - loss: 0.2332 - val_accuracy: 0.7800 - val_loss: 0.4316\n",
            "Epoch 351/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 939ms/step - accuracy: 0.8835 - loss: 0.2647 - val_accuracy: 0.8000 - val_loss: 0.3369\n",
            "Epoch 352/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8810 - loss: 0.2406 - val_accuracy: 0.7000 - val_loss: 0.7216\n",
            "Epoch 353/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 964ms/step - accuracy: 0.8951 - loss: 0.2347 - val_accuracy: 0.8200 - val_loss: 0.3491\n",
            "Epoch 354/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 931ms/step - accuracy: 0.8681 - loss: 0.2776 - val_accuracy: 0.7800 - val_loss: 0.4409\n",
            "Epoch 355/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 943ms/step - accuracy: 0.8886 - loss: 0.2470 - val_accuracy: 0.7600 - val_loss: 0.6246\n",
            "Epoch 356/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.9101 - loss: 0.2195 - val_accuracy: 0.7600 - val_loss: 0.5133\n",
            "Epoch 357/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 938ms/step - accuracy: 0.9100 - loss: 0.2402 - val_accuracy: 0.7400 - val_loss: 0.5658\n",
            "Epoch 358/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 945ms/step - accuracy: 0.9075 - loss: 0.2218 - val_accuracy: 0.7800 - val_loss: 0.5277\n",
            "Epoch 359/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 935ms/step - accuracy: 0.9053 - loss: 0.2254 - val_accuracy: 0.8200 - val_loss: 0.3152\n",
            "Epoch 360/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.9058 - loss: 0.2261 - val_accuracy: 0.8000 - val_loss: 0.4030\n",
            "Epoch 361/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 938ms/step - accuracy: 0.8987 - loss: 0.2526 - val_accuracy: 0.8400 - val_loss: 0.2636\n",
            "Epoch 362/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 937ms/step - accuracy: 0.9121 - loss: 0.2458 - val_accuracy: 0.7400 - val_loss: 0.5695\n",
            "Epoch 363/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.8670 - loss: 0.2720 - val_accuracy: 0.7800 - val_loss: 0.4056\n",
            "Epoch 364/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 946ms/step - accuracy: 0.8838 - loss: 0.2646 - val_accuracy: 0.7000 - val_loss: 0.5803\n",
            "Epoch 365/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.8766 - loss: 0.2849 - val_accuracy: 0.7400 - val_loss: 0.5254\n",
            "Epoch 366/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 941ms/step - accuracy: 0.8980 - loss: 0.2254 - val_accuracy: 0.7200 - val_loss: 0.5758\n",
            "Epoch 367/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 939ms/step - accuracy: 0.8854 - loss: 0.2421 - val_accuracy: 0.8200 - val_loss: 0.3175\n",
            "Epoch 368/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.8860 - loss: 0.2794 - val_accuracy: 0.9400 - val_loss: 0.1603\n",
            "Epoch 369/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 950ms/step - accuracy: 0.8968 - loss: 0.2393 - val_accuracy: 0.7600 - val_loss: 0.4753\n",
            "Epoch 370/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 945ms/step - accuracy: 0.9056 - loss: 0.2476 - val_accuracy: 0.8200 - val_loss: 0.3375\n",
            "Epoch 371/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 935ms/step - accuracy: 0.9023 - loss: 0.2405 - val_accuracy: 0.7400 - val_loss: 0.6666\n",
            "Epoch 372/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 949ms/step - accuracy: 0.9050 - loss: 0.2391 - val_accuracy: 0.7000 - val_loss: 0.9062\n",
            "Epoch 373/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 942ms/step - accuracy: 0.8717 - loss: 0.2706 - val_accuracy: 0.8200 - val_loss: 0.3124\n",
            "Epoch 374/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 953ms/step - accuracy: 0.9002 - loss: 0.2583 - val_accuracy: 0.7800 - val_loss: 0.4899\n",
            "Epoch 375/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 944ms/step - accuracy: 0.8983 - loss: 0.2421 - val_accuracy: 0.7800 - val_loss: 0.3510\n",
            "Epoch 376/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 938ms/step - accuracy: 0.9000 - loss: 0.2423 - val_accuracy: 0.7000 - val_loss: 0.7793\n",
            "Epoch 377/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 949ms/step - accuracy: 0.9144 - loss: 0.2092 - val_accuracy: 0.7800 - val_loss: 0.3578\n",
            "Epoch 378/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 956ms/step - accuracy: 0.8951 - loss: 0.2601 - val_accuracy: 0.8000 - val_loss: 0.3022\n",
            "Epoch 379/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.8534 - loss: 0.3424 - val_accuracy: 0.7400 - val_loss: 0.3826\n",
            "Epoch 380/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 942ms/step - accuracy: 0.8998 - loss: 0.2525 - val_accuracy: 0.7400 - val_loss: 0.5170\n",
            "Epoch 381/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 954ms/step - accuracy: 0.9161 - loss: 0.2005 - val_accuracy: 0.7200 - val_loss: 0.7152\n",
            "Epoch 382/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.9275 - loss: 0.1866 - val_accuracy: 0.7400 - val_loss: 0.4664\n",
            "Epoch 383/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.9199 - loss: 0.1976 - val_accuracy: 0.7600 - val_loss: 0.4575\n",
            "Epoch 384/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.8996 - loss: 0.2366 - val_accuracy: 0.7400 - val_loss: 0.4809\n",
            "Epoch 385/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.9431 - loss: 0.1724 - val_accuracy: 0.7400 - val_loss: 0.5608\n",
            "Epoch 386/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.9143 - loss: 0.2479 - val_accuracy: 0.8000 - val_loss: 0.3212\n",
            "Epoch 387/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 944ms/step - accuracy: 0.9094 - loss: 0.2401 - val_accuracy: 0.7600 - val_loss: 0.4954\n",
            "Epoch 388/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 933ms/step - accuracy: 0.9003 - loss: 0.2345 - val_accuracy: 0.7800 - val_loss: 0.5106\n",
            "Epoch 389/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.9434 - loss: 0.2075 - val_accuracy: 0.7400 - val_loss: 0.9769\n",
            "Epoch 390/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 954ms/step - accuracy: 0.8612 - loss: 0.2880 - val_accuracy: 0.7200 - val_loss: 1.0133\n",
            "Epoch 391/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 948ms/step - accuracy: 0.8745 - loss: 0.2600 - val_accuracy: 0.7200 - val_loss: 1.0118\n",
            "Epoch 392/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.8861 - loss: 0.2547 - val_accuracy: 0.7400 - val_loss: 0.7029\n",
            "Epoch 393/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.9001 - loss: 0.2570 - val_accuracy: 0.7800 - val_loss: 0.3586\n",
            "Epoch 394/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 958ms/step - accuracy: 0.8662 - loss: 0.2979 - val_accuracy: 0.6800 - val_loss: 1.2546\n",
            "Epoch 395/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 959ms/step - accuracy: 0.8803 - loss: 0.2708 - val_accuracy: 0.7200 - val_loss: 0.8577\n",
            "Epoch 396/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.9035 - loss: 0.2794 - val_accuracy: 0.7400 - val_loss: 0.5730\n",
            "Epoch 397/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 952ms/step - accuracy: 0.9054 - loss: 0.2097 - val_accuracy: 0.7400 - val_loss: 0.5036\n",
            "Epoch 398/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 987ms/step - accuracy: 0.8991 - loss: 0.2293 - val_accuracy: 0.7400 - val_loss: 0.8004\n",
            "Epoch 399/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 949ms/step - accuracy: 0.8859 - loss: 0.2441 - val_accuracy: 0.7800 - val_loss: 0.4944\n",
            "Epoch 400/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 949ms/step - accuracy: 0.8717 - loss: 0.2606 - val_accuracy: 0.7400 - val_loss: 0.9115\n",
            "Epoch 401/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.9057 - loss: 0.2302 - val_accuracy: 0.7400 - val_loss: 0.6349\n",
            "Epoch 402/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 951ms/step - accuracy: 0.9105 - loss: 0.1997 - val_accuracy: 0.7800 - val_loss: 0.5013\n",
            "Epoch 403/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 921ms/step - accuracy: 0.9210 - loss: 0.2048 - val_accuracy: 0.7400 - val_loss: 0.8193\n",
            "Epoch 404/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.9071 - loss: 0.2265 - val_accuracy: 0.7800 - val_loss: 0.4169\n",
            "Epoch 405/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 960ms/step - accuracy: 0.8895 - loss: 0.2321 - val_accuracy: 0.7800 - val_loss: 0.4947\n",
            "Epoch 406/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 989ms/step - accuracy: 0.8880 - loss: 0.2778 - val_accuracy: 0.8400 - val_loss: 0.2999\n",
            "Epoch 407/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8851 - loss: 0.2774 - val_accuracy: 0.7800 - val_loss: 0.3830\n",
            "Epoch 408/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 932ms/step - accuracy: 0.8974 - loss: 0.2519 - val_accuracy: 0.7200 - val_loss: 0.6253\n",
            "Epoch 409/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 939ms/step - accuracy: 0.8754 - loss: 0.2341 - val_accuracy: 0.8200 - val_loss: 0.4338\n",
            "Epoch 410/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 977ms/step - accuracy: 0.8733 - loss: 0.2795 - val_accuracy: 0.8600 - val_loss: 0.1943\n",
            "Epoch 411/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.8832 - loss: 0.2829 - val_accuracy: 0.8200 - val_loss: 0.2836\n",
            "Epoch 412/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.9004 - loss: 0.2285 - val_accuracy: 0.8600 - val_loss: 0.1834\n",
            "Epoch 413/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.8760 - loss: 0.2502 - val_accuracy: 0.7600 - val_loss: 0.6723\n",
            "Epoch 414/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 967ms/step - accuracy: 0.8840 - loss: 0.2681 - val_accuracy: 0.8400 - val_loss: 0.3906\n",
            "Epoch 415/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 927ms/step - accuracy: 0.8695 - loss: 0.2991 - val_accuracy: 0.7800 - val_loss: 0.5702\n",
            "Epoch 416/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.9138 - loss: 0.2437 - val_accuracy: 0.7400 - val_loss: 0.7635\n",
            "Epoch 417/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 949ms/step - accuracy: 0.8765 - loss: 0.2710 - val_accuracy: 0.7200 - val_loss: 0.7477\n",
            "Epoch 418/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 917ms/step - accuracy: 0.9052 - loss: 0.2328 - val_accuracy: 0.8200 - val_loss: 0.4155\n",
            "Epoch 419/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 925ms/step - accuracy: 0.9105 - loss: 0.2545 - val_accuracy: 0.8000 - val_loss: 0.4405\n",
            "Epoch 420/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 933ms/step - accuracy: 0.9260 - loss: 0.2081 - val_accuracy: 0.8600 - val_loss: 0.1937\n",
            "Epoch 421/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.8889 - loss: 0.3034 - val_accuracy: 0.8200 - val_loss: 0.3072\n",
            "Epoch 422/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 927ms/step - accuracy: 0.8878 - loss: 0.2213 - val_accuracy: 0.7600 - val_loss: 0.5070\n",
            "Epoch 423/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.8949 - loss: 0.2599 - val_accuracy: 0.7400 - val_loss: 0.5610\n",
            "Epoch 424/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.9217 - loss: 0.2283 - val_accuracy: 0.8200 - val_loss: 0.3385\n",
            "Epoch 425/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 944ms/step - accuracy: 0.8820 - loss: 0.2450 - val_accuracy: 0.7400 - val_loss: 0.4811\n",
            "Epoch 426/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 927ms/step - accuracy: 0.9122 - loss: 0.2347 - val_accuracy: 0.9200 - val_loss: 0.1924\n",
            "Epoch 427/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.9214 - loss: 0.2400 - val_accuracy: 0.7400 - val_loss: 0.5485\n",
            "Epoch 428/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 998ms/step - accuracy: 0.9445 - loss: 0.2061 - val_accuracy: 0.7400 - val_loss: 0.4870\n",
            "Epoch 429/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8925 - loss: 0.2518 - val_accuracy: 0.7200 - val_loss: 0.5380\n",
            "Epoch 430/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 928ms/step - accuracy: 0.8926 - loss: 0.2484 - val_accuracy: 0.7800 - val_loss: 0.4043\n",
            "Epoch 431/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.9015 - loss: 0.2368 - val_accuracy: 0.7600 - val_loss: 0.4774\n",
            "Epoch 432/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 954ms/step - accuracy: 0.9352 - loss: 0.1848 - val_accuracy: 0.7600 - val_loss: 0.5946\n",
            "Epoch 433/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 982ms/step - accuracy: 0.8963 - loss: 0.2211 - val_accuracy: 0.7600 - val_loss: 0.4834\n",
            "Epoch 434/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 942ms/step - accuracy: 0.8939 - loss: 0.2307 - val_accuracy: 0.9200 - val_loss: 0.2189\n",
            "Epoch 435/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 952ms/step - accuracy: 0.9306 - loss: 0.2227 - val_accuracy: 0.8200 - val_loss: 0.3320\n",
            "Epoch 436/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 969ms/step - accuracy: 0.8941 - loss: 0.2237 - val_accuracy: 0.7600 - val_loss: 0.4814\n",
            "Epoch 437/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 949ms/step - accuracy: 0.8856 - loss: 0.2556 - val_accuracy: 0.8600 - val_loss: 0.2851\n",
            "Epoch 438/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 954ms/step - accuracy: 0.9097 - loss: 0.2327 - val_accuracy: 0.8000 - val_loss: 0.4295\n",
            "Epoch 439/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 949ms/step - accuracy: 0.9383 - loss: 0.1675 - val_accuracy: 0.8400 - val_loss: 0.2789\n",
            "Epoch 440/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 950ms/step - accuracy: 0.9162 - loss: 0.2295 - val_accuracy: 0.7200 - val_loss: 0.6540\n",
            "Epoch 441/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 930ms/step - accuracy: 0.8976 - loss: 0.2096 - val_accuracy: 0.8000 - val_loss: 0.3701\n",
            "Epoch 442/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 946ms/step - accuracy: 0.8607 - loss: 0.3147 - val_accuracy: 0.8200 - val_loss: 0.3073\n",
            "Epoch 443/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 965ms/step - accuracy: 0.9071 - loss: 0.2102 - val_accuracy: 0.8600 - val_loss: 0.2245\n",
            "Epoch 444/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 961ms/step - accuracy: 0.9108 - loss: 0.2316 - val_accuracy: 0.7400 - val_loss: 0.4690\n",
            "Epoch 445/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.9305 - loss: 0.2302 - val_accuracy: 0.8200 - val_loss: 0.2956\n",
            "Epoch 446/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 958ms/step - accuracy: 0.8884 - loss: 0.2323 - val_accuracy: 0.7400 - val_loss: 0.4931\n",
            "Epoch 447/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 961ms/step - accuracy: 0.9189 - loss: 0.2255 - val_accuracy: 0.8800 - val_loss: 0.2681\n",
            "Epoch 448/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 954ms/step - accuracy: 0.8917 - loss: 0.2711 - val_accuracy: 0.7800 - val_loss: 0.4056\n",
            "Epoch 449/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 941ms/step - accuracy: 0.9363 - loss: 0.1897 - val_accuracy: 0.7400 - val_loss: 0.5189\n",
            "Epoch 450/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8735 - loss: 0.2486 - val_accuracy: 0.8000 - val_loss: 0.3446\n",
            "Epoch 451/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 979ms/step - accuracy: 0.8728 - loss: 0.2677 - val_accuracy: 0.7400 - val_loss: 0.5084\n",
            "Epoch 452/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 960ms/step - accuracy: 0.9184 - loss: 0.2405 - val_accuracy: 0.7800 - val_loss: 0.3202\n",
            "Epoch 453/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 935ms/step - accuracy: 0.8998 - loss: 0.2398 - val_accuracy: 0.8400 - val_loss: 0.2073\n",
            "Epoch 454/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.9361 - loss: 0.2040 - val_accuracy: 0.8600 - val_loss: 0.2753\n",
            "Epoch 455/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 990ms/step - accuracy: 0.8787 - loss: 0.2671 - val_accuracy: 0.7000 - val_loss: 0.6262\n",
            "Epoch 456/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 948ms/step - accuracy: 0.9003 - loss: 0.2352 - val_accuracy: 0.7400 - val_loss: 0.5530\n",
            "Epoch 457/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9063 - loss: 0.2703 - val_accuracy: 0.8200 - val_loss: 0.2987\n",
            "Epoch 458/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 939ms/step - accuracy: 0.8983 - loss: 0.2396 - val_accuracy: 0.6800 - val_loss: 0.9634\n",
            "Epoch 459/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.8737 - loss: 0.2538 - val_accuracy: 0.8200 - val_loss: 0.3438\n",
            "Epoch 460/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 933ms/step - accuracy: 0.9264 - loss: 0.1959 - val_accuracy: 0.7200 - val_loss: 0.6459\n",
            "Epoch 461/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.9197 - loss: 0.2450 - val_accuracy: 0.7200 - val_loss: 0.7793\n",
            "Epoch 462/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.9172 - loss: 0.1859 - val_accuracy: 0.7800 - val_loss: 0.5544\n",
            "Epoch 463/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 937ms/step - accuracy: 0.9196 - loss: 0.1999 - val_accuracy: 0.8200 - val_loss: 0.2843\n",
            "Epoch 464/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9109 - loss: 0.2038 - val_accuracy: 0.7600 - val_loss: 0.5249\n",
            "Epoch 465/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.9149 - loss: 0.2474 - val_accuracy: 0.8400 - val_loss: 0.2519\n",
            "Epoch 466/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 964ms/step - accuracy: 0.8954 - loss: 0.2252 - val_accuracy: 0.8200 - val_loss: 0.3362\n",
            "Epoch 467/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 961ms/step - accuracy: 0.9029 - loss: 0.1991 - val_accuracy: 0.7400 - val_loss: 0.5671\n",
            "Epoch 468/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 957ms/step - accuracy: 0.9121 - loss: 0.1981 - val_accuracy: 0.8000 - val_loss: 0.3588\n",
            "Epoch 469/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.9227 - loss: 0.1807 - val_accuracy: 0.8000 - val_loss: 0.4357\n",
            "Epoch 470/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 972ms/step - accuracy: 0.9278 - loss: 0.1851 - val_accuracy: 0.7800 - val_loss: 0.4498\n",
            "Epoch 471/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8932 - loss: 0.2397 - val_accuracy: 0.8400 - val_loss: 0.3589\n",
            "Epoch 472/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.9020 - loss: 0.2420 - val_accuracy: 0.7400 - val_loss: 0.6931\n",
            "Epoch 473/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 945ms/step - accuracy: 0.9294 - loss: 0.1910 - val_accuracy: 0.7400 - val_loss: 0.5401\n",
            "Epoch 474/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9114 - loss: 0.2133 - val_accuracy: 0.9200 - val_loss: 0.1518\n",
            "Epoch 475/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.9199 - loss: 0.2607 - val_accuracy: 0.8200 - val_loss: 0.3358\n",
            "Epoch 476/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 977ms/step - accuracy: 0.8788 - loss: 0.2763 - val_accuracy: 0.8800 - val_loss: 0.3295\n",
            "Epoch 477/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 935ms/step - accuracy: 0.9184 - loss: 0.2552 - val_accuracy: 0.8600 - val_loss: 0.2912\n",
            "Epoch 478/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.9182 - loss: 0.1803 - val_accuracy: 0.7400 - val_loss: 0.5210\n",
            "Epoch 479/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 925ms/step - accuracy: 0.8732 - loss: 0.2493 - val_accuracy: 0.9200 - val_loss: 0.1736\n",
            "Epoch 480/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 918ms/step - accuracy: 0.8961 - loss: 0.2230 - val_accuracy: 0.8200 - val_loss: 0.2654\n",
            "Epoch 481/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 958ms/step - accuracy: 0.9382 - loss: 0.1884 - val_accuracy: 0.8800 - val_loss: 0.3000\n",
            "Epoch 482/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.9223 - loss: 0.1836 - val_accuracy: 0.8800 - val_loss: 0.2027\n",
            "Epoch 483/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 940ms/step - accuracy: 0.9249 - loss: 0.1825 - val_accuracy: 0.8800 - val_loss: 0.2891\n",
            "Epoch 484/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 953ms/step - accuracy: 0.9288 - loss: 0.1898 - val_accuracy: 0.8400 - val_loss: 0.2913\n",
            "Epoch 485/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 935ms/step - accuracy: 0.9166 - loss: 0.2057 - val_accuracy: 0.8800 - val_loss: 0.2522\n",
            "Epoch 486/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 947ms/step - accuracy: 0.8800 - loss: 0.2568 - val_accuracy: 0.8200 - val_loss: 0.2653\n",
            "Epoch 487/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 932ms/step - accuracy: 0.9028 - loss: 0.2329 - val_accuracy: 0.8400 - val_loss: 0.2268\n",
            "Epoch 488/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.9061 - loss: 0.2284 - val_accuracy: 0.7400 - val_loss: 0.5758\n",
            "Epoch 489/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 938ms/step - accuracy: 0.8936 - loss: 0.2623 - val_accuracy: 0.9200 - val_loss: 0.1817\n",
            "Epoch 490/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 946ms/step - accuracy: 0.9085 - loss: 0.2283 - val_accuracy: 0.8000 - val_loss: 0.3943\n",
            "Epoch 491/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 942ms/step - accuracy: 0.8908 - loss: 0.2227 - val_accuracy: 0.9000 - val_loss: 0.1746\n",
            "Epoch 492/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 946ms/step - accuracy: 0.9140 - loss: 0.2081 - val_accuracy: 0.8200 - val_loss: 0.3347\n",
            "Epoch 493/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9038 - loss: 0.2374 - val_accuracy: 0.8800 - val_loss: 0.2290\n",
            "Epoch 494/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 947ms/step - accuracy: 0.9288 - loss: 0.2081 - val_accuracy: 0.8000 - val_loss: 0.3741\n",
            "Epoch 495/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 999ms/step - accuracy: 0.9021 - loss: 0.2119 - val_accuracy: 0.9600 - val_loss: 0.0928\n",
            "Epoch 496/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 969ms/step - accuracy: 0.9099 - loss: 0.2055 - val_accuracy: 0.9200 - val_loss: 0.1679\n",
            "Epoch 497/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.9333 - loss: 0.1929 - val_accuracy: 0.8000 - val_loss: 0.3892\n",
            "Epoch 498/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 941ms/step - accuracy: 0.9078 - loss: 0.2261 - val_accuracy: 0.8600 - val_loss: 0.3645\n",
            "Epoch 499/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 942ms/step - accuracy: 0.8991 - loss: 0.2104 - val_accuracy: 0.9400 - val_loss: 0.1587\n",
            "Epoch 500/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 935ms/step - accuracy: 0.9357 - loss: 0.1721 - val_accuracy: 0.8800 - val_loss: 0.2489\n",
            "Epoch 501/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 931ms/step - accuracy: 0.9114 - loss: 0.2226 - val_accuracy: 0.8200 - val_loss: 0.3845\n",
            "Epoch 502/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 944ms/step - accuracy: 0.9015 - loss: 0.2232 - val_accuracy: 0.9200 - val_loss: 0.1701\n",
            "Epoch 503/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.9025 - loss: 0.2302 - val_accuracy: 0.8000 - val_loss: 0.4582\n",
            "Epoch 504/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 932ms/step - accuracy: 0.9358 - loss: 0.1712 - val_accuracy: 0.8800 - val_loss: 0.2927\n",
            "Epoch 505/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 942ms/step - accuracy: 0.9152 - loss: 0.2131 - val_accuracy: 0.8800 - val_loss: 0.2786\n",
            "Epoch 506/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 946ms/step - accuracy: 0.9133 - loss: 0.2311 - val_accuracy: 0.8000 - val_loss: 0.3490\n",
            "Epoch 507/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 941ms/step - accuracy: 0.9235 - loss: 0.2141 - val_accuracy: 0.7400 - val_loss: 0.6432\n",
            "Epoch 508/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 937ms/step - accuracy: 0.9339 - loss: 0.1763 - val_accuracy: 0.8000 - val_loss: 0.4001\n",
            "Epoch 509/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 948ms/step - accuracy: 0.9031 - loss: 0.2415 - val_accuracy: 0.9400 - val_loss: 0.1509\n",
            "Epoch 510/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 957ms/step - accuracy: 0.9329 - loss: 0.1870 - val_accuracy: 0.8800 - val_loss: 0.2438\n",
            "Epoch 511/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 995ms/step - accuracy: 0.9225 - loss: 0.1999 - val_accuracy: 0.9600 - val_loss: 0.0896\n",
            "Epoch 512/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 992ms/step - accuracy: 0.9040 - loss: 0.2518 - val_accuracy: 0.7800 - val_loss: 0.4144\n",
            "Epoch 513/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 958ms/step - accuracy: 0.9121 - loss: 0.2234 - val_accuracy: 0.9200 - val_loss: 0.1979\n",
            "Epoch 514/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 953ms/step - accuracy: 0.9150 - loss: 0.2026 - val_accuracy: 0.9200 - val_loss: 0.2169\n",
            "Epoch 515/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 968ms/step - accuracy: 0.9385 - loss: 0.1818 - val_accuracy: 0.8200 - val_loss: 0.3168\n",
            "Epoch 516/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 948ms/step - accuracy: 0.9081 - loss: 0.2378 - val_accuracy: 0.9000 - val_loss: 0.2045\n",
            "Epoch 517/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 971ms/step - accuracy: 0.9334 - loss: 0.1706 - val_accuracy: 0.6800 - val_loss: 1.2397\n",
            "Epoch 518/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 943ms/step - accuracy: 0.9277 - loss: 0.2098 - val_accuracy: 0.7000 - val_loss: 1.0957\n",
            "Epoch 519/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 955ms/step - accuracy: 0.9214 - loss: 0.1942 - val_accuracy: 0.7600 - val_loss: 0.4785\n",
            "Epoch 520/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 950ms/step - accuracy: 0.9294 - loss: 0.1857 - val_accuracy: 0.7200 - val_loss: 0.6285\n",
            "Epoch 521/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 966ms/step - accuracy: 0.9165 - loss: 0.1881 - val_accuracy: 0.7400 - val_loss: 0.6244\n",
            "Epoch 522/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 949ms/step - accuracy: 0.9178 - loss: 0.1908 - val_accuracy: 0.7400 - val_loss: 0.6195\n",
            "Epoch 523/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 948ms/step - accuracy: 0.9078 - loss: 0.2091 - val_accuracy: 0.7600 - val_loss: 0.5309\n",
            "Epoch 524/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 951ms/step - accuracy: 0.8918 - loss: 0.3253 - val_accuracy: 0.8200 - val_loss: 0.3432\n",
            "Epoch 525/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 949ms/step - accuracy: 0.8827 - loss: 0.2720 - val_accuracy: 0.7800 - val_loss: 0.4418\n",
            "Epoch 526/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 933ms/step - accuracy: 0.9248 - loss: 0.1880 - val_accuracy: 0.7400 - val_loss: 0.5748\n",
            "Epoch 527/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.9477 - loss: 0.1468 - val_accuracy: 0.8400 - val_loss: 0.2477\n",
            "Epoch 528/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 989ms/step - accuracy: 0.9205 - loss: 0.2234 - val_accuracy: 0.7600 - val_loss: 0.6169\n",
            "Epoch 529/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 956ms/step - accuracy: 0.9020 - loss: 0.2276 - val_accuracy: 0.7600 - val_loss: 0.5061\n",
            "Epoch 530/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 940ms/step - accuracy: 0.9222 - loss: 0.2153 - val_accuracy: 0.7800 - val_loss: 0.4422\n",
            "Epoch 531/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 942ms/step - accuracy: 0.9248 - loss: 0.2067 - val_accuracy: 0.7800 - val_loss: 0.4222\n",
            "Epoch 532/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 966ms/step - accuracy: 0.9271 - loss: 0.2110 - val_accuracy: 0.7800 - val_loss: 0.4713\n",
            "Epoch 533/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 941ms/step - accuracy: 0.9036 - loss: 0.2338 - val_accuracy: 0.7600 - val_loss: 0.5521\n",
            "Epoch 534/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.9290 - loss: 0.1852 - val_accuracy: 0.7600 - val_loss: 0.5055\n",
            "Epoch 535/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 956ms/step - accuracy: 0.9104 - loss: 0.2048 - val_accuracy: 0.8400 - val_loss: 0.2828\n",
            "Epoch 536/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 940ms/step - accuracy: 0.9169 - loss: 0.2154 - val_accuracy: 0.7400 - val_loss: 0.5892\n",
            "Epoch 537/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 946ms/step - accuracy: 0.8992 - loss: 0.2412 - val_accuracy: 0.8400 - val_loss: 0.2448\n",
            "Epoch 538/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 940ms/step - accuracy: 0.8993 - loss: 0.2187 - val_accuracy: 0.7800 - val_loss: 0.4652\n",
            "Epoch 539/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 963ms/step - accuracy: 0.9002 - loss: 0.2034 - val_accuracy: 0.8400 - val_loss: 0.2582\n",
            "Epoch 540/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9004 - loss: 0.2192 - val_accuracy: 0.8200 - val_loss: 0.2725\n",
            "Epoch 541/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.9231 - loss: 0.1781 - val_accuracy: 0.7600 - val_loss: 0.4310\n",
            "Epoch 542/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 950ms/step - accuracy: 0.9227 - loss: 0.2114 - val_accuracy: 0.7600 - val_loss: 0.4320\n",
            "Epoch 543/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 975ms/step - accuracy: 0.9163 - loss: 0.2006 - val_accuracy: 0.7800 - val_loss: 0.4669\n",
            "Epoch 544/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 952ms/step - accuracy: 0.9250 - loss: 0.1750 - val_accuracy: 0.9000 - val_loss: 0.2994\n",
            "Epoch 545/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 972ms/step - accuracy: 0.9274 - loss: 0.1822 - val_accuracy: 0.8600 - val_loss: 0.2729\n",
            "Epoch 546/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 931ms/step - accuracy: 0.9090 - loss: 0.2084 - val_accuracy: 0.8800 - val_loss: 0.3587\n",
            "Epoch 547/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 942ms/step - accuracy: 0.9175 - loss: 0.2031 - val_accuracy: 0.8400 - val_loss: 0.3192\n",
            "Epoch 548/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 950ms/step - accuracy: 0.9315 - loss: 0.1657 - val_accuracy: 0.7200 - val_loss: 0.7650\n",
            "Epoch 549/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 918ms/step - accuracy: 0.9199 - loss: 0.2042 - val_accuracy: 0.8200 - val_loss: 0.3916\n",
            "Epoch 550/550\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.9345 - loss: 0.1963 - val_accuracy: 0.9600 - val_loss: 0.0940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Set paths to your folders\n",
        "train_dir = '/content/drive/MyDrive/spectrograms/train'\n",
        "val_dir = '/content/drive/MyDrive/spectrograms/validate'\n",
        "\n",
        "# Set image parameters\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Data Augmentation and Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'  # Binary classification\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'  # Binary classification\n",
        ")\n",
        "\n",
        "# Load pre-trained ResNet50 model + higher level layers for fine-tuning\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "# Freeze base model layers (optional, if fine-tuning you can unfreeze some layers later)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top of ResNet50\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Unfreeze the base model and fine-tune if necessary\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:140]:  # Unfreeze the last few layers\n",
        "    layer.trainable = False\n",
        "\n",
        "# Recompile the model after unfreezing\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continue training (fine-tuning)\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/CNN/best_model.keras\", monitor=\"val_loss\", save_best_only=True)\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=550,\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "# Save the model after fine-tuning\n",
        "model.save('/content/drive/MyDrive/CNN/fine_tuned_resnet_psd_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Set paths to your folders\n",
        "train_dir = '/content/drive/MyDrive/spectrograms/train'\n",
        "val_dir = '/content/drive/MyDrive/spectrograms/validate'\n",
        "\n",
        "# Set image parameters\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Data Augmentation and Preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'  # Binary classification\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'  # Binary classification\n",
        ")\n",
        "\n",
        "# Load the best saved model\n",
        "base_model = load_model(\"/content/drive/MyDrive/CNN/fine_tuned_resnet_psd_model-8.h5\")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:140]:  # Unfreeze the last few layers\n",
        "    layer.trainable = False\n",
        "base_model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history_continue = base_model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,  # or however many more epochs you want\n",
        "    validation_data=validation_generator,\n",
        "    verbose=1,\n",
        "    callbacks=[ModelCheckpoint(\"/content/drive/MyDrive/CNN/fine_tuned_resnet_psd_model-9.h5\", monitor=\"val_loss\", save_best_only=True)]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyTfEvy5hRky",
        "outputId": "5f9afd71-057f-432e-c3d3-17a2c5ac7c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 459 images belonging to 2 classes.\n",
            "Found 50 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9309 - loss: 0.1514"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 1s/step - accuracy: 0.9304 - loss: 0.1522 - val_accuracy: 0.8600 - val_loss: 0.3769\n",
            "Epoch 2/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819ms/step - accuracy: 0.9055 - loss: 0.1801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9061 - loss: 0.1804 - val_accuracy: 0.9400 - val_loss: 0.0947\n",
            "Epoch 3/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9163 - loss: 0.1810 - val_accuracy: 0.9400 - val_loss: 0.1562\n",
            "Epoch 4/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - accuracy: 0.9482 - loss: 0.1695"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.9481 - loss: 0.1695 - val_accuracy: 0.9600 - val_loss: 0.0880\n",
            "Epoch 5/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 933ms/step - accuracy: 0.9393 - loss: 0.1521 - val_accuracy: 0.9000 - val_loss: 0.1763\n",
            "Epoch 6/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 910ms/step - accuracy: 0.9164 - loss: 0.1806 - val_accuracy: 0.9400 - val_loss: 0.1538\n",
            "Epoch 7/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 914ms/step - accuracy: 0.9432 - loss: 0.1534 - val_accuracy: 0.9400 - val_loss: 0.1051\n",
            "Epoch 8/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 916ms/step - accuracy: 0.9050 - loss: 0.1967 - val_accuracy: 0.8400 - val_loss: 0.4256\n",
            "Epoch 9/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 919ms/step - accuracy: 0.9276 - loss: 0.2158 - val_accuracy: 0.8800 - val_loss: 0.3445\n",
            "Epoch 10/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 908ms/step - accuracy: 0.9413 - loss: 0.1511 - val_accuracy: 0.9000 - val_loss: 0.2788\n",
            "Epoch 11/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 921ms/step - accuracy: 0.9288 - loss: 0.1755 - val_accuracy: 0.8000 - val_loss: 0.5108\n",
            "Epoch 12/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 910ms/step - accuracy: 0.9205 - loss: 0.1725 - val_accuracy: 0.9400 - val_loss: 0.1664\n",
            "Epoch 13/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 917ms/step - accuracy: 0.9203 - loss: 0.1852 - val_accuracy: 0.9000 - val_loss: 0.2370\n",
            "Epoch 14/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 913ms/step - accuracy: 0.9308 - loss: 0.1709 - val_accuracy: 0.7600 - val_loss: 0.6135\n",
            "Epoch 15/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.9378 - loss: 0.1785 - val_accuracy: 0.8600 - val_loss: 0.2648\n",
            "Epoch 16/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 925ms/step - accuracy: 0.9387 - loss: 0.1760 - val_accuracy: 0.8200 - val_loss: 0.4503\n",
            "Epoch 17/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 915ms/step - accuracy: 0.9209 - loss: 0.1829 - val_accuracy: 0.7600 - val_loss: 0.7915\n",
            "Epoch 18/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 907ms/step - accuracy: 0.9182 - loss: 0.1859 - val_accuracy: 0.8400 - val_loss: 0.3669\n",
            "Epoch 19/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 911ms/step - accuracy: 0.9347 - loss: 0.1826 - val_accuracy: 0.7800 - val_loss: 0.5958\n",
            "Epoch 20/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 914ms/step - accuracy: 0.9265 - loss: 0.1565 - val_accuracy: 0.8800 - val_loss: 0.3556\n",
            "Epoch 21/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 914ms/step - accuracy: 0.9445 - loss: 0.1616 - val_accuracy: 0.8800 - val_loss: 0.3112\n",
            "Epoch 22/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 906ms/step - accuracy: 0.9477 - loss: 0.1552 - val_accuracy: 0.9200 - val_loss: 0.2228\n",
            "Epoch 23/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 904ms/step - accuracy: 0.9344 - loss: 0.1877 - val_accuracy: 0.8800 - val_loss: 0.3274\n",
            "Epoch 24/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 909ms/step - accuracy: 0.9361 - loss: 0.1438 - val_accuracy: 0.8200 - val_loss: 0.4626\n",
            "Epoch 25/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 916ms/step - accuracy: 0.9543 - loss: 0.1443 - val_accuracy: 0.9400 - val_loss: 0.1891\n",
            "Epoch 26/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 902ms/step - accuracy: 0.9267 - loss: 0.2526 - val_accuracy: 0.9200 - val_loss: 0.2253\n",
            "Epoch 27/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 911ms/step - accuracy: 0.9173 - loss: 0.1984 - val_accuracy: 0.9200 - val_loss: 0.1722\n",
            "Epoch 28/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.8998 - loss: 0.2309 - val_accuracy: 0.8800 - val_loss: 0.3908\n",
            "Epoch 29/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 911ms/step - accuracy: 0.9378 - loss: 0.1972 - val_accuracy: 0.9200 - val_loss: 0.1298\n",
            "Epoch 30/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 899ms/step - accuracy: 0.9323 - loss: 0.1557 - val_accuracy: 0.9200 - val_loss: 0.1977\n",
            "Epoch 31/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825ms/step - accuracy: 0.9207 - loss: 0.1789"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9213 - loss: 0.1779 - val_accuracy: 0.9400 - val_loss: 0.0696\n",
            "Epoch 32/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.9262 - loss: 0.2063 - val_accuracy: 0.8800 - val_loss: 0.2505\n",
            "Epoch 33/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 905ms/step - accuracy: 0.9487 - loss: 0.1642 - val_accuracy: 0.9200 - val_loss: 0.1482\n",
            "Epoch 34/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 923ms/step - accuracy: 0.9307 - loss: 0.1475 - val_accuracy: 0.8800 - val_loss: 0.2529\n",
            "Epoch 35/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 910ms/step - accuracy: 0.9426 - loss: 0.1415 - val_accuracy: 0.9000 - val_loss: 0.2247\n",
            "Epoch 36/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830ms/step - accuracy: 0.8925 - loss: 0.1817"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.8931 - loss: 0.1817 - val_accuracy: 0.9600 - val_loss: 0.0654\n",
            "Epoch 37/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.9380 - loss: 0.1318 - val_accuracy: 0.9200 - val_loss: 0.2750\n",
            "Epoch 38/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 931ms/step - accuracy: 0.9444 - loss: 0.1550 - val_accuracy: 0.9200 - val_loss: 0.1440\n",
            "Epoch 39/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 915ms/step - accuracy: 0.9468 - loss: 0.1509 - val_accuracy: 0.8400 - val_loss: 0.4537\n",
            "Epoch 40/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 908ms/step - accuracy: 0.9328 - loss: 0.1819 - val_accuracy: 0.8800 - val_loss: 0.2589\n",
            "Epoch 41/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 895ms/step - accuracy: 0.9274 - loss: 0.1730 - val_accuracy: 0.9200 - val_loss: 0.1727\n",
            "Epoch 42/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.9538 - loss: 0.1399 - val_accuracy: 0.9200 - val_loss: 0.2244\n",
            "Epoch 43/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.9305 - loss: 0.1570 - val_accuracy: 0.9200 - val_loss: 0.2561\n",
            "Epoch 44/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 907ms/step - accuracy: 0.9442 - loss: 0.1466 - val_accuracy: 0.8400 - val_loss: 0.3210\n",
            "Epoch 45/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 900ms/step - accuracy: 0.9330 - loss: 0.1574 - val_accuracy: 0.9200 - val_loss: 0.2559\n",
            "Epoch 46/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 939ms/step - accuracy: 0.9463 - loss: 0.1634 - val_accuracy: 0.9200 - val_loss: 0.1598\n",
            "Epoch 47/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 914ms/step - accuracy: 0.9185 - loss: 0.1697 - val_accuracy: 0.8800 - val_loss: 0.3749\n",
            "Epoch 48/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 904ms/step - accuracy: 0.9215 - loss: 0.1654 - val_accuracy: 0.9200 - val_loss: 0.1253\n",
            "Epoch 49/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 917ms/step - accuracy: 0.9504 - loss: 0.1474 - val_accuracy: 0.9400 - val_loss: 0.1377\n",
            "Epoch 50/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 914ms/step - accuracy: 0.9361 - loss: 0.1589 - val_accuracy: 0.8400 - val_loss: 0.3445\n",
            "Epoch 51/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.9422 - loss: 0.1613 - val_accuracy: 0.8600 - val_loss: 0.3038\n",
            "Epoch 52/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 901ms/step - accuracy: 0.9364 - loss: 0.1935 - val_accuracy: 0.9200 - val_loss: 0.1183\n",
            "Epoch 53/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.9196 - loss: 0.1901 - val_accuracy: 0.8800 - val_loss: 0.3593\n",
            "Epoch 54/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.9231 - loss: 0.1593 - val_accuracy: 0.9200 - val_loss: 0.3608\n",
            "Epoch 55/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.9383 - loss: 0.1512 - val_accuracy: 0.9400 - val_loss: 0.1297\n",
            "Epoch 56/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 912ms/step - accuracy: 0.9499 - loss: 0.1336 - val_accuracy: 0.9200 - val_loss: 0.2066\n",
            "Epoch 57/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 916ms/step - accuracy: 0.9119 - loss: 0.2110 - val_accuracy: 0.9400 - val_loss: 0.1198\n",
            "Epoch 58/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.9085 - loss: 0.2056 - val_accuracy: 0.9200 - val_loss: 0.2635\n",
            "Epoch 59/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 926ms/step - accuracy: 0.9534 - loss: 0.1251 - val_accuracy: 0.9200 - val_loss: 0.1556\n",
            "Epoch 60/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 930ms/step - accuracy: 0.9237 - loss: 0.2166 - val_accuracy: 0.9400 - val_loss: 0.0977\n",
            "Epoch 61/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 916ms/step - accuracy: 0.9351 - loss: 0.1904 - val_accuracy: 0.9400 - val_loss: 0.1252\n",
            "Epoch 62/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.9299 - loss: 0.1646 - val_accuracy: 0.9400 - val_loss: 0.1256\n",
            "Epoch 63/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 903ms/step - accuracy: 0.9132 - loss: 0.1711 - val_accuracy: 0.9200 - val_loss: 0.1335\n",
            "Epoch 64/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 910ms/step - accuracy: 0.9531 - loss: 0.1290 - val_accuracy: 0.8800 - val_loss: 0.3305\n",
            "Epoch 65/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 903ms/step - accuracy: 0.9526 - loss: 0.1314 - val_accuracy: 0.9200 - val_loss: 0.1610\n",
            "Epoch 66/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818ms/step - accuracy: 0.9362 - loss: 0.1660"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.9361 - loss: 0.1661 - val_accuracy: 0.9400 - val_loss: 0.0509\n",
            "Epoch 67/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.8917 - loss: 0.2493 - val_accuracy: 0.9600 - val_loss: 0.1046\n",
            "Epoch 68/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 904ms/step - accuracy: 0.9329 - loss: 0.1645 - val_accuracy: 0.9400 - val_loss: 0.1103\n",
            "Epoch 69/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 905ms/step - accuracy: 0.9350 - loss: 0.1872 - val_accuracy: 0.9400 - val_loss: 0.1083\n",
            "Epoch 70/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.9140 - loss: 0.1947 - val_accuracy: 0.9200 - val_loss: 0.2046\n",
            "Epoch 71/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 920ms/step - accuracy: 0.9323 - loss: 0.1734 - val_accuracy: 0.9200 - val_loss: 0.1525\n",
            "Epoch 72/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 901ms/step - accuracy: 0.9453 - loss: 0.1380 - val_accuracy: 0.8800 - val_loss: 0.2694\n",
            "Epoch 73/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 910ms/step - accuracy: 0.9465 - loss: 0.1717 - val_accuracy: 0.9200 - val_loss: 0.1952\n",
            "Epoch 74/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 925ms/step - accuracy: 0.9597 - loss: 0.1379 - val_accuracy: 0.8400 - val_loss: 0.2882\n",
            "Epoch 75/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 924ms/step - accuracy: 0.9460 - loss: 0.1553 - val_accuracy: 0.9000 - val_loss: 0.1618\n",
            "Epoch 76/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 913ms/step - accuracy: 0.8875 - loss: 0.2341 - val_accuracy: 0.8200 - val_loss: 0.4224\n",
            "Epoch 77/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 917ms/step - accuracy: 0.9250 - loss: 0.1656 - val_accuracy: 0.9000 - val_loss: 0.2166\n",
            "Epoch 78/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 923ms/step - accuracy: 0.9365 - loss: 0.1811 - val_accuracy: 0.8800 - val_loss: 0.2947\n",
            "Epoch 79/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848ms/step - accuracy: 0.9394 - loss: 0.1785"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.9390 - loss: 0.1791 - val_accuracy: 1.0000 - val_loss: 0.0274\n",
            "Epoch 80/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.9258 - loss: 0.2065 - val_accuracy: 0.9600 - val_loss: 0.1212\n",
            "Epoch 81/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 913ms/step - accuracy: 0.9366 - loss: 0.1584 - val_accuracy: 0.9400 - val_loss: 0.1287\n",
            "Epoch 82/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 928ms/step - accuracy: 0.9175 - loss: 0.1697 - val_accuracy: 0.9400 - val_loss: 0.1443\n",
            "Epoch 83/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 932ms/step - accuracy: 0.9428 - loss: 0.1553 - val_accuracy: 0.9400 - val_loss: 0.1356\n",
            "Epoch 84/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 929ms/step - accuracy: 0.9475 - loss: 0.1380 - val_accuracy: 0.9400 - val_loss: 0.1064\n",
            "Epoch 85/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 947ms/step - accuracy: 0.9423 - loss: 0.1544 - val_accuracy: 0.8400 - val_loss: 0.3491\n",
            "Epoch 86/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 985ms/step - accuracy: 0.9460 - loss: 0.1495 - val_accuracy: 0.8800 - val_loss: 0.2468\n",
            "Epoch 87/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.9515 - loss: 0.1714 - val_accuracy: 0.9400 - val_loss: 0.1070\n",
            "Epoch 88/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 918ms/step - accuracy: 0.9068 - loss: 0.1862 - val_accuracy: 0.9600 - val_loss: 0.1068\n",
            "Epoch 89/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 907ms/step - accuracy: 0.9388 - loss: 0.1546 - val_accuracy: 0.9400 - val_loss: 0.1203\n",
            "Epoch 90/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 916ms/step - accuracy: 0.9238 - loss: 0.1804 - val_accuracy: 0.9200 - val_loss: 0.2199\n",
            "Epoch 91/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 934ms/step - accuracy: 0.9277 - loss: 0.1719 - val_accuracy: 0.9200 - val_loss: 0.2191\n",
            "Epoch 92/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 930ms/step - accuracy: 0.9485 - loss: 0.1298 - val_accuracy: 0.9200 - val_loss: 0.1896\n",
            "Epoch 93/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.9273 - loss: 0.1780 - val_accuracy: 0.9400 - val_loss: 0.1501\n",
            "Epoch 94/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 936ms/step - accuracy: 0.9365 - loss: 0.1450 - val_accuracy: 1.0000 - val_loss: 0.0392\n",
            "Epoch 95/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 922ms/step - accuracy: 0.9255 - loss: 0.1837 - val_accuracy: 0.9200 - val_loss: 0.1614\n",
            "Epoch 96/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 914ms/step - accuracy: 0.9285 - loss: 0.1723 - val_accuracy: 0.9000 - val_loss: 0.1954\n",
            "Epoch 97/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 919ms/step - accuracy: 0.8966 - loss: 0.2436 - val_accuracy: 0.8400 - val_loss: 0.3420\n",
            "Epoch 98/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 963ms/step - accuracy: 0.9508 - loss: 0.1176 - val_accuracy: 0.8800 - val_loss: 0.2494\n",
            "Epoch 99/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.9446 - loss: 0.1446 - val_accuracy: 0.9600 - val_loss: 0.0757\n",
            "Epoch 100/100\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.9491 - loss: 0.1243 - val_accuracy: 0.9400 - val_loss: 0.0969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpxOcE8CW0lU",
        "outputId": "577b91d6-07fe-4dda-9f74-b90fb34d5cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the test directory path\n",
        "test_dir = '/content/drive/MyDrive/spectrograms/test'\n",
        "\n",
        "# Set batch size and image size\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Create a test data generator (only rescale, no augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load test images\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Binary classification\n",
        "    shuffle=False  # No shuffling to match filenames with predictions\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "QBZ9THkqH9F2",
        "outputId": "750eace7-6b80-40f9-b399-8dd73ae434c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0b0da5767b87>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m  \u001b[0;31m# Binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Print the final test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "\n",
        "val_dir = '/content/drive/MyDrive/spectrograms/validate'\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary'  # Binary classification\n",
        ")\n",
        "test_loss, test_acc = best_model.evaluate(validation_generator)\n",
        "\n",
        "# Print the final test accuracy\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save model cnn model using keras.models\n",
        "\n",
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Assuming 'model' is your trained Keras model\n",
        "save_model(model, '/content/drive/MyDrive/CNN/cnn_model8923.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkEExYOTimmm",
        "outputId": "8f3819c7-917e-41dc-bd82-68222304df39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo7ktI_tKdMg",
        "outputId": "3db71071-17c0-44b2-973b-012b77c7c7bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.9507 - loss: 0.1050\n",
            "Validation Loss: 0.08960086107254028, Validation Accuracy: 0.9599999785423279\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best saved model\n",
        "best_model = load_model(\"/content/drive/MyDrive/CNN/best_model.keras\")\n",
        "\n",
        "# Now you can evaluate or use it for predictions\n",
        "loss, accuracy = best_model.evaluate(validation_generator)\n",
        "print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLMly0UP-OAy",
        "outputId": "d0f04fce-acd0-406a-9577-21b4d0ec45c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_dir = '/content/drive/MyDrive/spectrograms/test/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Just normalization\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important if you want to match predictions to filenames\n",
        ")\n",
        "#7= 8769"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXWiToLEASge",
        "outputId": "df809088-0ca5-471e-9efd-1d6f937baf33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8886 - loss: 0.2145\n",
            "Test Accuracy: 0.8900, Test Loss: 0.2238\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "test_loss, test_acc = best_model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Predict\n",
        "predictions = best_model.predict(test_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "w6hg_DubAV86",
        "outputId": "7a9bb3af-439b-4234-f462-8c70e9cde12a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 624ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90        53\n",
            "           1       0.88      0.89      0.88        47\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.89      0.89      0.89       100\n",
            "weighted avg       0.89      0.89      0.89       100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = test_generator.classes\n",
        "y_pred = (best_model.predict(test_generator) > 0.5).astype(int).flatten()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q-oEGEVLAm_t",
        "outputId": "996a69ec-a676-4f17-e953-031cc48cba9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90        53\n",
            "           1       0.88      0.89      0.88        47\n",
            "\n",
            "    accuracy                           0.89       100\n",
            "   macro avg       0.89      0.89      0.89       100\n",
            "weighted avg       0.89      0.89      0.89       100\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Paths\n",
        "model_path = \"/content/drive/MyDrive/CNN/best_model.keras\"\n",
        "test_dir = '/content/drive/MyDrive/spectrograms/test'\n",
        "\n",
        "# Image dimensions and batch size (should match training)\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Load model\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Data preprocessing for test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important for matching predictions with ground truth\n",
        ")\n",
        "\n",
        "# Get ground truth and predicted probabilities\n",
        "y_true = test_generator.classes\n",
        "y_scores = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Optional: Classification report and confusion matrix\n",
        "y_pred = (y_scores > 0.5).astype(int).flatten()\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u59EKjBCA7D7"
      },
      "outputs": [],
      "source": [
        "filet = h5py.File(\"/content/drive/MyDrive/signal data/test-data.h5\", \"r\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file6 = h5py.File(\"/content/drive/MyDrive/signal data/benign-single.h5\", \"r\")\n",
        "file7 = h5py.File(\"/content/drive/MyDrive/signal data/infected-single.h5\", \"r\")\n",
        "file8 = h5py.File(\"/content/drive/MyDrive/signal data/benign-gamesall.h5\", \"r\")\n",
        "file9 = h5py.File(\"/content/drive/MyDrive/signal data/infected-gamesall.h5\", \"r\")"
      ],
      "metadata": {
        "id": "AahB91kwAwK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(file7.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNAXQ-2pieqq",
        "outputId": "747a6883-32d3-4add-e9c4-32592635ccc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "RRKoSQe2A0ZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRlcbvQHcVLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22511a8-6c2d-4302-e5fe-6e7e669db50a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spectrogram for infected-idle0 saved to /content/drive/MyDrive/spectrograms/infected-single/test/1/z5noise-infected-idle0.png\n",
            "Spectrogram for infected-idle1 saved to /content/drive/MyDrive/spectrograms/infected-single/test/1/z5noise-infected-idle1.png\n",
            "Spectrogram for infected-idle2 saved to /content/drive/MyDrive/spectrograms/infected-single/test/1/z5noise-infected-idle2.png\n",
            "Spectrogram for infected-idle3 saved to /content/drive/MyDrive/spectrograms/infected-single/test/1/z5noise-infected-idle3.png\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gc\n",
        "import scipy.signal as signal  # Ensure signal is properly imported\n",
        "\n",
        "# Create the new folder if it doesn't exist\n",
        "output_folder = \"/content/drive/MyDrive/spectrograms/infected-single/test/1\"\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "keys = file7.keys()\n",
        "for key in list(keys):\n",
        "    try:\n",
        "        signal_data = file7[key]  # Load data\n",
        "        fig = plt.figure()\n",
        "        plt.psd(signal_data, NFFT=2048, Fc=12e6, Fs=20e6)\n",
        "        output_filename = os.path.join(output_folder, f\"z5noise-{key}.png\")\n",
        "        fig.savefig(output_filename, dpi=300, format=\"png\", bbox_inches=\"tight\")\n",
        "        plt.close(fig)  # Close figure to release memory\n",
        "\n",
        "        print(f\"Spectrogram for {key} saved to {output_filename}\")\n",
        "\n",
        "        gc.collect()  # Trigger garbage collection\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing key {key}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_dir = '/content/drive/MyDrive/spectrograms/benign-all/test/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Just normalization\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important if you want to match predictions to filenames\n",
        ")\n",
        "#7= 8769"
      ],
      "metadata": {
        "id": "-WFMLz98h5H8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d65ca56-46d9-479c-caea-11f1a64d83b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwgMZ7_zvNMA",
        "outputId": "730a1cb6-6e18-45c0-8b1c-5615ff86e8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = test_generator.classes\n",
        "y_pred = (best_model.predict(test_generator) > 0.5).astype(int).flatten()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "ZFZBi4jZAopK",
        "outputId": "e5c906e4-1a2a-4056-a475-ccab36dba394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       3.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       3.0\n",
            "   macro avg       0.00      0.00      0.00       3.0\n",
            "weighted avg       0.00      0.00      0.00       3.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_dir = '/content/drive/MyDrive/spectrograms/infected-all/test/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Just normalization\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important if you want to match predictions to filenames\n",
        ")\n",
        "#7= 8769"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnk-E-UtAxOW",
        "outputId": "4b2130be-bbc6-4e63-a736-bfd0cb12f6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8iUEimxkwfdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = [1,1,1]\n",
        "y_pred = (best_model.predict(test_generator) > 0.5).astype(int).flatten()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "C9kEkykXBt6d",
        "outputId": "e3db5653-b9f1-414d-9801-5b28b6874bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_dir = '/content/drive/MyDrive/spectrograms/benign-single/test/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Just normalization\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important if you want to match predictions to filenames\n",
        ")\n",
        "#7= 8769"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOFw29OSBvoe",
        "outputId": "376de48c-ff36-45f2-be60-2695cbc74983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = test_generator.classes\n",
        "y_pred = (best_model.predict(test_generator) > 0.5).astype(int).flatten()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "xncI-H4nWajV",
        "outputId": "d1a7c647-cd09-4433-be0e-83f4df91294a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAG2CAYAAADMcaSeAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKNpJREFUeJzt3X1UlWW+//HPhmSDqSQZ4HP+DubDaKhYip1faEOptUymxhznQSxzJtNSsSdalZpn2k3m2JNJZkZTY1qW6DHTYWiUHLGSpNRTnjFLrAGSMgnKLcL+/dHvMGcnKhuui83mfr9a91rDzf3w3azF8PF7Xdd9u3w+n08AAACGhAW7AAAA0LoQLgAAgFGECwAAYBThAgAAGEW4AAAARhEuAACAUYQLAABgFOECAAAYRbgAAABGES4AAIBRhAsAAFqhZcuW6eKLL1aHDh3UoUMHJScn68033zzjOa+++qr69u2ryMhIDRw4UJs2bWrUvQkXAAC0Qt26ddPDDz+swsJC7dq1S1dccYXGjx+vffv21Xv8jh07NGnSJE2dOlW7d+9WWlqa0tLStHfv3oDv7eLFZQAAOENMTIwWLVqkqVOnnvK9iRMnqqqqShs3bqzbN3z4cA0aNEhZWVkB3YfOBQAAIcLr9aqiosJv83q9Zz2vpqZGq1evVlVVlZKTk+s9pqCgQKmpqX77Ro8erYKCgoDrPCfgM0JA1OCZwS4BaJESJ04IdglAi7PznhTr9zD1d+nu8Z20YMECv33z5s3T/Pnz6z1+z549Sk5O1vHjx9WuXTutW7dO/fv3r/fY0tJSxcXF+e2Li4tTaWlpwHW2ynABAEBrlJmZqYyMDL99brf7tMf36dNHRUVFOnbsmNauXav09HRt27bttAHDFMIFAAC2uczMQnC73WcMEz8WERGhhIQESVJSUpLee+89Pf7443rmmWdOOTY+Pl5lZWV++8rKyhQfHx9wncy5AADANpfLzNZEtbW1p52jkZycrLy8PL99ubm5p52jcSZ0LgAAsM1Q5yIQmZmZGjt2rHr06KFvv/1Wq1at0tatW7VlyxZJ0uTJk9W1a1d5PB5J0qxZs5SSkqLFixfrmmuu0erVq7Vr1y4tX7484HsTLgAAaIW+/PJLTZ48WSUlJYqOjtbFF1+sLVu26Morr5QkFRcXKyzsX6FnxIgRWrVqle677z7de++96t27t3JycjRgwICA790qn3PBahGgfqwWAU7VLKtFLsk4+0EN8P17fzRyHdvoXAAAYFsQhkWCyVmfFgAAWEfnAgAA2wys9AglhAsAAGxjWAQAAKDx6FwAAGAbwyIAAMAohkUAAAAaj84FAAC2MSwCAACMctiwCOECAADbHNa5cFaUAgAA1tG5AADANoZFAACAUQ4LF876tAAAwDo6FwAA2BbmrAmdhAsAAGxjWAQAAKDx6FwAAGCbw55zQbgAAMA2hkUAAAAaj84FAAC2MSwCAACMctiwCOECAADbHNa5cFaUAgAA1tG5AADANoZFAACAUQyLAAAANB6dCwAAbGNYBAAAGMWwCAAAQOPRuQAAwDaGRQAAgFEOCxfO+rQAAMA6OhcAANjmsAmdhAsAAGxz2LAI4QIAANsc1rlwVpQCAADW0bkAAMA2hkUAAIBRDIsAAAA0Hp0LAAAsczmsc0G4AADAMqeFC4ZFAACAUXQuAACwzVmNC8IFAAC2MSwCAADQBHQuAACwzGmdC8IFAACWES4AAIBRTgsXzLkAAABGES4AALDNZWgLgMfj0SWXXKL27dsrNjZWaWlp2r9//xnPyc7Olsvl8tsiIyMDu7EIFwAAWPfjP9iN3QKxbds2zZgxQzt37lRubq6qq6t11VVXqaqq6ozndejQQSUlJXXboUOHAv68zLkAAKAV2rx5s9/X2dnZio2NVWFhoS6//PLTnudyuRQfH9+ke9O5AADAMlOdC6/Xq4qKCr/N6/U2qIZjx45JkmJiYs54XGVlpXr27Knu3btr/Pjx2rdvX8Cfl3ABAIBlpsKFx+NRdHS03+bxeM56/9raWs2ePVuXXXaZBgwYcNrj+vTpo5UrV2r9+vV66aWXVFtbqxEjRujzzz8P7PP6fD5fQGeEgKjBM4NdAtAiJU6cEOwSgBZn5z0p1u8R85tVRq5TsuL6UzoVbrdbbrf7jOdNnz5db775prZv365u3bo1+H7V1dXq16+fJk2apIULFzb4POZcAABgmannXDQkSPzYzJkztXHjRuXn5wcULCSpTZs2Gjx4sA4cOBDQeQyLAABgWxCWovp8Ps2cOVPr1q3TW2+9pV69egVcdk1Njfbs2aPOnTsHdB6dCwAAWqEZM2Zo1apVWr9+vdq3b6/S0lJJUnR0tKKioiRJkydPVteuXevmbTz44IMaPny4EhIS9M0332jRokU6dOiQbr755oDuTbgAAMCyYDz+e9myZZKkkSNH+u1//vnnNWXKFElScXGxwsL+NYhx9OhRTZs2TaWlperYsaOSkpK0Y8cO9e/fP6B7Ey4AALAsGOGiIes1tm7d6vf1kiVLtGTJkibfm3ABAIBlvLgMAACgCehcAABgm7MaF4QLAABsY1gEAACgCehcAABgmdM6F4QLAAAsc1q4YFgEAAAYRecCAADLnNa5IFwAAGCbs7IFwyIAAMAsOhcAAFjGsAgAADCKcAEAAIxyWrhgzgUAADCKzgUAALY5q3FBuAAAwDaGRQAAAJqAzgWMmzbh3zXt5/9XPbvESJI+Oliqh5a/qb/8/b+CXBkQXJOHd9fIPp3UM6atvCdrteeLCi3delDFX38f7NJgmdM6F4QLGPdF2Te6/8n1OlB8RC659Otxw/Tqkt9q+C8e1kcHS4NdHhA0g3ucp9fe/6f+q+RbhYe5NP3yXnp84sWatOI9Ha+uDXZ5sIhwATTRpvy9fl/PX/qfmjbh33Xpxb0IF3C0Oa/s8ft64Rv7tXnWCPWNb6+iw8eCVBVgXlDDRXl5uVauXKmCggKVlv7wRyc+Pl4jRozQlClTdMEFFwSzPBgQFubS9VcO0blREXrnw0+DXQ7QorRzh0uSKr6vDnIlsI3ORTN57733NHr0aLVt21apqam66KKLJEllZWV64okn9PDDD2vLli0aOnRosEpEE/wkoYu2vjBXkRHnqPJ7rybOfVYf07UA6rgkzU5N0AeHj+lg+XfBLge2OStbBC9c3HbbbZowYYKysrJOSXQ+n0+33HKLbrvtNhUUFJzxOl6vV16v1//82hq5wsKN14yG++/PyjTsFx5Ft4vSz1IH69kHf6Orbn6cgAH8f3de1Vv/dsG5+u1Lu4NdCmBc0JaifvDBB5ozZ069rSKXy6U5c+aoqKjorNfxeDyKjo72206WFVqoGIGoPlmjg4fLtfujw3rgyQ3a899faMakkcEuC2gR5l6ZoMsSYnTrqg905NsTwS4HzcDlchnZQkXQwkV8fLzefffd037/3XffVVxc3Fmvk5mZqWPHjvlt58QlmSwVBoS5XHJHMH8YmHtlglIu6qSZL3+okmPHg10OmonTwkXQ/t/+jjvu0G9/+1sVFhbqpz/9aV2QKCsrU15enp599lk9+uijZ72O2+2W2+3228eQSHA9eNu12vL3fTpcclTtz43UxLFDdfnQ3hp369PBLg0IqjuvStBV/eN012t7VXXipGLObSNJqvLWyHuSpaitWQjlAiOCFi5mzJihTp06acmSJXr66adVU1MjSQoPD1dSUpKys7N1ww03BKs8NMEFMe303MLJiu/UQccqj2vvP77QuFuf1lvvfBzs0oCgun5IV0nSsl8N8tu/8I2P9caesiBUBNjh8vl8vmAXUV1drfLycklSp06d1KZNmyZdL2rwTBNlAa1O4sQJwS4BaHF23pNi/R6979xs5Dr/WDTGyHVsaxGD4G3atFHnzp2DXQYAAFY4bViEF5cBAACjWkTnAgCA1iyUVnqYQLgAAMAyh2ULhkUAAIBZdC4AALAsLMxZrQvCBQAAljEsAgAA0AR0LgAAsIzVIgAAwCiHZQvCBQAAtjmtc8GcCwAAYBSdCwAALHNa54JwAQCAZQ7LFgyLAAAAs+hcAABgGcMiAADAKIdlC4ZFAACAWXQuAACwjGERAABglMOyBcMiAADALMIFAACWuVwuI1sgPB6PLrnkErVv316xsbFKS0vT/v37z3req6++qr59+yoyMlIDBw7Upk2bAv68hAsAACxzucxsgdi2bZtmzJihnTt3Kjc3V9XV1brqqqtUVVV12nN27NihSZMmaerUqdq9e7fS0tKUlpamvXv3BvZ5fT6fL7ByW76owTODXQLQIiVOnBDsEoAWZ+c9KdbvMcyzzch13slsfK1HjhxRbGystm3bpssvv7zeYyZOnKiqqipt3Lixbt/w4cM1aNAgZWVlNfhedC4AAAgRXq9XFRUVfpvX623QuceOHZMkxcTEnPaYgoICpaam+u0bPXq0CgoKAqqTcAEAgGWmhkU8Ho+io6P9No/Hc9b719bWavbs2brssss0YMCA0x5XWlqquLg4v31xcXEqLS0N6POyFBUAAMtMPeciMzNTGRkZfvvcbvdZz5sxY4b27t2r7du3G6njbAgXAACECLfb3aAw8b/NnDlTGzduVH5+vrp163bGY+Pj41VWVua3r6ysTPHx8QHdk2ERAAAsC8ZqEZ/Pp5kzZ2rdunV666231KtXr7Oek5ycrLy8PL99ubm5Sk5ODujedC4AALAsGI//njFjhlatWqX169erffv2dfMmoqOjFRUVJUmaPHmyunbtWjdvY9asWUpJSdHixYt1zTXXaPXq1dq1a5eWL18e0L3pXAAA0AotW7ZMx44d08iRI9W5c+e6bc2aNXXHFBcXq6SkpO7rESNGaNWqVVq+fLkSExO1du1a5eTknHESaH3oXAAAYFkw3i3SkMdYbd269ZR9EyZM0IQJTXsmDuECAADLnPZWVIZFAACAUXQuAACwzGmdC8IFAACWOSxbEC4AALDNaZ0L5lwAAACj6FwAAGCZwxoXhAsAAGxjWAQAAKAJ6FwAAGCZwxoXhAsAAGwLc1i6YFgEAAAYRecCAADLHNa4IFwAAGCb01aLEC4AALAszFnZgjkXAADALDoXAABYxrAIAAAwymHZgmERAABgFp0LAAAsc8lZrQvCBQAAlrFaBAAAoAnoXAAAYBmrRQAAgFEOyxYMiwAAALPoXAAAYJnTXrlOuAAAwDKHZQvCBQAAtjltQidzLgAAgFF0LgAAsMxhjQvCBQAAtjltQifDIgAAwCg6FwAAWOasvgXhAgAA61gtAgAA0AR0LgAAsMxpr1xvULjYsGFDgy947bXXNroYAABaI6cNizQoXKSlpTXoYi6XSzU1NU2pBwAAhLgGhYva2lrbdQAA0Go5rHHBnAsAAGxjWKQBqqqqtG3bNhUXF+vEiRN+37v99tuNFAYAQGvBhM6z2L17t66++mp99913qqqqUkxMjMrLy9W2bVvFxsYSLgAAcLiAn3MxZ84cjRs3TkePHlVUVJR27typQ4cOKSkpSY8++qiNGgEACGkul8vIFioCDhdFRUWaO3euwsLCFB4eLq/Xq+7du+uRRx7Rvffea6NGAABCmsvQFioCDhdt2rRRWNgPp8XGxqq4uFiSFB0drcOHD5utDgAAhJyA51wMHjxY7733nnr37q2UlBQ98MADKi8v14svvqgBAwbYqBEAgJDGK9fP4qGHHlLnzp0lSb///e/VsWNHTZ8+XUeOHNHy5cuNFwgAQKhzucxsoSLgzsXQoUPr/ndsbKw2b95stCAAABDaeIgWAACWhdJKDxMCDhe9evU64w/p4MGDTSoIAIDWxmHZIvBwMXv2bL+vq6urtXv3bm3evFl33nmnqboAAECICjhczJo1q979S5cu1a5du5pcEAAArU2wVovk5+dr0aJFKiwsVElJidatW3fGN51v3bpVo0aNOmV/SUmJ4uPjG3zfgFeLnM7YsWP12muvmbocAACtRrBWi1RVVSkxMVFLly4N6Lz9+/erpKSkbouNjQ3ofGMTOteuXauYmBhTlwMAoNUI1oTOsWPHauzYsQGfFxsbq/POO6/R923UQ7T+9w/J5/OptLRUR44c0dNPP93oQgAAwJl5vV55vV6/fW63W2632+h9Bg0aJK/XqwEDBmj+/Pm67LLLAjo/4HAxfvx4v3ARFhamCy64QCNHjlTfvn0DvZwVR997KtglAABQx9QcBI/HowULFvjtmzdvnubPn2/k+p07d1ZWVpaGDh0qr9erFStWaOTIkXrnnXc0ZMiQBl/H5fP5fEYqakGOnwx2BQCAUBHZDE98uj3nYyPXWTS2V6M7Fy6X66wTOuuTkpKiHj166MUXX2zwOQGHqfDwcH355Zen7P/qq68UHh4e6OUAAEADud1udejQwW8zPSTyY5deeqkOHDgQ0DkB57XTNTq8Xq8iIiICvRwAAK1eWAg/RKuoqKjunWIN1eBw8cQTT0j6oa2yYsUKtWvXru57NTU1ys/PbzFzLgAAaEmCFS4qKyv9ug6ffvqpioqKFBMTox49eigzM1NffPGF/vSnP0mSHnvsMfXq1Us/+clPdPz4ca1YsUJvvfWW/vKXvwR03waHiyVLlkj6oXORlZXlNwQSERGhCy+8UFlZWQHdHAAA2LNr1y6/h2JlZGRIktLT05Wdna2SkhIVFxfXff/EiROaO3euvvjiC7Vt21YXX3yx/vrXv9b7YK0zCXhC56hRo/T666+rY8eOAd2oOTGhEwDQUM0xoXPuf+43cp3F4/oYuY5tAf9I//a3v9moAwCAViuU51w0RsCrRa6//nr94Q9/OGX/I488ogkTJhgpCgAAhK6Aw0V+fr6uvvrqU/aPHTtW+fn5RooCAKA1Cda7RYIl4GGRysrKepectmnTRhUVFUaKAgCgNQnWW1GDJeDOxcCBA7VmzZpT9q9evVr9+/c3UhQAAK1JmKEtVATcubj//vt13XXX6ZNPPtEVV1whScrLy9OqVau0du1a4wUCAIDQEnC4GDdunHJycvTQQw9p7dq1ioqKUmJiot566y1euQ4AQD0cNirS9BeXVVRU6OWXX9Zzzz2nwsJC1dTUmKqt0XjOBQCgoZrjORf3b/6HkessHNPbyHVsa/QQTn5+vtLT09WlSxctXrxYV1xxhXbu3GmyNgAAEIICymulpaXKzs7Wc889p4qKCt1www3yer3KyclhMicAAKfhtGGRBncuxo0bpz59+ujDDz/UY489pn/+85968sknbdYGAECrEOYys4WKBncu3nzzTd1+++2aPn26evcOjTEfAADQ/Brcudi+fbu+/fZbJSUladiwYXrqqadUXl5uszYAAFqFMJfLyBYqGhwuhg8frmeffVYlJSX63e9+p9WrV6tLly6qra1Vbm6uvv32W5t1AgAQspz2+O+AV4uce+65uummm7R9+3bt2bNHc+fO1cMPP6zY2Fhde+21NmoEAAAhpElPE+3Tp48eeeQRff7553r55ZdN1QQAQKvitAmdTX6IVkvEQ7QAAA3VHA/ReijvEyPXufen/2bkOrY1w48UAABnC6Wugwmh9JI1AAAQAuhcAABgmdM6F4QLAAAsc4XSOlIDGBYBAABG0bkAAMAyhkUAAIBRDhsVYVgEAACYRecCAADLQumlYyYQLgAAsMxpcy4YFgEAAEbRuQAAwDKHjYoQLgAAsC1MzkoXhAsAACxzWueCORcAAMAoOhcAAFjmtNUihAsAACxz2nMuGBYBAABG0bkAAMAyhzUuCBcAANjGsAgAAEAT0LkAAMAyhzUuCBcAANjmtGECp31eAABgGZ0LAAAsczlsXIRwAQCAZc6KFoQLAACsYykqAABAE9C5AADAMmf1LQgXAABY57BREYZFAACAWXQuAACwjKWoAADAKKcNEzjt8wIA4Bj5+fkaN26cunTpIpfLpZycnLOes3XrVg0ZMkRut1sJCQnKzs4O+L6ECwAALHO5XEa2QFVVVSkxMVFLly5t0PGffvqprrnmGo0aNUpFRUWaPXu2br75Zm3ZsiWg+zIsAgCAZcGacTF27FiNHTu2wcdnZWWpV69eWrx4sSSpX79+2r59u5YsWaLRo0c3+Dp0LgAAgCSpoKBAqampfvtGjx6tgoKCgK5D5wIAAMtMrRbxer3yer1++9xut9xut5Hrl5aWKi4uzm9fXFycKioq9P333ysqKqpB16FzAQCAZWGGNo/Ho+joaL/N4/E098c5KzoXAABYZqpzkZmZqYyMDL99proWkhQfH6+ysjK/fWVlZerQoUODuxYS4QIAgJBhcgikPsnJydq0aZPfvtzcXCUnJwd0HYZFAACwzGVoC1RlZaWKiopUVFQk6YelpkVFRSouLpb0Qydk8uTJdcffcsstOnjwoO666y59/PHHevrpp/XKK69ozpw5Ad2XzgUAAJYF6+nfu3bt0qhRo+q+/p8hlfT0dGVnZ6ukpKQuaEhSr1699MYbb2jOnDl6/PHH1a1bN61YsSKgZaiS5PL5fD4zH6HlOH4y2BUAAEJFZDP8M3v9nlIj1xk/MN7IdWyjcwEAgGVhQXuMVnAQLgAAsMxhL0VlQicAADCLzgUAAJa5GBYBAAAmMSwCAADQBHQuAACwjNUiAADAKKcNixAuAACwzGnhgjkXAADAKDoXAABYxlJUAABgVJizsgXDIgAAwCw6FwAAWMawCAAAMIrVIgAAAE1A5wIAAMsYFgEAAEaxWgQAAKAJCBewZvWqP2vslVfoksED9atfTNCeDz8MdklA0PF74UwuQ/+FCsIFrNj85iY9+ohHv7t1hla/uk59+vTV9N9N1VdffRXs0oCg4ffCuVwuM1uoIFzAihdfeF7X/fwGpf3sev1bQoLum7dAkZGRynn9tWCXBgQNvxfO5TK0hQrCBYyrPnFCH/3XPg1PHlG3LywsTMOHj9CHH+wOYmVA8PB7ASdp0eHi8OHDuummm854jNfrVUVFhd/m9XqbqULU5+g3R1VTU6Pzzz/fb//555+v8vLyIFUFBBe/F84W5nIZ2UJFiw4XX3/9tV544YUzHuPxeBQdHe23LfqDp5kqBADg7Jw2LBLU51xs2LDhjN8/ePDgWa+RmZmpjIwMv32+cHeT6kLTdDyvo8LDw0+ZpPbVV1+pU6dOQaoKCC5+L+AkQQ0XaWlpcrlc8vl8pz3GdZY2kNvtltvtHyaOnzRSHhqpTUSE+vX/id7ZWaArfpoqSaqtrdU77xToF5N+HeTqgODg98LhQqntYEBQh0U6d+6s119/XbW1tfVu77//fjDLQxP8Jv1Gvb72FW3IWaeDn3yi/3hwvr7//nul/ey6YJcGBA2/F87ltOdcBLVzkZSUpMLCQo0fP77e75+tq4GWa8zYq3X066/19FNPqLz8iPr07aenn1mh82n/wsH4vYBTuHxB/Ov99ttvq6qqSmPGjKn3+1VVVdq1a5dSUlICui7DIgCAhopshn9mv3vwmJHrXPp/oo1cx7aghgtbCBcAgIZqjnDxnqFwcUmIhIsWvRQVAACEHl65DgCAbaEzF9MIwgUAAJaF0koPEwgXAABYFkJP7jaCORcAAMAoOhcAAFjmsMYF4QIAAOscli4YFgEAAEbRuQAAwDJWiwAAAKNYLQIAANAEdC4AALDMYY0LwgUAANY5LF0wLAIAAIyicwEAgGWsFgEAAEY5bbUI4QIAAMscli2YcwEAAMyicwEAgG0Oa10QLgAAsMxpEzoZFgEAoBVbunSpLrzwQkVGRmrYsGF69913T3tsdna2XC6X3xYZGRnwPQkXAABY5nKZ2QK1Zs0aZWRkaN68eXr//feVmJio0aNH68svvzztOR06dFBJSUnddujQoYDvS7gAAMAyl6EtUH/84x81bdo03Xjjjerfv7+ysrLUtm1brVy58vS1ulyKj4+v2+Li4gK+L+ECAIAQ4fV6VVFR4bd5vd56jz1x4oQKCwuVmppaty8sLEypqakqKCg47T0qKyvVs2dPde/eXePHj9e+ffsCrpNwAQCAbYZaFx6PR9HR0X6bx+Op95bl5eWqqak5pfMQFxen0tLSes/p06ePVq5cqfXr1+ull15SbW2tRowYoc8//zygj8tqEQAALDO1WiQzM1MZGRl++9xut5FrS1JycrKSk5Prvh4xYoT69eunZ555RgsXLmzwdQgXAACECLfb3eAw0alTJ4WHh6usrMxvf1lZmeLj4xt0jTZt2mjw4ME6cOBAQHUyLAIAgGXBWC0SERGhpKQk5eXl1e2rra1VXl6eX3fiTGpqarRnzx517tw5oHvTuQAAwLJgPUIrIyND6enpGjp0qC699FI99thjqqqq0o033ihJmjx5srp27Vo3b+PBBx/U8OHDlZCQoG+++UaLFi3SoUOHdPPNNwd0X8IFAAC2BSldTJw4UUeOHNEDDzyg0tJSDRo0SJs3b66b5FlcXKywsH8NYhw9elTTpk1TaWmpOnbsqKSkJO3YsUP9+/cP6L4un8/nM/pJWoDjJ4NdAQAgVEQ2wz+z/7vsOyPXuSiurZHr2EbnAgAAy5z2bhHCBQAAljXm0d2hjNUiAADAKDoXAABY5rDGBeECAADrHJYuGBYBAABG0bkAAMAyVosAAACjWC0CAADQBHQuAACwzGGNC8IFAADWOSxdEC4AALDMaRM6mXMBAACMonMBAIBlTlstQrgAAMAyh2ULhkUAAIBZdC4AALCMYREAAGCYs9IFwyIAAMAoOhcAAFjGsAgAADDKYdmCYREAAGAWnQsAACxjWAQAABjltHeLEC4AALDNWdmCORcAAMAsOhcAAFjmsMYF4QIAANucNqGTYREAAGAUnQsAACxjtQgAADDLWdmCYREAAGAWnQsAACxzWOOCcAEAgG2sFgEAAGgCOhcAAFjGahEAAGAUwyIAAABNQLgAAABGMSwCAIBlThsWIVwAAGCZ0yZ0MiwCAACMonMBAIBlDIsAAACjHJYtGBYBAABm0bkAAMA2h7UuCBcAAFjGahEAAIAmoHMBAIBlrBYBAABGOSxbEC4AALDOYemCORcAALRiS5cu1YUXXqjIyEgNGzZM77777hmPf/XVV9W3b19FRkZq4MCB2rRpU8D3JFwAAGCZy9B/gVqzZo0yMjI0b948vf/++0pMTNTo0aP15Zdf1nv8jh07NGnSJE2dOlW7d+9WWlqa0tLStHfv3sA+r8/n8wVcbQt3/GSwKwAAhIrIZpggYOrvUqC1Dhs2TJdccomeeuopSVJtba26d++u2267Tffcc88px0+cOFFVVVXauHFj3b7hw4dr0KBBysrKavB96VwAABAivF6vKioq/Dav11vvsSdOnFBhYaFSU1Pr9oWFhSk1NVUFBQX1nlNQUOB3vCSNHj36tMefTquc0NkcKRRn5/V65fF4lJmZKbfbHexygBaD3w3nMfV3af5/eLRgwQK/ffPmzdP8+fNPOba8vFw1NTWKi4vz2x8XF6ePP/643uuXlpbWe3xpaWlAddK5gDVer1cLFiw4baoGnIrfDTRWZmamjh075rdlZmYGu6xT8G98AABChNvtbnC3q1OnTgoPD1dZWZnf/rKyMsXHx9d7Tnx8fEDHnw6dCwAAWqGIiAglJSUpLy+vbl9tba3y8vKUnJxc7znJycl+x0tSbm7uaY8/HToXAAC0UhkZGUpPT9fQoUN16aWX6rHHHlNVVZVuvPFGSdLkyZPVtWtXeTweSdKsWbOUkpKixYsX65prrtHq1au1a9cuLV++PKD7Ei5gjdvt1rx585iwBvwIvxtoLhMnTtSRI0f0wAMPqLS0VIMGDdLmzZvrJm0WFxcrLOxfgxgjRozQqlWrdN999+nee+9V7969lZOTowEDBgR031b5nAsAABA8zLkAAABGES4AAIBRhAsAAGAU4QIAABhFuIA1gb7mF2jt8vPzNW7cOHXp0kUul0s5OTnBLgmwgnABKwJ9zS/gBFVVVUpMTNTSpUuDXQpgFUtRYUWgr/kFnMblcmndunVKS0sLdimAcXQuYFxjXvMLAGg9CBcw7kyv+Q30tb0AgNBDuAAAAEYRLmBcY17zCwBoPQgXMK4xr/kFALQevBUVVpztNb+AE1VWVurAgQN1X3/66acqKipSTEyMevToEcTKALNYigprnnrqKS1atKjuNb9PPPGEhg0bFuyygKDZunWrRo0adcr+9PR0ZWdnN39BgCWECwAAYBRzLgAAgFGECwAAYBThAgAAGEW4AAAARhEuAACAUYQLAABgFOECAAAYRbgAWqEpU6YoLS2t7uuRI0dq9uzZzV7H1q1b5XK59M033zT7vQEED+ECaEZTpkyRy+WSy+VSRESEEhIS9OCDD+rkyZNW7/v6669r4cKFDTqWQACgqXi3CNDMxowZo+eff15er1ebNm3SjBkz1KZNG2VmZvodd+LECUVERBi5Z0xMjJHrAEBD0LkAmpnb7VZ8fLx69uyp6dOnKzU1VRs2bKgbyvj973+vLl26qE+fPpKkw4cP64YbbtB5552nmJgYjR8/Xp999lnd9WpqapSRkaHzzjtP559/vu666y79+Kn+Px4W8Xq9uvvuu9W9e3e53W4lJCToueee02effVb37ouOHTvK5XJpypQpkn54s63H41GvXr0UFRWlxMRErV271u8+mzZt0kUXXaSoqCiNGjXKr04AzkG4AIIsKipKJ06ckCTl5eVp//79ys3N1caNG1VdXa3Ro0erffv2evvtt/X3v/9d7dq105gxY+rOWbx4sbKzs7Vy5Upt375dX3/9tdatW3fGe06ePFkvv/yynnjiCX300Ud65pln1K5dO3Xv3l2vvfaaJGn//v0qKSnR448/LknyeDz605/+pKysLO3bt09z5szRr3/9a23btk3SDyHouuuu07hx41RUVKSbb75Z99xzj60fG4CWzAeg2aSnp/vGjx/v8/l8vtraWl9ubq7P7Xb77rjjDl96erovLi7O5/V6645/8cUXfX369PHV1tbW7fN6vb6oqCjfli1bfD6fz9e5c2ffI488Uvf96upqX7du3eru4/P5fCkpKb5Zs2b5fD6fb//+/T5Jvtzc3Hpr/Nvf/uaT5Dt69GjdvuPHj/vatm3r27Fjh9+xU6dO9U2aNMnn8/l8mZmZvv79+/t9/+677z7lWgBaP+ZcAM1s48aNateunaqrq1VbW6tf/vKXmj9/vmbMmKGBAwf6zbP44IMPdODAAbVv397vGsePH9cnn3yiY8eOqaSkxO9V9uecc46GDh16ytDI/ygqKlJ4eLhSUlIaXPOBAwf03Xff6corr/Tbf+LECQ0ePFiS9NFHH/nVIUnJyckNvgeA1oNwATSzUaNGadmyZYqIiFCXLl10zjn/+jU899xz/Y6trKxUUlKS/vznP59ynQsuuKBR94+Kigr4nMrKSknSG2+8oa5du/p9z+12N6oOAK0X4QJoZueee64SEhIadOyQIUO0Zs0axcbGqkOHDvUe07lzZ73zzju6/PLLJUknT55UYWGhhgwZUu/xAwcOVG1trbZt26bU1NRTvv8/nZOampq6ff3795fb7VZxcfFpOx79+vXThg0b/Pbt3Lnz7B8SQKvDhE6gBfvVr36lTp06afz48Xr77bf16aefauvWrbr99tv1+eefS5JmzZqlhx9+WDk5Ofr444916623nvEZFRdeeKHS09N10003KScnp+6ar7zyiiSpZ8+ecrlc2rhxo44cOaLKykq1b99ed9xxh+bMmaMXXnhBn3zyid5//309+eSTeuGFFyRJt9xyi/7xj3/ozjvv1P79+7Vq1SplZ2fb/hEBaIEIF0AL1rZtW+Xn56tHjx667rrr1K9fP02dOlXHjx+v62TMnTtXv/nNb5Senq7k5GS1b99eP/vZz8543WXLlunnP/+5br31VvXt21fTpk1TVVWVJKlr165asGCB7rnnHsXFxWnmzJmSpIULF+r++++Xx+NRv379NGbMGL3xxhvq1auXJKlHjx567bXXlJOTo8TERGVlZemhhx6y+NMB0FK5fKeb9QUAANAIdC4AAIBRhAsAAGAU4QIAABhFuAAAAEYRLgAAgFGECwAAYBThAgAAGEW4AAAARhEuAACAUYQLAABgFOECAAAYRbgAAABG/T+78pPZYPfWewAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.60         5\n",
            "   macro avg       0.50      0.30      0.38         5\n",
            "weighted avg       1.00      0.60      0.75         5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "test_dir = '/content/drive/MyDrive/spectrograms/infected-single/test/'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Just normalization\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important if you want to match predictions to filenames\n",
        ")\n",
        "#7= 8769"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKw0pxO2Wdmb",
        "outputId": "d826a5a6-fb62-49ff-8afd-8e2824d6bea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = [1,1,1,1]\n",
        "y_pred = (best_model.predict(test_generator) > 0.5).astype(int).flatten()\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "BhF694wuWgWn",
        "outputId": "10496764-2ffe-4283-a45f-e244682e1fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.75         4\n",
            "   macro avg       0.50      0.38      0.43         4\n",
            "weighted avg       1.00      0.75      0.86         4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MkWI-HlWtLi",
        "outputId": "7f0a93e0-4a0a-44f5-ebe5-d6a0126b8b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvYHOQIIe2vg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJ/Kr+JWp2c2iR795Z4H4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}